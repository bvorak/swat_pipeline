{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f932f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "# Ensure the project root (parent of this folder) is importable\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "from python_pipeline_scripts import utils, runner\n",
    "config = utils.load_config(Path().resolve().parent / 'config' / 'config.yaml')\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d55a753",
   "metadata": {},
   "source": [
    "### working for diffuse loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 17:32:26,256 | INFO | python_pipeline_scripts.raster_agg | Zonal aggregation start | zones=C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\cubillas_hru\\Watershed\\Shapes\\hru1.shp | rasters_dir=C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\n",
      "2025-09-02 17:32:26,756 | INFO | python_pipeline_scripts.raster_agg | Valid HRU features: 878 | bounds=[ 438912.5        4123462.50012207  470812.5        4158362.50012207]\n",
      "2025-09-02 17:32:26,760 | INFO | python_pipeline_scripts.raster_agg | Found 2 raster(s) matching '_rediam.tif'\n",
      "2025-09-02 17:32:26,762 | INFO | python_pipeline_scripts.raster_agg | Reprojected (cached) -> C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\temp_cache\\Fosforo_mg_100g_P205_rediam_reproj.tif\n",
      "2025-09-02 17:32:26,764 | INFO | python_pipeline_scripts.raster_agg | Clipped (cached) -> C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\temp_cache\\Fosforo_mg_100g_P205_rediam_clip.tif\n",
      "2025-09-02 17:32:53,236 | INFO | python_pipeline_scripts.raster_agg | Reprojected (cached) -> C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\temp_cache\\Nitrogeno_total_porcent_resample_Rediam_reproj.tif\n",
      "2025-09-02 17:32:53,238 | INFO | python_pipeline_scripts.raster_agg | Clipped (cached) -> C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\temp_cache\\Nitrogeno_total_porcent_resample_Rediam_clip.tif\n",
      "2025-09-02 17:33:21,792 | INFO | python_pipeline_scripts.raster_agg | Wrote: C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil GEO_INFO_POOL\\Input Data\\Diffuse loads\\Soil chemical composition\\python calculated hru stats\\hru_chem_stats.gpkg (layer=values_by_hru)\n",
      "2025-09-02 17:33:21,800 | INFO | python_pipeline_scripts.raster_agg | Wrote manifest: C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil GEO_INFO_POOL\\Input Data\\Diffuse loads\\Soil chemical composition\\python calculated hru stats\\hru_chem_stats.gpkg.manifest.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to CSV: C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil GEO_INFO_POOL\\Input Data\\Diffuse loads\\Soil chemical composition\\python calculated hru stats\\hru_chem_stats.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'build_mean_overrides_from_spec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 413\u001b[39m\n",
      "\u001b[32m    411\u001b[39m     per_realization_params = build_random_overrides_from_spec(MC_SPEC, MC_SPEC.get(\u001b[33m\"\u001b[39m\u001b[33mdraws\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m), seed=\u001b[32m0\u001b[39m)\n",
      "\u001b[32m    412\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m MODE == \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     per_realization_params = \u001b[43mbuild_mean_overrides_from_spec\u001b[49m(MC_SPEC)\n",
      "\u001b[32m    414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[31mNameError\u001b[39m: name 'build_mean_overrides_from_spec' is not defined"
     ]
    }
   ],
   "source": [
    "# Jupyter single-cell: Monte Carlo pipeline using generic ops with mean/extreme/random modes and per-realization provenance files.\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from itertools import product\n",
    "import random\n",
    "import geopandas as gpd\n",
    "\n",
    "# Ensure the project root (parent of this folder) is importable\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "from python_pipeline_scripts import utils\n",
    "from python_pipeline_scripts.raster_agg import raster_zonal_aggregation_to_gpkg\n",
    "from python_pipeline_scripts.transforms.soil_chm import (\n",
    "    read_n_p_means_from_csv_to_df,\n",
    "    transform_apply_ops,\n",
    "    transform_split_with_bounds,\n",
    "    transform_write_chm_from_df,\n",
    ")\n",
    "\n",
    "from python_pipeline_scripts.transforms.soil_chm import (\n",
    "    read_n_p_means_from_csv_to_df,\n",
    "    transform_apply_ops,\n",
    "    transform_split_with_bounds,\n",
    "    transform_write_chm_from_df,\n",
    ")\n",
    "\n",
    "from python_pipeline_scripts.transforms.point_dat import (\n",
    "    read_population_by_subbasin_csv_to_df,\n",
    "    transform_interpolate_years_wide,\n",
    "    transform_build_point_load_timeseries,\n",
    "    transform_write_point_dat_from_df,\n",
    ")\n",
    "\n",
    "from python_pipeline_scripts.mc_engine import run_monte_carlo\n",
    "from python_pipeline_scripts.provenance_report import summarize_run, realization_report, build_upstream_inputs\n",
    "\n",
    "DEBUG = True  # set False to silence extra transform prints\n",
    "\n",
    "def _resolve(p: str, base: Path) -> Path:\n",
    "    pp = Path(p)\n",
    "    return pp if pp.is_absolute() else (base / pp).resolve()\n",
    "\n",
    "# ------------------------- 0) Resolve paths -------------------------\n",
    "script_dir = Path(r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\scripts\\script DIFFUSE loads - input .chm\")\n",
    "\n",
    "output_gpkg = r\"..\\..\\Genil GEO_INFO_POOL\\Input Data\\Diffuse loads\\Soil chemical composition\\python calculated hru stats\\hru_chem_stats.gpkg\"\n",
    "raster_folder = r\"..\\..\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\"\n",
    "zones_fp = r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\cubillas_hru\\Watershed\\Shapes\\hru1.shp\"\n",
    "\n",
    "output_gpkg_p = _resolve(output_gpkg, script_dir)\n",
    "raster_folder_p = _resolve(raster_folder, script_dir)\n",
    "zones_fp_p = Path(zones_fp)\n",
    "\n",
    "cfg = utils.load_config(Path(\"../config/config.yaml\"))\n",
    "\n",
    "_ = raster_zonal_aggregation_to_gpkg(\n",
    "    raster_folder=raster_folder_p,\n",
    "    zones_fp=zones_fp_p,\n",
    "    zone_field=\"HRU_GIS\",\n",
    "    label_field=\"OBJECTID\",\n",
    "    output_gpkg=output_gpkg_p,\n",
    "    files_end_with=\"_rediam.tif\",\n",
    "    stat_operation=\"mean\",\n",
    "    raster_alias=\"full_name\",\n",
    "    zone_meaning=\"HRU\",\n",
    "    overwrite_cache=False,\n",
    "    write_manifest=True,  # emit .manifest.json\n",
    "    config=cfg,\n",
    ")\n",
    "\n",
    "layer_name = \"values_by_hru\"\n",
    "gdf = gpd.read_file(output_gpkg_p, layer=layer_name)\n",
    "csv_output = str(output_gpkg_p).replace(\".gpkg\", \".csv\")\n",
    "gdf.drop(columns=\"geometry\").to_csv(csv_output, sep=\";\", index=False)\n",
    "print(f\"Exported to CSV: {csv_output}\")\n",
    "\n",
    "# -------------------- 1) Monte Carlo spec (single dict) --------------------\n",
    "# MODE: 'extreme', 'random', or 'mean'\n",
    "MC_SPEC = {\n",
    "    \"mode\": \"mean\",   # 'mean' | 'extreme' | 'random'\n",
    "    \"draws\": 2,       # used only when mode == 'random'\n",
    "    \"transforms\": [\n",
    "        # 0) Base conversions via generic ops (unbounded, deterministic)\n",
    "        {\"type\": \"ops\", \"name\": \"compute_base_ops\", \"ops\": [\n",
    "            {\n",
    "                \"src\": \"mean_Nitrogeno_total_porcent_resample_Rediam\",\n",
    "                \"out\": \"N_total_mg_kg\",\n",
    "                \"op\": \"mul\",\n",
    "                #\"factor\": 10_000.0,      # deterministic\n",
    "                \"mean\": 10_000.0, \"lower\": None, \"upper\": None,\n",
    "                \"source\": \"deterministic\",\n",
    "            },\n",
    "            {\n",
    "                \"src\": \"mean_Fosforo_mg_100g_P205_rediam\",\n",
    "                \"out\": \"P_element_mg_kg\",\n",
    "                \"op\": \"mul\",\n",
    "                #\"factor\": 10.0 * 0.4364, # deterministic\n",
    "                \"mean\": 10.0 * 0.4364, \"lower\": None, \"upper\": None,\n",
    "                \"source\": \"deterministic\",\n",
    "            },\n",
    "        ]},\n",
    "\n",
    "\n",
    "        # # 1) Scaling via generic ops (bounded; per-realization picks factor)\n",
    "        # {\"type\": \"ops\", \"name\": \"scale_ops\", \"ops\": [\n",
    "        #     {\n",
    "        #         \"src\": \"N_total_mg_kg\",\n",
    "        #         \"out\": \"N_total_mg_kg_scaled\",\n",
    "        #         \"op\": \"mul\",\n",
    "        #         \"mean\": 1.0, \"lower\": 0.8, \"upper\": 1.2,\n",
    "        #     },\n",
    "        #     {\n",
    "        #         \"src\": \"P_element_mg_kg\",\n",
    "        #         \"out\": \"P_element_mg_kg_scaled\",\n",
    "        #         \"op\": \"mul\",\n",
    "        #         \"mean\": 1.0, \"lower\": 0.6, \"upper\": 1.4,\n",
    "        #     },\n",
    "        # ]},\n",
    "\n",
    "        # 2) Split N_total_mg_kg_scaled into pools (bounded ratios)\n",
    "        {\"type\": \"split\", \"src\": \"N_total_mg_kg\", \"renormalize\": True,\n",
    "         \"outputs\": [\n",
    "             {\"name\": \"Soil NO3 [mg/kg]\", \"mean\": 0.02, \"lower\": 0.018, \"upper\": 0.022},\n",
    "             {\"name\": \"Soil organic N [mg/kg]\", \"mean\": 0.98, \"lower\": 0.978, \"upper\": 0.982},\n",
    "         ]},\n",
    "\n",
    "        # 2b) Derive Soil organic P from N (bounded ratio)\n",
    "        {\"type\": \"ops\", \"name\": \"derive_p_org_from_n\", \"ops\": [\n",
    "            {\n",
    "                \"src\": \"N_total_mg_kg\",\n",
    "                \"out\": \"Soil organic P [mg/kg]\",\n",
    "                \"op\": \"mul\",\n",
    "                \"mean\": 0.125, \"lower\": 0.1, \"upper\": 0.3,\n",
    "                \"source\": \"deterministic\",\n",
    "            },\n",
    "        ]},\n",
    "\n",
    "\n",
    "        # 3) Split P_element_mg_kg_scaled into pools (bounded ratios)\n",
    "        {\"type\": \"split\", \"src\": \"P_element_mg_kg\", \"renormalize\": True,\n",
    "         \"outputs\": [\n",
    "             {\"name\": \"Soil labile P [mg/kg]\", \"mean\": 1.0, \"lower\": 1.0, \"upper\": 1.0},\n",
    "             #{\"name\": \"Soil organic P [mg/kg]\", \"mean\": 0.0, \"lower\": 0.0, \"upper\": 0.0},\n",
    "         ]},\n",
    "\n",
    "\n",
    "\n",
    "        # 4) Write CHM files\n",
    "        {\"type\": \"write_chm\", \"id_col\": \"HRU_GIS\",\n",
    "         \"label_map\": {\n",
    "             \"Soil NO3 [mg/kg]\": \"Soil NO3 [mg/kg]\",\n",
    "             \"Soil organic N [mg/kg]\": \"Soil organic N [mg/kg]\",\n",
    "             \"Soil labile P [mg/kg]\": \"Soil labile P [mg/kg]\",\n",
    "             \"Soil organic P [mg/kg]\": \"Soil organic P [mg/kg]\",\n",
    "         }},\n",
    "\n",
    "\n",
    "        ######### THIS SHOULD BE CONNECTED TO .CIO FILE TO ALWAYS HAVE CORRECT START AND END YEARS\n",
    "        # Interpolate to full yearly range (optional; place before build_point):\n",
    "        {\"type\": \"interpolate_years_wide\", \"id_col\": \"GRIDCODE\", \"year_start\": 1970, \"year_end\": 2021},\n",
    "\n",
    "        # Build point-source timeseries from population:\n",
    "        {\n",
    "            \"type\": \"build_point\",\n",
    "            \"id_col\": \"GRIDCODE\",\n",
    "            \"wastewater_lppd\": 150.0,\n",
    "            \"mgL_values\": {\n",
    "            \"ORGNYR\": {\"mean\": 15, \"lower\": 12, \"upper\": 18},\n",
    "            \"ORGPYR\": {\"mean\": 3,  \"lower\": 2.5, \"upper\": 3.5},\n",
    "            \"NO3YR\":  {\"mean\": 0,  \"lower\": 0,   \"upper\": 0},\n",
    "            \"NH3YR\":  {\"mean\": 25, \"lower\": 20,  \"upper\": 30},\n",
    "            \"NO2YR\":  {\"mean\": 0,  \"lower\": 0,   \"upper\": 0},\n",
    "            \"MINPYR\": {\"mean\": 5,  \"lower\": 4,   \"upper\": 6},\n",
    "            \"SEDYR\":  {\"mean\": 720,\"lower\": 600, \"upper\": 800},\n",
    "            \"CBODYR\": {\"mean\": 220,\"lower\": 180, \"upper\": 260},\n",
    "            \"DISOXYR\":{\"mean\": 2.5,\"lower\": 2.0, \"upper\": 3.0},\n",
    "            \"CHLAYR\": {\"mean\": 0.001,\"lower\": 0.0,\"upper\": 0.002}\n",
    "            },\n",
    "            \"out_columns\": [\"YEAR\",\"FLOYR\",\"SEDYR\",\"ORGNYR\",\"ORGPYR\",\"NO3YR\",\"NH3YR\",\"NO2YR\",\"MINPYR\",\"CBODYR\",\"DISOXYR\",\"CHLAYR\"]\n",
    "        },\n",
    "\n",
    "        ######### THIS SHOULD BE CONNECTED TO .CIO FILE TO ALWAYS HAVE CORRECT START AND END YEARS\n",
    "        # Write .dat files:\n",
    "        {\"type\": \"write_point_dat\",\n",
    "        \"id_col\": \"GRIDCODE\",\n",
    "        \"columns_order\": [\"YEAR\",\"FLOYR\",\"SEDYR\",\"ORGNYR\",\"ORGPYR\",\"NO3YR\",\"NH3YR\",\"NO2YR\",\"MINPYR\",\"CBODYR\",\"DISOXYR\",\"CHLAYR\"],\n",
    "        \"start_year\": 1970, \"end_year\": 2021}\n",
    "\n",
    "\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ------------------ 2) Build transforms & defaults ------------------\n",
    "base_txtinout = r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_set-219\\TxtInOut_1\"\n",
    "realizations_root = r\"C:\\SWAT\\RSWAT\\cubillas\\mc_realizations\"\n",
    "results_root = r\"C:\\SWAT\\RSWAT\\cubillas\\mc_results\"\n",
    "\n",
    "base_txtinout_p = Path(base_txtinout)\n",
    "realizations_root_p = Path(realizations_root)\n",
    "results_root_p = Path(results_root)\n",
    "\n",
    "manifest_file = Path(str(output_gpkg_p) + \".manifest.json\")\n",
    "upstream = build_upstream_inputs(\n",
    "    raster_folder=raster_folder_p,\n",
    "    pattern=\"*_rediam.tif\",\n",
    "    zones_fp=zones_fp_p,\n",
    "    gpkg_path=output_gpkg_p,\n",
    "    csv_path=Path(csv_output),\n",
    ")\n",
    "\n",
    "transforms = []\n",
    "transforms_params = []\n",
    "\n",
    "for t in MC_SPEC[\"transforms\"]:\n",
    "    ttype = t[\"type\"]\n",
    "\n",
    "    if ttype == \"ops\":\n",
    "        transforms.append(transform_apply_ops)\n",
    "        transforms_params.append({\n",
    "            \"ops\": t[\"ops\"],\n",
    "            \"input_source\": str(manifest_file) if manifest_file.exists() else None,\n",
    "            \"debug\": DEBUG,\n",
    "        })\n",
    "\n",
    "    elif ttype == \"split\":\n",
    "        transforms.append(transform_split_with_bounds)\n",
    "        outputs = [{\n",
    "            \"name\": o[\"name\"],\n",
    "            \"mean\": o[\"mean\"],\n",
    "            \"lower\": o[\"lower\"],\n",
    "            \"upper\": o[\"upper\"],\n",
    "            \"source\": MC_SPEC[\"mode\"]\n",
    "        } for o in t[\"outputs\"]]\n",
    "        transforms_params.append({\n",
    "            \"src\": t[\"src\"],\n",
    "            \"renormalize\": bool(t.get(\"renormalize\", True)),\n",
    "            \"outputs\": outputs,\n",
    "            \"input_source\": str(manifest_file) if manifest_file.exists() else None,\n",
    "            \"debug\": DEBUG,\n",
    "        })\n",
    "\n",
    "    elif ttype == \"write_chm\":\n",
    "        transforms.append(transform_write_chm_from_df)\n",
    "        transforms_params.append({\n",
    "            \"id_col\": t[\"id_col\"],\n",
    "            \"label_map\": t[\"label_map\"],\n",
    "        })\n",
    "\n",
    "    # Optional: keep legacy base computation (now logs via generic scaling)\n",
    "\n",
    "    # elif ttype == \"compute_base\":\n",
    "    #     transforms.append(transform_compute_base_soil_vars)\n",
    "    #     transforms_params.append({\n",
    "    #         \"id_col\": t.get(\"id_col\", \"HRU_GIS\"),\n",
    "    #         \"n_col\": t[\"n_col\"],\n",
    "    #         \"p_col\": t[\"p_col\"],\n",
    "    #         \"debug\": DEBUG,\n",
    "    #     })\n",
    "\n",
    "    # Point loads: interpolate decade→year (wide table)\n",
    "    elif ttype == \"interpolate_years_wide\":\n",
    "        transforms.append(transform_interpolate_years_wide)\n",
    "        transforms_params.append({\n",
    "            \"id_col\": t.get(\"id_col\", \"GRIDCODE\"),\n",
    "            \"year_start\": int(t[\"year_start\"]),\n",
    "            \"year_end\": int(t[\"year_end\"]),\n",
    "            \"keep_existing\": bool(t.get(\"keep_existing\", True)),\n",
    "        })\n",
    "\n",
    "    # Point loads: build timeseries from population and mg/L specs\n",
    "    elif ttype == \"build_point\":\n",
    "        transforms.append(transform_build_point_load_timeseries)\n",
    "        transforms_params.append({\n",
    "            \"id_col\": t.get(\"id_col\", \"GRIDCODE\"),\n",
    "            \"wastewater_lppd\": float(t.get(\"wastewater_lppd\", 150.0)),\n",
    "            \"mgL_values\": t[\"mgL_values\"],     # dict[var] = {mean, lower, upper}\n",
    "            \"out_columns\": t.get(\"out_columns\"),  # optional ordered list\n",
    "            \"round_to\": int(t.get(\"round_to\", 6)),\n",
    "        })\n",
    "\n",
    "    # Point loads: write rcyr_<subbasin>.dat per subbasin\n",
    "    elif ttype == \"write_point_dat\":\n",
    "        transforms.append(transform_write_point_dat_from_df)\n",
    "        transforms_params.append({\n",
    "            \"id_col\": t.get(\"id_col\", \"GRIDCODE\"),\n",
    "            \"columns_order\": t.get(\"columns_order\"),\n",
    "            \"start_year\": t.get(\"start_year\"),\n",
    "            \"end_year\": t.get(\"end_year\"),\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transform type: {ttype}\")\n",
    "\n",
    "# ------------------ 3) Build per_realization overrides ------------------\n",
    "def _op_param_name(kind: str) -> str:\n",
    "    return {\"mul\":\"factor\",\"relative\":\"factor\",\"add\":\"delta\",\"absolute\":\"delta\",\"set\":\"value\"}.get(kind, \"factor\")\n",
    "\n",
    "def _has_bounds(lo, hi) -> bool:\n",
    "    try: return lo is not None and hi is not None and float(hi) != float(lo)\n",
    "    except: return False\n",
    "\n",
    "def build_extreme_overrides(MC_SPEC):\n",
    "    from itertools import product\n",
    "    per_tf_opts = []\n",
    "    for t in MC_SPEC[\"transforms\"]:\n",
    "        tt = t[\"type\"]\n",
    "        if tt == \"ops\":\n",
    "            bundles, any_b = [], False\n",
    "            for op in t[\"ops\"]:\n",
    "                kind = op.get(\"op\",\"mul\"); key = _op_param_name(kind)\n",
    "                lo, hi = op.get(\"lower\"), op.get(\"upper\")\n",
    "                if _has_bounds(lo, hi):\n",
    "                    any_b = True\n",
    "                    bundles.append([{**op, key: float(lo), \"source\":\"extreme_lower\"},\n",
    "                                    {**op, key: float(hi), \"source\":\"extreme_upper\"}])\n",
    "                else:\n",
    "                    bundles.append([{**op}])\n",
    "            per_tf_opts.append([{\"ops\":[dict(b) for b in combo]} for combo in product(*bundles)] if any_b else [{}])\n",
    "        elif tt == \"split\":\n",
    "            outs = []\n",
    "            for o in t[\"outputs\"]:\n",
    "                lo, hi = float(o[\"lower\"]), float(o[\"upper\"])\n",
    "                name = o[\"name\"]\n",
    "                outs.append([{ \"name\": name, \"ratio\": lo, \"source\":\"extreme_lower\"}] if abs(hi-lo)<1e-12\n",
    "                             else [{ \"name\": name, \"ratio\": lo, \"source\":\"extreme_lower\"},\n",
    "                                   { \"name\": name, \"ratio\": hi, \"source\":\"extreme_upper\"}])\n",
    "            per_tf_opts.append([{\"outputs\": list(combo)} for combo in product(*outs)])\n",
    "        elif tt == \"build_point\":\n",
    "            mg_sets = []\n",
    "            for var, meta in t[\"mgL_values\"].items():\n",
    "                lo, hi = meta.get(\"lower\"), meta.get(\"upper\")\n",
    "                if _has_bounds(lo, hi):\n",
    "                    mg_sets.append([{var: {\"mgL\": float(lo), \"source\":\"extreme_lower\"}},\n",
    "                                    {var: {\"mgL\": float(hi), \"source\":\"extreme_upper\"}}])\n",
    "                else:\n",
    "                    mg_sets.append([{var: {\"mgL\": float(meta.get(\"mean\", 0.0)), \"source\":\"mean\"}}])\n",
    "            combos = []\n",
    "            for combo in product(*mg_sets):\n",
    "                merged = {}\n",
    "                for d in combo: merged.update(d)\n",
    "                combos.append({\"mgL_values\": merged})\n",
    "            per_tf_opts.append(combos)\n",
    "        else:\n",
    "            per_tf_opts.append([{}])\n",
    "    return [list(c) for c in product(*per_tf_opts)]\n",
    "\n",
    "def build_random_overrides(MC_SPEC, n_draws, seed=0):\n",
    "    import random; rnd = random.Random(seed)\n",
    "    draws = []\n",
    "    for _ in range(n_draws):\n",
    "        per_tf = []\n",
    "        for t in MC_SPEC[\"transforms\"]:\n",
    "            tt = t[\"type\"]\n",
    "            if tt == \"ops\":\n",
    "                bundle = []\n",
    "                for op in t[\"ops\"]:\n",
    "                    kind = op.get(\"op\",\"mul\"); key = _op_param_name(kind)\n",
    "                    lo, hi = op.get(\"lower\"), op.get(\"upper\")\n",
    "                    if lo is not None and hi is not None:\n",
    "                        bundle.append({**op, key: rnd.uniform(float(lo), float(hi)), \"source\":\"random\"})\n",
    "                    else:\n",
    "                        bundle.append(dict(op))\n",
    "                per_tf.append({\"ops\": bundle})\n",
    "            elif tt == \"split\":\n",
    "                outs = []\n",
    "                for o in t[\"outputs\"]:\n",
    "                    lo, hi = float(o[\"lower\"]), float(o[\"upper\"])\n",
    "                    r = lo if abs(hi-lo)<1e-12 else rnd.uniform(lo, hi)\n",
    "                    src = \"lower_equals_upper\" if abs(hi-lo)<1e-12 else \"random\"\n",
    "                    outs.append({\"name\": o[\"name\"], \"ratio\": r, \"source\": src})\n",
    "                per_tf.append({\"outputs\": outs})\n",
    "            elif tt == \"build_point\":\n",
    "                mg = {}\n",
    "                for var, meta in t[\"mgL_values\"].items():\n",
    "                    lo, hi = meta.get(\"lower\"), meta.get(\"upper\")\n",
    "                    if lo is not None and hi is not None:\n",
    "                        mg[var] = {\"mgL\": rnd.uniform(float(lo), float(hi)), \"source\":\"random\"}\n",
    "                    else:\n",
    "                        mg[var] = {\"mgL\": float(meta.get(\"mean\", 0.0)), \"source\":\"mean\"}\n",
    "                per_tf.append({\"mgL_values\": mg})\n",
    "            else:\n",
    "                per_tf.append({})\n",
    "        draws.append(per_tf)\n",
    "    return draws\n",
    "\n",
    "def build_mean_overrides(MC_SPEC):\n",
    "    per_tf = []\n",
    "    for t in MC_SPEC[\"transforms\"]:\n",
    "        tt = t[\"type\"]\n",
    "        if tt == \"ops\":\n",
    "            bundle = []\n",
    "            for op in t[\"ops\"]:\n",
    "                kind = op.get(\"op\",\"mul\"); key = _op_param_name(kind)\n",
    "                mean = op.get(\"mean\")\n",
    "                bundle.append({**op, key: float(mean) if mean is not None else op.get(key), \"source\":\"mean\"})\n",
    "            per_tf.append({\"ops\": bundle})\n",
    "        elif tt == \"split\":\n",
    "            outs = [{\"name\": o[\"name\"], \"ratio\": float(o[\"mean\"]), \"source\":\"mean\"} for o in t[\"outputs\"]]\n",
    "            per_tf.append({\"outputs\": outs})\n",
    "        elif tt == \"build_point\":\n",
    "            mg = {var: {\"mgL\": float(meta.get(\"mean\", 0.0)), \"source\":\"mean\"} for var, meta in t[\"mgL_values\"].items()}\n",
    "            per_tf.append({\"mgL_values\": mg})\n",
    "        else:\n",
    "            per_tf.append({})\n",
    "    return [per_tf]\n",
    "\n",
    "MODE = MC_SPEC[\"mode\"].strip().lower()\n",
    "if MODE == \"extreme\":\n",
    "    per_realization_params = build_extreme_overrides_from_spec(MC_SPEC)\n",
    "elif MODE == \"random\":\n",
    "    per_realization_params = build_random_overrides_from_spec(MC_SPEC, MC_SPEC.get(\"draws\", 1), seed=0)\n",
    "elif MODE == \"mean\":\n",
    "    per_realization_params = build_mean_overrides_from_spec(MC_SPEC)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown mode: {MODE}\")\n",
    "\n",
    "# ------------------ 4) Run MC (write CHMs only) ------------------\n",
    "RUN_MODEL = False\n",
    "\n",
    "results = run_monte_carlo(\n",
    "    N=len(per_realization_params),\n",
    "    base_txtinout=base_txtinout_p,\n",
    "    realization_root=realizations_root_p,\n",
    "    results_root=results_root_p,\n",
    "    link_file_regexes=[r\"^[0-9]+\\.chm$\"],\n",
    "    outputs_to_copy=[\"output.std\", \"*.rch\"],  # unused when RUN_MODEL=False\n",
    "    aggregator=lambda: read_n_p_means_from_csv_to_df(\n",
    "        csv_output,\n",
    "        id_col=\"HRU_GIS\",\n",
    "        n_col=\"mean_Nitrogeno_total_porcent_resample_Rediam\",\n",
    "        p_col=\"mean_Fosforo_mg_100g_P205_rediam\",\n",
    "    ),\n",
    "    transforms=transforms,\n",
    "    transforms_params=transforms_params,\n",
    "    per_realization_params=per_realization_params,\n",
    "    exe_path=None,\n",
    "    seed=0,\n",
    "    expect_plus=False,\n",
    "    config=cfg,\n",
    "    include_base_run=False,\n",
    "    create_workspace_copy=True,\n",
    "    force_recreate_workspace=True,\n",
    "    report=True,\n",
    "    run_model=RUN_MODEL,\n",
    "    upstream_inputs=upstream,\n",
    "    manifest_file=manifest_file if manifest_file.exists() else None,\n",
    "    auto_attach_manifest=True,\n",
    ")\n",
    "\n",
    "ok = sum(1 for r in results if r.success)\n",
    "run_id = results[0].run_id if results else -1\n",
    "print(f\"Created {len(results)} realizations; {ok} succeeded. run_id={run_id}\")\n",
    "for r in results:\n",
    "    print(f\"- {r.name}: id={r.realization_id} run_id={r.run_id} success={r.success} folder={r.folder}\")\n",
    "\n",
    "# ------------------ 5) Concise run + realization summaries ------------------\n",
    "print(\"\\n=== Monte Carlo run summary ===\")\n",
    "print(summarize_run(run_id))\n",
    "\n",
    "if results:\n",
    "    one_id = results[0].realization_id\n",
    "    print(f\"\\n=== Single realization report (id={one_id}) ===\")\n",
    "    print(realization_report(one_id))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
