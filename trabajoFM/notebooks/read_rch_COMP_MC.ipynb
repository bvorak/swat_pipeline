{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4af045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install seaborn\n",
    "#!pip install plotly\n",
    "\n",
    "#!pip install nbformat\n",
    "\n",
    "#!pip install jupyter\n",
    "#!pip install anywidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb91631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import arcpy\n",
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# Ensure the project root (parent of this folder) is importable\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "from python_pipeline_scripts import utils, runner\n",
    "config = utils.load_config(Path().resolve().parent / 'config' / 'config.yaml')\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c166c4",
   "metadata": {},
   "source": [
    "## One-Stop Function to parse .rch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb029800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "DEFAULT_RCH_COLUMNS = [\n",
    "    \"object type\",\"RCH\",\"GIS\",\"MON\",\"AREAkm2\",\"FLOW_INcms\",\"FLOW_OUTcmscms\",\"EVAPcms\",\"TLOSScms\",\n",
    "    \"SED_INtons\",\"SED_OUTtons\",\"SEDCONCmg/L\",\"ORGN_INkg\",\"ORGN_OUTkg\",\"ORGP_INkg\",\"ORGP_OUTkg\",\n",
    "    \"NO3_INkg\",\"NO3_OUTkg\",\"NH4_INkg\",\"NH4_OUTkg\",\"NO2_INkg\",\"NO2_OUTkg\",\"MINP_INkg\",\"MINP_OUTkg\",\n",
    "    \"CHLA_INkg\",\"CHLA_OUTkg\",\"CBOD_INkg\",\"CBOD_OUTkg\",\"DISOX_INkg\",\"DISOX_OUTkg\",\"SOLPST_INmg\",\n",
    "    \"SOLPST_OUTmg\",\"SORPST_INmg\",\"SORPST_OUTmg\",\"REACTPSTmg\",\"VOLPSTmg\",\"SETTLPSTmg\",\"RESUSP_PSTmg\",\n",
    "    \"DIFFUSEPSTmg\",\"REACBEDPSTmg\",\"BURYPSTmg\",\"BED_PSTmg\",\"BACTP_OUTct\",\"BACTLP_OUTct\",\"CMETAL#1kg\",\n",
    "    \"CMETAL#2kg\",\"CMETAL#3kg\",\"TOT_Nkg\",\"TOT_Pkg\",\"NO3ConcMg/l\",\"WTMPdegc\",\"Salt1\",\"Salt2\",\"Salt3\",\n",
    "    \"Salt4\",\"Salt5\",\"Salt6\",\"Salt7\",\"Salt8\",\"Salt9\",\"Salt10\",\"SAR\",\"EC\"\n",
    "]\n",
    "\n",
    "DEFAULT_DROP_COLS = [\"object type\",\"total_days\",\"GIS\",\"MON\",\"AREAkm2\",\"YEAR\"]\n",
    "\n",
    "def load_output_rch(\n",
    "    file_path: str,\n",
    "    cio_file: str,\n",
    "    *,\n",
    "    columns: list[str] = None,\n",
    "    skiprows: int = 9,\n",
    "    group_size: int = 17,        # rows per day in output.rch (typical)\n",
    "    add_area_ha: bool = True,\n",
    "    hectare_per_km2: float = 100.0,\n",
    "    drop_cols: list[str] = None,\n",
    "    reorder_date_cols: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load SWAT output.rch, attach datetime based on file.cio, compute area_ha, and tidy columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to output.rch\n",
    "    cio_file : str\n",
    "        Path to file.cio (used to derive simulation start date)\n",
    "    columns : list[str], optional\n",
    "        Column names for output.rch; defaults to DEFAULT_RCH_COLUMNS\n",
    "    skiprows : int, optional\n",
    "        Lines to skip before header/data (default 9 for SWAT outputs)\n",
    "    group_size : int, optional\n",
    "        Number of rows per simulated day in output.rch (default 17)\n",
    "    add_area_ha : bool, optional\n",
    "        If True, adds area_ha = AREAkm2 * hectare_per_km2\n",
    "    hectare_per_km2 : float, optional\n",
    "        Conversion factor (default 100 ha per km²)\n",
    "    drop_cols : list[str], optional\n",
    "        Columns to drop at the end (default DEFAULT_DROP_COLS)\n",
    "    reorder_date_cols : bool, optional\n",
    "        If True, moves 'date' to col 3 and 'YEAR' to col 4 (0-based)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Tidy DataFrame with date, optional area_ha, and dropped columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- helpers to read cio ----\n",
    "    def _getModelParameter(param: str, parameterfile: str) -> str | None:\n",
    "        with open(parameterfile, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                if param in line:\n",
    "                    # value expected before first '|'\n",
    "                    return line.partition(\"|\")[0].strip()\n",
    "        return None\n",
    "\n",
    "    def _getStartDate(swatiofile: str) -> date:\n",
    "        skip_year = int(_getModelParameter(\"NYSKIP\", swatiofile))\n",
    "        sim_year = int(_getModelParameter(\"NBYR\", swatiofile))\n",
    "        start_year = int(_getModelParameter(\"IYR\", swatiofile))\n",
    "        start_day = int(_getModelParameter(\"IDAF\", swatiofile))\n",
    "        # first day of (start_year + skip_year) plus (start_day - 1)\n",
    "        return date(start_year + skip_year, 1, 1) + timedelta(days=start_day - 1)\n",
    "\n",
    "    # ---- defaults ----\n",
    "    if columns is None:\n",
    "        columns = DEFAULT_RCH_COLUMNS\n",
    "    if drop_cols is None:\n",
    "        drop_cols = DEFAULT_DROP_COLS\n",
    "\n",
    "    # ---- read output.rch ----\n",
    "    df = pd.read_csv(file_path, sep=r\"\\s+\", skiprows=skiprows, header=None, names=columns, engine=\"python\")\n",
    "\n",
    "    # ---- create total_days from row index / group_size ----\n",
    "    df.index.name = \"total_days\"\n",
    "    df.reset_index(drop=False, inplace=True)\n",
    "    if group_size <= 0:\n",
    "        raise ValueError(\"group_size must be > 0\")\n",
    "    df[\"total_days\"] = df[\"total_days\"] // group_size\n",
    "\n",
    "    # ---- compute date & YEAR from cio ----\n",
    "    start_date = _getStartDate(cio_file)\n",
    "    df[\"date\"] = df[\"total_days\"].apply(lambda d: start_date + timedelta(days=int(d)))\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"YEAR\"] = df[\"date\"].dt.year\n",
    "\n",
    "    # ---- reorder date/YEAR columns if desired ----\n",
    "    if reorder_date_cols:\n",
    "        # insert 'date' at position 3 and 'YEAR' at position 4 (0-based)\n",
    "        df.insert(3, \"date\", df.pop(\"date\"))\n",
    "        df.insert(4, \"YEAR\", df.pop(\"YEAR\"))\n",
    "\n",
    "    # ---- add area_ha if requested ----\n",
    "    if add_area_ha:\n",
    "        if \"AREAkm2\" not in df.columns:\n",
    "            raise KeyError(\"AREAkm2 column not found; cannot compute area_ha.\")\n",
    "        df[\"area_ha\"] = df[\"AREAkm2\"] * hectare_per_km2\n",
    "        # place area_ha after AREAkm2 (which is index 6 after inserts; but robustly reinsert)\n",
    "        # insert at 7 like your original\n",
    "        df.insert(7, \"area_ha\", df.pop(\"area_ha\"))\n",
    "\n",
    "    # ---- final tidy: drop columns ----\n",
    "    to_drop = [c for c in drop_cols if c in df.columns]\n",
    "    df = df.drop(columns=to_drop)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f20e4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_multiple_rch_from_folders(base_folders: list[str], **kwargs) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads output.rch and file.cio from multiple SWAT TxtInOut base folders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_folders : list[str]\n",
    "        List of paths to TxtInOut folders.\n",
    "    **kwargs :\n",
    "        Additional keyword arguments to pass to load_output_rch().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, pd.DataFrame]\n",
    "        Dictionary mapping parent folder names to loaded DataFrames.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for folder in base_folders:\n",
    "        # Normalize path\n",
    "        folder = os.path.abspath(folder)\n",
    "        parent_folder = os.path.dirname(folder)\n",
    "        if \"txtinout\" in os.path.basename(folder).lower():\n",
    "            realization_name = f\"rch_{os.path.basename(parent_folder)}\"\n",
    "        else:\n",
    "            realization_name = f\"rch_{os.path.basename(folder)}\"\n",
    "        print(f\"Loading from folder: {folder} as {realization_name}\")\n",
    "\n",
    "        # Expected files\n",
    "        output_rch_path = os.path.join(folder, \"output.rch\")\n",
    "        cio_path = os.path.join(folder, \"file.cio\")\n",
    "\n",
    "        # Safety check\n",
    "        if not os.path.isfile(output_rch_path):\n",
    "            raise FileNotFoundError(f\"output.rch not found in {folder}\")\n",
    "        if not os.path.isfile(cio_path):\n",
    "            raise FileNotFoundError(f\"file.cio not found in {folder}\")\n",
    "\n",
    "        # Load using the previous function\n",
    "        df = load_output_rch(file_path=output_rch_path, cio_file=cio_path, **kwargs)\n",
    "\n",
    "        results[realization_name] = df\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def compare_dfs(df1: pd.DataFrame, df2: pd.DataFrame):\n",
    "    # Only compare numeric columns\n",
    "    df1_numeric = df1.select_dtypes(include=[np.number])\n",
    "    df2_numeric = df2.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Handle column name differences (e.g., FLOW_OUTcms vs FLOW_OUTcmscms)\n",
    "    col_map = {\n",
    "        \"FLOW_OUTcms\": \"FLOW_OUTcmscms\",\n",
    "        \"FLOW_OUTcmscms\": \"FLOW_OUTcms\"\n",
    "    }\n",
    "    df1_cols = set(df1_numeric.columns)\n",
    "    df2_cols = set(df2_numeric.columns)\n",
    "\n",
    "    # Prepare lists of columns to compare\n",
    "    common_cols = [c for c in df1_numeric.columns if c in df2_numeric.columns and c not in col_map]\n",
    "    mapped_comparisons = []\n",
    "    for c1, c2 in col_map.items():\n",
    "        if c1 in df1_cols and c2 in df2_cols:\n",
    "            mapped_comparisons.append((c1, c2))\n",
    "        elif c2 in df1_cols and c1 in df2_cols:\n",
    "            mapped_comparisons.append((c2, c1))\n",
    "\n",
    "    # Align DataFrames by columns\n",
    "    df1_common = df1_numeric[common_cols]\n",
    "    df2_common = df2_numeric[common_cols]\n",
    "\n",
    "    # Compare common columns directly\n",
    "    if df1_common.shape != df2_common.shape:\n",
    "        raise ValueError(\"DataFrames must have the same shape for direct comparison.\")\n",
    "\n",
    "    diff_mask = df1_common != df2_common\n",
    "    any_diff = diff_mask.any().any()\n",
    "\n",
    "    # Metrics for common columns\n",
    "    abs_diff = (df1_common - df2_common).abs()\n",
    "    mean_abs_diff = abs_diff.mean()\n",
    "    max_abs_diff = abs_diff.max()\n",
    "    mean_rel_diff = ((abs_diff / (df1_common.replace(0, np.nan))).mean()).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Compare mapped columns\n",
    "    mapped_diff_columns = []\n",
    "    mapped_diff_counts = {}\n",
    "    mapped_mean_abs_diff = {}\n",
    "    mapped_max_abs_diff = {}\n",
    "    mapped_mean_rel_diff = {}\n",
    "    for c1, c2 in mapped_comparisons:\n",
    "        col_diff_mask = df1_numeric[c1] != df2_numeric[c2]\n",
    "        if col_diff_mask.any():\n",
    "            mapped_diff_columns.append(f\"{c1} vs {c2}\")\n",
    "            mapped_diff_counts[f\"{c1} vs {c2}\"] = int(col_diff_mask.sum())\n",
    "            abs_diff_col = (df1_numeric[c1] - df2_numeric[c2]).abs()\n",
    "            mapped_mean_abs_diff[f\"{c1} vs {c2}\"] = abs_diff_col.mean()\n",
    "            mapped_max_abs_diff[f\"{c1} vs {c2}\"] = abs_diff_col.max()\n",
    "            mapped_mean_rel_diff[f\"{c1} vs {c2}\"] = (abs_diff_col / df1_numeric[c1].replace(0, np.nan)).mean()\n",
    "            any_diff = True\n",
    "\n",
    "    # Columns with at least one difference\n",
    "    diff_columns = diff_mask.any(axis=0)\n",
    "    diff_counts = diff_mask.sum(axis=0)[diff_columns]\n",
    "\n",
    "    # Collect metrics for columns with differences\n",
    "    metrics = {}\n",
    "    for col in diff_columns.index[diff_columns]:\n",
    "        metrics[col] = {\n",
    "            \"count\": int(diff_counts[col]),\n",
    "            \"mean_abs_diff\": float(mean_abs_diff[col]),\n",
    "            \"max_abs_diff\": float(max_abs_diff[col]),\n",
    "            \"mean_rel_diff\": float(mean_rel_diff[col]) if col in mean_rel_diff else None\n",
    "        }\n",
    "    for col in mapped_diff_columns:\n",
    "        metrics[col] = {\n",
    "            \"count\": mapped_diff_counts[col],\n",
    "            \"mean_abs_diff\": mapped_mean_abs_diff[col],\n",
    "            \"max_abs_diff\": mapped_max_abs_diff[col],\n",
    "            \"mean_rel_diff\": mapped_mean_rel_diff[col]\n",
    "        }\n",
    "\n",
    "    # Print easy to read stats\n",
    "    print(\"Comparison Summary\")\n",
    "    print(\"==================\")\n",
    "    print(f\"Any difference: {any_diff}\")\n",
    "    print(f\"Number of numeric columns with differences: {int(diff_columns.sum()) + len(mapped_diff_columns)}\")\n",
    "    print(\"Numeric columns with differences:\")\n",
    "    for col in diff_columns.index[diff_columns]:\n",
    "        m = metrics[col]\n",
    "        print(f\"  {col}: count={m['count']}, mean_abs_diff={m['mean_abs_diff']:.4g}, max_abs_diff={m['max_abs_diff']:.4g}, mean_rel_diff={m['mean_rel_diff']:.4g}\")\n",
    "    for col in mapped_diff_columns:\n",
    "        m = metrics[col]\n",
    "        print(f\"  {col}: count={m['count']}, mean_abs_diff={m['mean_abs_diff']:.4g}, max_abs_diff={m['max_abs_diff']:.4g}, mean_rel_diff={m['mean_rel_diff']:.4g}\")\n",
    "\n",
    "    result = {\n",
    "        \"any_difference\": any_diff,\n",
    "        \"n_diff_columns\": int(diff_columns.sum()) + len(mapped_diff_columns),\n",
    "        \"diff_columns\": diff_columns.index[diff_columns].tolist() + mapped_diff_columns,\n",
    "        \"diff_counts\": {**diff_counts.to_dict(), **mapped_diff_counts},\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16cc8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_run_folders(run_number, path=r\"C:\\SWAT\\RSWAT\\cubillas\\mc_results\"):\n",
    "    \"\"\"\n",
    "    Find folders in the given path that match the pattern:\n",
    "    runXXXXXX_realYYYYYY_*\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    run_number : int\n",
    "        The run number to match (will be zero-padded to 6 digits).\n",
    "    path : str, optional\n",
    "        The folder path to search in. Defaults to \n",
    "        'C:\\\\SWAT\\\\RSWAT\\\\cubillas\\\\mc_results'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        A list of matching folder names.\n",
    "    \"\"\"\n",
    "    # Format the number as 6 digits with leading zeros\n",
    "    run_str = f\"run{run_number:06d}_\"\n",
    "    \n",
    "    try:\n",
    "        # List all entries in the path\n",
    "        all_entries = os.listdir(path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Path '{path}' does not exist.\")\n",
    "        return []\n",
    "    \n",
    "    # Keep only directories that start with the correct run string\n",
    "    matching_folders = [\n",
    "        os.path.join(path, folder) for folder in all_entries\n",
    "        if os.path.isdir(os.path.join(path, folder)) and folder.startswith(run_str)\n",
    "    ]\n",
    "    \n",
    "    return matching_folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ce18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Dict, Any\n",
    "import pickle\n",
    "\n",
    "def _coerce_to_dict(obj: Any, run: int) -> Dict[str, Any]:\n",
    "    \"\"\"Make sure we hand back a dict no matter what was stored.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return obj\n",
    "    if isinstance(obj, list):\n",
    "        # common patterns: list of (name, df) or list of dfs\n",
    "        try:\n",
    "            if all(isinstance(x, tuple) and len(x) == 2 for x in obj):\n",
    "                return dict(obj)  # [(key, df), ...]\n",
    "        except Exception:\n",
    "            pass\n",
    "        # fallback: enumerate\n",
    "        return {f\"run{run}_sim{i}\": x for i, x in enumerate(obj)}\n",
    "    # last resort: wrap single object\n",
    "    return {f\"run{run}\": obj}\n",
    "\n",
    "def load_or_build_dfs_for_runs(\n",
    "    runs: int | Iterable[int],\n",
    "    *,\n",
    "    pickle_name_fmt: str = \"all_dfs_mc_run_{run}.pkl\",\n",
    "    force_rebuild: bool = False,\n",
    "    save_pickle: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    For each run:\n",
    "      - Look in first folder from find_run_folders(run) for a pickle.\n",
    "      - Load it unless force_rebuild; otherwise build with load_multiple_rch_from_folders.\n",
    "      - Coerce result to a dict (compat with old pickles returning lists), then merge.\n",
    "    Returns ONE merged dict across all runs.\n",
    "    \"\"\"\n",
    "    run_list = [runs] if isinstance(runs, int) else list(runs)\n",
    "    merged: Dict[str, Any] = {}\n",
    "\n",
    "    for run in run_list:\n",
    "        folders = find_run_folders(run)\n",
    "        if not folders:\n",
    "            continue\n",
    "        first_folder = Path(folders[0])\n",
    "        pkl_path = first_folder / pickle_name_fmt.format(run=run)\n",
    "\n",
    "        run_obj = None\n",
    "        if not force_rebuild and pkl_path.exists():\n",
    "            try:\n",
    "                with open(pkl_path, \"rb\") as f:\n",
    "                    run_obj = pickle.load(f)\n",
    "            except Exception:\n",
    "                run_obj = None\n",
    "\n",
    "        if run_obj is None:\n",
    "            run_obj = load_multiple_rch_from_folders(folders)\n",
    "            if save_pickle:\n",
    "                try:\n",
    "                    with open(pkl_path, \"wb\") as f:\n",
    "                        pickle.dump(run_obj, f)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        run_dict = _coerce_to_dict(run_obj, run)\n",
    "        # if keys collide across runs, later runs overwrite earlier ones\n",
    "        merged.update(run_dict)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3aa2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_vars = [\"FLOW_INcms\",\"FLOW_OUTcms\",\"EVAPcms\",\"TLOSScms\", \n",
    "    \"SED_INtons\",\"SED_OUTtons\",\"SEDCONCmg/L\",\"ORGN_INkg\",\"ORGN_OUTkg\",\"ORGP_INkg\",\"ORGP_OUTkg\",\n",
    "    \"NO3_INkg\",\"NO3_OUTkg\",\"NH4_INkg\",\"NH4_OUTkg\",\"NO2_INkg\",\"NO2_OUTkg\",\"MINP_INkg\",\"MINP_OUTkg\",\n",
    "    \"CHLA_INkg\",\"CHLA_OUTkg\",\"CBOD_INkg\",\"CBOD_OUTkg\",\"DISOX_INkg\",\"DISOX_OUTkg\",\"SOLPST_INmg\",\n",
    "    \"SOLPST_OUTmg\",\"SORPST_INmg\",\"SORPST_OUTmg\",\"REACTPSTmg\",\"VOLPSTmg\",\"SETTLPSTmg\",\"RESUSP_PSTmg\",\n",
    "    \"DIFFUSEPSTmg\",\"REACBEDPSTmg\",\"BURYPSTmg\",\n",
    "    #\"BED_PSTmg\",\n",
    "    \"BACTP_OUTct\",\"BACTLP_OUTct\",\"CMETAL#1kg\",\n",
    "    \"CMETAL#2kg\",\"CMETAL#3kg\",\"TOT_Nkg\",\"TOT_Pkg\",\"NO3ConcMg/l\",\"WTMPdegc\",\n",
    "    #\"Salt1\",\"Salt2\",\"Salt3\",\"Salt4\",\"Salt5\",\"Salt6\",\"Salt7\",\"Salt8\",\"Salt9\",\"Salt10\",\n",
    "    #\"SAR\",\"EC\"\n",
    "]\n",
    "\n",
    "how_map_defaults_all = {\n",
    "    # Flow rates\n",
    "    \"FLOW_INcms\": \"mean\",\n",
    "    \"FLOW_OUTcms\": \"mean\",\n",
    "    \"EVAPcms\": \"mean\",\n",
    "    \"TLOSScms\": \"mean\",\n",
    "\n",
    "    # Sediment fluxes & concentrations\n",
    "    \"SED_INtons\": \"sum\",\n",
    "    \"SED_OUTtons\": \"sum\",\n",
    "    \"SEDCONCmg/L\": \"flow_weighted_mean\",\n",
    "\n",
    "    # Nutrient fluxes\n",
    "    \"ORGN_INkg\": \"sum\",\n",
    "    \"ORGN_OUTkg\": \"sum\",\n",
    "    \"ORGP_INkg\": \"sum\",\n",
    "    \"ORGP_OUTkg\": \"sum\",\n",
    "    \"NO3_INkg\": \"sum\",\n",
    "    \"NO3_OUTkg\": \"sum\",\n",
    "    \"NH4_INkg\": \"sum\",\n",
    "    \"NH4_OUTkg\": \"sum\",\n",
    "    \"NO2_INkg\": \"sum\",\n",
    "    \"NO2_OUTkg\": \"sum\",\n",
    "    \"MINP_INkg\": \"sum\",\n",
    "    \"MINP_OUTkg\": \"sum\",\n",
    "\n",
    "        # Totals\n",
    "    \"TOT_Nkg\": \"sum\",\n",
    "    \"TOT_Pkg\": \"sum\",\n",
    "\n",
    "    # Algae & BOD / DO fluxes\n",
    "    \"CHLA_INkg\": \"sum\",\n",
    "    \"CHLA_OUTkg\": \"sum\",\n",
    "    \"CBOD_INkg\": \"sum\",\n",
    "    \"CBOD_OUTkg\": \"sum\",\n",
    "    \"DISOX_INkg\": \"sum\",\n",
    "    \"DISOX_OUTkg\": \"sum\",\n",
    "\n",
    "    # Pesticide-related\n",
    "    \"SOLPST_INmg\": \"sum\",\n",
    "    \"SOLPST_OUTmg\": \"sum\",\n",
    "    \"SORPST_INmg\": \"sum\",\n",
    "    \"SORPST_OUTmg\": \"sum\",\n",
    "    \"REACTPSTmg\": \"sum\",\n",
    "    \"VOLPSTmg\": \"sum\",\n",
    "    \"SETTLPSTmg\": \"sum\",\n",
    "    \"RESUSP_PSTmg\": \"sum\",\n",
    "    \"DIFFUSEPSTmg\": \"sum\",\n",
    "    \"REACBEDPSTmg\": \"sum\",\n",
    "    \"BURYPSTmg\": \"sum\",\n",
    "    \"BED_PSTmg\": \"mean\",  # Bed storage → inventory\n",
    "\n",
    "    # Bacteria counts (flux over time)\n",
    "    \"BACTP_OUTct\": \"sum\",\n",
    "    \"BACTLP_OUTct\": \"sum\",\n",
    "\n",
    "    # Metals\n",
    "    \"CMETAL#1kg\": \"sum\",\n",
    "    \"CMETAL#2kg\": \"sum\",\n",
    "    \"CMETAL#3kg\": \"sum\",\n",
    "\n",
    "\n",
    "\n",
    "    # Concentrations & physical/chemical properties\n",
    "    \"NO3ConcMg/l\": \"flow_weighted_mean\",\n",
    "    \"WTMPdegc\": \"flow_weighted_mean\",\n",
    "    \"Salt1\": \"flow_weighted_mean\",\n",
    "    \"Salt2\": \"flow_weighted_mean\",\n",
    "    \"Salt3\": \"flow_weighted_mean\",\n",
    "    \"Salt4\": \"flow_weighted_mean\",\n",
    "    \"Salt5\": \"flow_weighted_mean\",\n",
    "    \"Salt6\": \"flow_weighted_mean\",\n",
    "    \"Salt7\": \"flow_weighted_mean\",\n",
    "    \"Salt8\": \"flow_weighted_mean\",\n",
    "    \"Salt9\": \"flow_weighted_mean\",\n",
    "    \"Salt10\": \"flow_weighted_mean\",\n",
    "    \"SAR\": \"flow_weighted_mean\",\n",
    "    \"EC\": \"flow_weighted_mean\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef86be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "swat_to_measured = {\n",
    "\n",
    "    # -------- Sediment fluxes & concentrations --------\n",
    "    \"SEDCONCmg/L\": {\n",
    "        \"100\": (\"SOLIDOS EN SUSPENSION\", \"# both are suspended solids concentrations (mg/L)\"),\n",
    "        \"90\": (\"FOSFORO TOTAL\", \"# much TP is sediment-associated; strong event co-variation\"),\n",
    "        \"70\": (\"DEMANDA QUIMICA DE OXIGENO\", \"# COD can increase with particulate/organic matter; indirect\"),\n",
    "    },\n",
    "\n",
    "    # ------------------- Nutrient fluxes -------------------\n",
    "\n",
    "    \"ORGN_OUTkg\": {\n",
    "        \"100\": (\"\", \"# organic N flux not directly measured\"),\n",
    "        \"90\": (\"NITROGENO KJELDAHL\", \"# TKN captures most of organic N (plus NH4)\"),\n",
    "        \"70\": (\"NITROGENO TOTAL\", \"# broader pool; weaker proxy for organic component\"),\n",
    "    },\n",
    "    \"ORGP_OUTkg\": {\n",
    "        \"100\": (\"\", \"# organic P flux not directly measured\"),\n",
    "        \"90\": (\"FOSFORO TOTAL\", \"# TP best available proxy for total non-dissolved P\"),\n",
    "        \"70\": (\"FOSFATOS\", \"# inorganic reactive P; complementary rather than equivalent\"),\n",
    "    },\n",
    "    \"NO3_OUTkg\": {\n",
    "        \"100\": (\"NITRATOS\", \"# same species; outflow flux vs measured concentration\"),\n",
    "        \"90\": (\"NITROGENO TOTAL\", \"# TN includes NO3\"),\n",
    "        \"70\": (\"NITRITOS\", \"# weaker association via nitrification/denitrification dynamics\"),\n",
    "    },\n",
    "\n",
    "    \"NH4_OUTkg\": {\n",
    "        \"100\": (\"AMONIO\", \"# same dissolved species (NH4+)\"),\n",
    "        \"90\": (\"NITROGENO KJELDAHL\", \"# TKN includes NH4\"),\n",
    "        \"70\": (\"NITROGENO TOTAL\", \"# TN includes NH4; weaker proxy\"),\n",
    "    },\n",
    "\n",
    "    \"NO2_OUTkg\": {\n",
    "        \"100\": (\"NITRITOS\", \"# same dissolved species (NO2-)\"),\n",
    "        \"90\": (\"NITRATOS\", \"# related via N redox cycling\"),\n",
    "        \"70\": (\"NITROGENO TOTAL\", \"# broad; weak proxy\"),\n",
    "    },\n",
    "    \"MINP_OUTkg\": {\n",
    "        \"100\": (\"FOSFATOS\", \"# orthophosphate ≈ dissolved inorganic P\"),\n",
    "        \"90\": (\"FOSFORO TOTAL\", \"# TP co-varies; not the same species\"),\n",
    "        \"70\": (\"SOLIDOS EN SUSPENSION\", \"# indirect via sorption/desorption with sediment\"),\n",
    "    },\n",
    "\n",
    "    # --------- Algae & BOD / DO fluxes ----------\n",
    "    \n",
    "    \"CHLA_OUTkg\": {\n",
    "        \"100\": (\"\", \"# chlorophyll-a not in measurement list\"),\n",
    "        \"90\": (\"CARBONO ORGANICO TOTAL\", \"# biomass–carbon linkage; indirect\"),\n",
    "        \"70\": (\"DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS\", \"# decay/oxygen demand linkage; weaker\"),\n",
    "    },\n",
    "\n",
    "    \"CBOD_OUTkg\": {\n",
    "        \"100\": (\"DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS\", \"# CBOD ≈ BOD5\"),\n",
    "        \"90\": (\"DEMANDA QUIMICA DE OXIGENO\", \"# COD as broader oxygen demand metric\"),\n",
    "        \"70\": (\"CARBONO ORGANICO TOTAL\", \"# TOC–oxygen demand linkage; weaker\"),\n",
    "    },\n",
    "   \n",
    "    \"DISOX_OUTkg\": {\n",
    "        \"100\": (\"OXIGENO DISUELTO \\\"IN SITU\\\"\", \"# same analyte (DO)\"),\n",
    "        \"90\": (\"SATURACION DE OXIGENO DISUELTO \\\"IN SITU\\\"\", \"# closely related\"),\n",
    "        \"70\": (\"TEMPERATURA \\\"IN SITU\\\"\", \"# inverse solubility link; weak\"),\n",
    "    },\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------------------- Totals ----------------------------\n",
    "    \"TOT_Nkg\": {\n",
    "        \"100\": (\"NITROGENO KJELDAHL\", \"# organic N + NH4 subset of TN\"),\n",
    "        \"70\": (\"NITROGENO TOTAL\", \"# same aggregate analyte (all N forms), but almost no data\"),\n",
    "        \"90\": (\"NITRATOS\", \"# dominant dissolved N species in many rivers\"),\n",
    "    },\n",
    "    \"TOT_Pkg\": {\n",
    "        \"100\": (\"FOSFORO TOTAL\", \"# same aggregate analyte (all P forms)\"),\n",
    "        \"90\": (\"FOSFATOS\", \"# DIP is a major fraction in some conditions; not total\"),\n",
    "        \"70\": (\"SOLIDOS EN SUSPENSION\", \"# much TP is particulate-bound; indirect\"),\n",
    "    },\n",
    "\n",
    "    # ---- Concentrations & physical/chemical properties ----\n",
    "    \"NO3ConcMg/l\": {\n",
    "        \"100\": (\"NITRATOS\", \"# same dissolved species concentration\"),\n",
    "        \"90\": (\"NITROGENO TOTAL\", \"# contains NO3; partial tracking\"),\n",
    "        \"70\": (\"NITRITOS\", \"# related nitrogen species; weaker\"),\n",
    "    },\n",
    "    \"WTMPdegc\": {\n",
    "        \"100\": (\"TEMPERATURA \\\"IN SITU\\\"\", \"# same variable (°C)\"),\n",
    "        \"90\": (\"SATURACION DE OXIGENO DISUELTO \\\"IN SITU\\\"\", \"# temperature drives DO saturation; inverse relation\"),\n",
    "        \"70\": (\"OXIGENO DISUELTO \\\"IN SITU\\\"\", \"# DO concentration linked to temperature; indirect\"),\n",
    "    },\n",
    "\n",
    "    \"EC\": {\n",
    "        \"100\": (\"CONDUCTIVIDAD ELECTRICA A 20ºC \\\"IN SITU\\\"\", \"# same measurement (EC)\"),\n",
    "        \"90\": (\"NITRATOS\", \"# ions contribute to EC; partial proxy\"),\n",
    "        \"70\": (\"FOSFATOS\", \"# lesser ionic contributor; weak\"),\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618d1ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_vars_with_comments = [\n",
    "    \"TOT_Nkg\",         # Total nitrogen load — sum of all N forms, will increase.\n",
    "    \"TOT_Pkg\",         # Total phosphorus load — sum of all P forms, will increase.\n",
    "    \"MINP_OUTkg\",      # Mineral P load — soluble phosphate, highly bioavailable.\n",
    "    \"ORGP_OUTkg\",      # Organic phosphorus load — particulate P from wastewater.\n",
    "    \"ORGN_OUTkg\",      # Organic nitrogen load — particulate N from wastewater.\n",
    "    \"NO3_OUTkg\",       # Nitrate load — may increase with lag; seasonal patterns important.\n",
    "    \"NH4_OUTkg\",       # Ammonium load — direct from effluent (big spike expected).\n",
    "    \"NO3ConcMg/l\",     # Nitrate concentration — can rise downstream after nitrification; flow-weighted mean.\n",
    "    \"SED_OUTtons\",     # Suspended solids — large TSS load increases sediment export.\n",
    "    \"SEDCONCmg/L\",     # Sediment concentration — turbidity impact; use flow-weighted mean.\n",
    "    \"CBOD_OUTkg\",      # Biochemical oxygen demand — strong increase, drives DO depletion.\n",
    "    \"DISOX_OUTkg\",     # Dissolved oxygen mass exported — expect decrease due to BOD and nitrification.\n",
    "    \"CHLA_OUTkg\"       # Chlorophyll-a load — algal biomass; can increase if nutrients + light allow.\n",
    "\n",
    "]\n",
    "\n",
    "#vars_to_compare = available_vars\n",
    "vars_to_compare = key_vars_with_comments\n",
    "how_map_defaults = how_map_defaults_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2264eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MEASURED DATA (OLD)\n",
    "df_cubillas_chem_measur_clean = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Pasca\\MDA_test_data\\df_cubillas_chem_measur_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0585f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ndef clean_and_mg_L_to_kg_per_day(\\n    df_samples: pd.DataFrame,\\n    df_flow: pd.DataFrame,\\n    sample_date_col: str = \"F_MUESTREO\",\\n    sample_value_col: str = \"RESULTADO\",\\n    flow_date_col: str = \"date\",\\n    flow_value_col: str = \"water_flow_m3_d_cubillas\",\\n    kg_col: str = \"kg_per_day\",\\n) -> pd.DataFrame:\\n\\n    # Add (or overwrite) a kg/day load column to df_samples.\\n\\n    # Assumptions:\\n    #   - df_samples[sample_value_col] is in mg/L.\\n    #   - df_flow[flow_value_col] is the flow in m^3/day.\\n    #   - We join flow to samples by (day) date.\\n\\n    # kg/day is computed as: (mg/L) * (m^3/day) * (1000 L/m^3) * (1 kg / 1e6 mg) = value * flow * 0.001\\n\\n    # Work on copies to avoid changing caller\\'s data\\n    s = df_samples.copy()\\n    f = df_flow.copy()\\n\\n    # --- Force types ---\\n    # Dates → datetime (floored to day)\\n    s[sample_date_col] = pd.to_datetime(s[sample_date_col], errors=\"coerce\").dt.floor(\"D\")\\n    f[flow_date_col]   = pd.to_datetime(f[flow_date_col],   errors=\"coerce\").dt.floor(\"D\")\\n\\n    # Numeric → float (0 if coercion fails)\\n    s[sample_value_col] = pd.to_numeric(s[sample_value_col], errors=\"coerce\").astype(float).fillna(0)\\n    # setting negative sample_value_col to zero\\n    s.loc[s[sample_value_col] < 0, sample_value_col] = 0\\n\\n    f[flow_value_col]   = pd.to_numeric(f[flow_value_col],   errors=\"coerce\").astype(float).fillna(0)\\n\\n\\n\\n    # If multiple flow rows per date, reduce to a single value (mean is a sensible default)\\n    f_reduced = (\\n        f[[flow_date_col, flow_value_col]]\\n        .groupby(flow_date_col, as_index=False)\\n        .mean(numeric_only=True)\\n    )\\n\\n    # --- Join flow onto samples by date ---\\n    merged = s.merge(\\n        f_reduced,\\n        left_on=sample_date_col,\\n        right_on=flow_date_col,\\n        how=\"left\",\\n        suffixes=(\"\", \"_flow\")\\n    )\\n\\n    # --- Compute kg/day ---\\n    # kg/day = (mg/L) * (m^3/day) * 0.001\\n    merged[kg_col] = merged[sample_value_col] * merged[flow_value_col] * 0.001\\n\\n    # Drop the join key from the right side to keep original schema tidy\\n    merged = merged.drop(columns=[flow_date_col])\\n\\n    return merged\\n '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\" \n",
    "def clean_and_mg_L_to_kg_per_day(\n",
    "    df_samples: pd.DataFrame,\n",
    "    df_flow: pd.DataFrame,\n",
    "    sample_date_col: str = \"F_MUESTREO\",\n",
    "    sample_value_col: str = \"RESULTADO\",\n",
    "    flow_date_col: str = \"date\",\n",
    "    flow_value_col: str = \"water_flow_m3_d_cubillas\",\n",
    "    kg_col: str = \"kg_per_day\",\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # Add (or overwrite) a kg/day load column to df_samples.\n",
    "\n",
    "    # Assumptions:\n",
    "    #   - df_samples[sample_value_col] is in mg/L.\n",
    "    #   - df_flow[flow_value_col] is the flow in m^3/day.\n",
    "    #   - We join flow to samples by (day) date.\n",
    "\n",
    "    # kg/day is computed as: (mg/L) * (m^3/day) * (1000 L/m^3) * (1 kg / 1e6 mg) = value * flow * 0.001\n",
    "    \n",
    "    # Work on copies to avoid changing caller's data\n",
    "    s = df_samples.copy()\n",
    "    f = df_flow.copy()\n",
    "\n",
    "    # --- Force types ---\n",
    "    # Dates → datetime (floored to day)\n",
    "    s[sample_date_col] = pd.to_datetime(s[sample_date_col], errors=\"coerce\").dt.floor(\"D\")\n",
    "    f[flow_date_col]   = pd.to_datetime(f[flow_date_col],   errors=\"coerce\").dt.floor(\"D\")\n",
    "\n",
    "    # Numeric → float (0 if coercion fails)\n",
    "    s[sample_value_col] = pd.to_numeric(s[sample_value_col], errors=\"coerce\").astype(float).fillna(0)\n",
    "    # setting negative sample_value_col to zero\n",
    "    s.loc[s[sample_value_col] < 0, sample_value_col] = 0\n",
    "    \n",
    "    f[flow_value_col]   = pd.to_numeric(f[flow_value_col],   errors=\"coerce\").astype(float).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "    # If multiple flow rows per date, reduce to a single value (mean is a sensible default)\n",
    "    f_reduced = (\n",
    "        f[[flow_date_col, flow_value_col]]\n",
    "        .groupby(flow_date_col, as_index=False)\n",
    "        .mean(numeric_only=True)\n",
    "    )\n",
    "\n",
    "    # --- Join flow onto samples by date ---\n",
    "    merged = s.merge(\n",
    "        f_reduced,\n",
    "        left_on=sample_date_col,\n",
    "        right_on=flow_date_col,\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_flow\")\n",
    "    )\n",
    "\n",
    "    # --- Compute kg/day ---\n",
    "    # kg/day = (mg/L) * (m^3/day) * 0.001\n",
    "    merged[kg_col] = merged[sample_value_col] * merged[flow_value_col] * 0.001\n",
    "\n",
    "    # Drop the join key from the right side to keep original schema tidy\n",
    "    merged = merged.drop(columns=[flow_date_col])\n",
    "\n",
    "    return merged\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30904705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rch_run000136_real000492_1']) dict_keys(['rch_run000141_real000499_1']) dict_keys(['rch_run000108_real000395_1']) dict_keys(['rch_run000142_real000500_1']) dict_keys(['rch_run000143_real000501_1']) dict_keys(['rch_run000144_real000502_1']) dict_keys(['rch_run000145_real000503_1']) dict_keys(['rch_run000140_real000497_1', 'rch_run000140_real000498_2']) dict_keys(['rch_run000117_real000404_1']) dict_keys(['rch_run000138_real000495_1']) dict_keys(['rch_run000134_real000490_1'])\n"
     ]
    }
   ],
   "source": [
    "#dict_81 = load_or_build_dfs_for_runs([81], force_rebuild=False)\n",
    "#dict_83 = load_or_build_dfs_for_runs([83], force_rebuild=False)\n",
    "#dict_91 = load_or_build_dfs_for_runs([91], force_rebuild=False)\n",
    "#dict_92 = load_or_build_dfs_for_runs([92], force_rebuild=False)\n",
    "#dict_106 = load_or_build_dfs_for_runs([106], force_rebuild=False)\n",
    "#dict_107 = load_or_build_dfs_for_runs([107], force_rebuild=False)\n",
    "dict_108 = load_or_build_dfs_for_runs([108], force_rebuild=False)\n",
    "#dict_109 = load_or_build_dfs_for_runs([109], force_rebuild=False)\n",
    "dict_117 = load_or_build_dfs_for_runs([117], force_rebuild=False)\n",
    "dict_134 = load_or_build_dfs_for_runs([134], force_rebuild=False)\n",
    "dict_136 = load_or_build_dfs_for_runs([136], force_rebuild=False)\n",
    "dict_138 = load_or_build_dfs_for_runs([138], force_rebuild=False)\n",
    "dict_140 = load_or_build_dfs_for_runs([140], force_rebuild=False)\n",
    "dict_141 = load_or_build_dfs_for_runs([141], force_rebuild=False)\n",
    "dict_142 = load_or_build_dfs_for_runs([142], force_rebuild=False)\n",
    "dict_143 = load_or_build_dfs_for_runs([143], force_rebuild=False)\n",
    "dict_144 = load_or_build_dfs_for_runs([144], force_rebuild=False)\n",
    "dict_145 = load_or_build_dfs_for_runs([145], force_rebuild=False)\n",
    "dict_155 = load_or_build_dfs_for_runs([155], force_rebuild=False)\n",
    "#dict_BASE_orig = load_multiple_rch_from_folders([r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_set-219\\TxtInOut_1\"])\n",
    "#dict_BASE_recr_default_rswat = load_multiple_rch_from_folders([r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_set-219\\BASE recreated from arcswat default\\TxtInOut_1\"])\n",
    "\n",
    "print(dict_136.keys(), dict_141.keys(), dict_108.keys(), dict_142.keys(), dict_143.keys(), dict_144.keys(), dict_145.keys(), dict_140.keys(), dict_117.keys(), dict_138.keys(), dict_134.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7e8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_BASE_recr_default[\"rch_BASE recreated from arcswat default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dcb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(compare_dfs(dict_144['rch_run000144_real000502_1'], dict_BASE_recr_default_recr_python['rch_BASE recreated from arcswat default']))\n",
    "\n",
    "#print(compare_dfs(dict_91[\"rch_run000091_real000364_1\"], dict_92[\"rch_run000092_real000366_1\"]))\n",
    "#print(compare_dfs(dict_91[\"rch_run000091_real000365_2\"], dict_92[\"rch_run000092_real000367_2\"]))\n",
    "\n",
    "#print(compare_dfs(dict_107[\"rch_run000107_real000394_2\"], dict_107[\"rch_run000107_real000393_1\"]))\n",
    "#print(compare_dfs(dict_109[\"rch_run000109_real000396_1\"], dict_BASE_POINT_recreated[\"rch_TxtInOut_1_work\"]))\n",
    "\n",
    "\n",
    "#dfs_compare_different_point_load_runs = load_multiple_rch_from_folders([r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_POINT_set-219\\TxtInOut_1_work\\TxtInOut\", r\"C:\\SWAT\\RSWAT\\cubillas\\mc_results\\run000109_real000396_1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db31cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b40437cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Usuario\\\\OneDrive - UNIVERSIDAD DE HUELVA\\\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\\\cubillas_hru\\\\Scenarios\\\\Default\\\\TxtInOut', 'C:\\\\Users\\\\Usuario\\\\OneDrive - UNIVERSIDAD DE HUELVA\\\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\\\cubillas_hru\\\\Scenarios\\\\cubillas_original\\\\TxtInOut']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TxtInOut base folders\n",
    "OLD_base_folders = [\n",
    "    #r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_set-219\\TxtInOut_1\",\n",
    "    #r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_POINT_set-219\\TxtInOut_1\",\n",
    "    #r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_DIFFUSE_set-219\\TxtInOut_1\"\n",
    "    r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\cubillas_hru\\Scenarios\\Default\\TxtInOut\",\n",
    "    r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\cubillas_hru\\Scenarios\\cubillas_original\\TxtInOut\",\n",
    "\n",
    "]\n",
    "folders_to_compara = OLD_base_folders + find_run_folders(77)\n",
    "print(folders_to_compara)\n",
    "#dfs_base_vs_point = load_multiple_rch_from_folders(OLD_base_folders)\n",
    "#print(dfs_base_vs_point.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34a56b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tag_flow_outliers(\n",
    "    df_flow: pd.DataFrame,\n",
    "    *,\n",
    "    date_col: str = \"date\",\n",
    "    flow_col: str = \"water_flow_m3_d_cubillas\",\n",
    "    col_name: str = \"outliers\",\n",
    "    method: str = \"mad_log\",      # \"mad_log\" | \"iqr\" | \"quantile\"\n",
    "    sided: str = \"upper\",         # \"upper\" | \"both\"\n",
    "    k: float = 3.5,               # mad_log threshold (in robust-sd)\n",
    "    iqr_k: float = 1.5,           # IQR multiplier for IQR method\n",
    "    upper_q: float = 0.995,       # upper quantile for \"quantile\" method\n",
    "    lower_q: float = 0.005,       # lower quantile if sided=\"both\"\n",
    "    daily_reduce: str = \"sum\",    # \"sum\" | \"mean\"\n",
    "    inplace: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a boolean column marking extreme flow days. A sensible default is\n",
    "    method=\"mad_log\", sided=\"upper\", k=3.5 which flags unusually large flows.\n",
    "\n",
    "    - Reduces to daily resolution before tagging.\n",
    "    - 'sided=\"upper\"' flags only high-flow extremes; use \"both\" to also flag lows.\n",
    "    \"\"\"\n",
    "    df = df_flow if inplace else df_flow.copy()\n",
    "\n",
    "    # Normalize dates\n",
    "    d = df[[date_col, flow_col]].copy()\n",
    "    d[date_col] = pd.to_datetime(d[date_col], errors=\"coerce\").dt.floor(\"D\")\n",
    "    d[flow_col] = pd.to_numeric(d[flow_col], errors=\"coerce\").astype(float)\n",
    "\n",
    "    # Reduce duplicates per day\n",
    "    if daily_reduce == \"mean\":\n",
    "        daily = d.groupby(date_col, as_index=False)[flow_col].mean()\n",
    "    else:\n",
    "        daily = d.groupby(date_col, as_index=False)[flow_col].sum(min_count=1)\n",
    "\n",
    "    s = daily.set_index(date_col)[flow_col].sort_index()\n",
    "\n",
    "    # Choose method\n",
    "    method = str(method).lower()\n",
    "    sided = \"both\" if str(sided).lower() == \"both\" else \"upper\"\n",
    "\n",
    "    if method == \"mad_log\":\n",
    "        x = np.log1p(s.values)  # robust for heavy tails\n",
    "        med = np.nanmedian(x)\n",
    "        mad = np.nanmedian(np.abs(x - med))\n",
    "        robust_sigma = 1.4826 * mad if mad > 0 else np.nan\n",
    "        if np.isnan(robust_sigma) or robust_sigma == 0:\n",
    "            flags = np.zeros_like(x, dtype=bool)\n",
    "        else:\n",
    "            z = (x - med) / robust_sigma\n",
    "            if sided == \"both\":\n",
    "                flags = np.abs(z) > float(k)\n",
    "            else:\n",
    "                flags = z > float(k)\n",
    "    elif method == \"iqr\":\n",
    "        q1, q3 = np.nanpercentile(s.values, [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        lo = q1 - float(iqr_k) * iqr\n",
    "        hi = q3 + float(iqr_k) * iqr\n",
    "        if sided == \"both\":\n",
    "            flags = (s.values < lo) | (s.values > hi)\n",
    "        else:\n",
    "            flags = s.values > hi\n",
    "    elif method == \"quantile\":\n",
    "        hi = np.nanquantile(s.values, float(upper_q))\n",
    "        if sided == \"both\":\n",
    "            lo = np.nanquantile(s.values, float(lower_q))\n",
    "            flags = (s.values < lo) | (s.values > hi)\n",
    "        else:\n",
    "            flags = s.values > hi\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'mad_log', 'iqr', or 'quantile'.\")\n",
    "\n",
    "    out_days = pd.Series(flags, index=s.index, name=col_name)\n",
    "\n",
    "    # Attach to original df by daily date\n",
    "    map_days = out_days.reset_index().rename(columns={date_col: \"_day\"})\n",
    "    df[\"_day\"] = pd.to_datetime(df[date_col], errors=\"coerce\").dt.floor(\"D\")\n",
    "    df = df.merge(map_days, left_on=\"_day\", right_on=\"_day\", how=\"left\")\n",
    "    df[col_name] = df[col_name].fillna(False).astype(bool)\n",
    "    df.drop(columns=[\"_day\"], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f971e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load water flow and measurement data\n",
    "df_water_flow_m3_d_cubillas = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil GEO_INFO_POOL\\Data Zip inicial Francisco\\CHGxSAIH\\Embalses\\E45SAIHInflowQR_most_current_Francisco\\E45SAIHInflowQR.csv\", index_col=False)\n",
    "DMA_cubillas_measurements_131415_mg_L = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil GEO_INFO_POOL\\Input Data\\Water flow\\Ptos_MDA_Cubillas_131517_data_mgL.csv\")\n",
    "\n",
    "\n",
    "df_water_flow_m3_d_cubillas = tag_flow_outliers(\n",
    "    df_water_flow_m3_d_cubillas,\n",
    "    date_col=\"date\",\n",
    "    flow_col=\"water_flow_m3_d_cubillas\",\n",
    "    col_name=\"outliers\",\n",
    "    method=\"mad_log\",\n",
    "    sided=\"upper\",\n",
    "    k=1,\n",
    "    daily_reduce=\"sum\",\n",
    "    inplace=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e201d2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "water_flow_m3_d_cubillas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "doy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "smooth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "outliers",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "4ae92b8b-0644-4ea1-89eb-95a952203ac6",
       "rows": [
        [
         "0",
         "1955-03-02",
         "450000.0",
         "61",
         "364133.3333333333",
         "True"
        ],
        [
         "1",
         "1955-03-03",
         "0.0",
         "62",
         "352937.5",
         "False"
        ],
        [
         "2",
         "1955-03-04",
         "500000.0",
         "63",
         "348294.1176470588",
         "True"
        ],
        [
         "3",
         "1955-03-05",
         "324000.0",
         "64",
         "343388.8888888889",
         "True"
        ],
        [
         "4",
         "1955-03-06",
         "649000.0",
         "65",
         "343894.7368421053",
         "True"
        ],
        [
         "5",
         "1955-03-07",
         "495000.0",
         "66",
         "339800.0",
         "True"
        ],
        [
         "6",
         "1955-03-08",
         "421000.0",
         "67",
         "343523.8095238095",
         "True"
        ],
        [
         "7",
         "1955-03-09",
         "392000.0",
         "68",
         "344636.36363636365",
         "True"
        ],
        [
         "8",
         "1955-03-10",
         "391000.0",
         "69",
         "344869.5652173913",
         "True"
        ],
        [
         "9",
         "1955-03-11",
         "390000.0",
         "70",
         "348583.3333333333",
         "True"
        ],
        [
         "10",
         "1955-03-12",
         "350000.0",
         "71",
         "350640.0",
         "True"
        ],
        [
         "11",
         "1955-03-13",
         "0.0",
         "72",
         "352538.4615384616",
         "False"
        ],
        [
         "12",
         "1955-03-14",
         "350000.0",
         "73",
         "355222.22222222225",
         "True"
        ],
        [
         "13",
         "1955-03-15",
         "400000.0",
         "74",
         "352892.8571428572",
         "True"
        ],
        [
         "14",
         "1955-03-16",
         "350000.0",
         "75",
         "354862.0689655172",
         "True"
        ],
        [
         "15",
         "1955-03-17",
         "185000.0",
         "76",
         "354700.0",
         "False"
        ],
        [
         "16",
         "1955-03-18",
         "274000.0",
         "77",
         "351366.6666666667",
         "True"
        ],
        [
         "17",
         "1955-03-19",
         "260000.0",
         "78",
         "373866.6666666667",
         "True"
        ],
        [
         "18",
         "1955-03-20",
         "353000.0",
         "79",
         "370533.3333333333",
         "True"
        ],
        [
         "19",
         "1955-03-21",
         "262000.0",
         "80",
         "371400.0",
         "True"
        ],
        [
         "20",
         "1955-03-22",
         "418000.0",
         "81",
         "361100.0",
         "True"
        ],
        [
         "21",
         "1955-03-23",
         "368000.0",
         "82",
         "354600.0",
         "True"
        ],
        [
         "22",
         "1955-03-24",
         "350000.0",
         "83",
         "350200.0",
         "True"
        ],
        [
         "23",
         "1955-03-25",
         "434000.0",
         "84",
         "346433.3333333333",
         "True"
        ],
        [
         "24",
         "1955-03-26",
         "400000.0",
         "85",
         "342733.3333333333",
         "True"
        ],
        [
         "25",
         "1955-03-27",
         "400000.0",
         "86",
         "339100.0",
         "True"
        ],
        [
         "26",
         "1955-03-28",
         "425000.0",
         "87",
         "337066.6666666667",
         "True"
        ],
        [
         "27",
         "1955-03-29",
         "290000.0",
         "88",
         "346733.3333333333",
         "True"
        ],
        [
         "28",
         "1955-03-30",
         "410000.0",
         "89",
         "344366.6666666667",
         "True"
        ],
        [
         "29",
         "1955-03-31",
         "350000.0",
         "90",
         "338966.6666666667",
         "True"
        ],
        [
         "30",
         "1955-04-01",
         "350000.0",
         "91",
         "334000.0",
         "True"
        ],
        [
         "31",
         "1955-04-02",
         "675000.0",
         "92",
         "336766.6666666667",
         "True"
        ],
        [
         "32",
         "1955-04-03",
         "400000.0",
         "93",
         "334833.3333333333",
         "True"
        ],
        [
         "33",
         "1955-04-04",
         "350000.0",
         "94",
         "333700.0",
         "True"
        ],
        [
         "34",
         "1955-04-05",
         "340000.0",
         "95",
         "329466.6666666667",
         "True"
        ],
        [
         "35",
         "1955-04-06",
         "300000.0",
         "96",
         "328266.6666666667",
         "True"
        ],
        [
         "36",
         "1955-04-07",
         "289000.0",
         "97",
         "321533.3333333333",
         "True"
        ],
        [
         "37",
         "1955-04-08",
         "279000.0",
         "98",
         "316800.0",
         "True"
        ],
        [
         "38",
         "1955-04-09",
         "280000.0",
         "99",
         "309033.3333333333",
         "True"
        ],
        [
         "39",
         "1955-04-10",
         "281000.0",
         "100",
         "298500.0",
         "True"
        ],
        [
         "40",
         "1955-04-11",
         "289000.0",
         "101",
         "289033.3333333333",
         "True"
        ],
        [
         "41",
         "1955-04-12",
         "290000.0",
         "102",
         "285366.6666666667",
         "True"
        ],
        [
         "42",
         "1955-04-13",
         "279000.0",
         "103",
         "280866.6666666667",
         "True"
        ],
        [
         "43",
         "1955-04-14",
         "238000.0",
         "104",
         "280500.0",
         "False"
        ],
        [
         "44",
         "1955-04-15",
         "201000.0",
         "105",
         "276133.3333333333",
         "False"
        ],
        [
         "45",
         "1955-04-16",
         "268000.0",
         "106",
         "274100.0",
         "True"
        ],
        [
         "46",
         "1955-04-17",
         "216000.0",
         "107",
         "273166.6666666667",
         "False"
        ],
        [
         "47",
         "1955-04-18",
         "226000.0",
         "108",
         "258900.0",
         "False"
        ],
        [
         "48",
         "1955-04-19",
         "226000.0",
         "109",
         "252900.0",
         "False"
        ],
        [
         "49",
         "1955-04-20",
         "226000.0",
         "110",
         "248066.66666666663",
         "False"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 25491
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>water_flow_m3_d_cubillas</th>\n",
       "      <th>doy</th>\n",
       "      <th>smooth</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955-03-02</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>61</td>\n",
       "      <td>364133.333333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1955-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62</td>\n",
       "      <td>352937.500000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-03-04</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>63</td>\n",
       "      <td>348294.117647</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955-03-05</td>\n",
       "      <td>324000.0</td>\n",
       "      <td>64</td>\n",
       "      <td>343388.888889</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1955-03-06</td>\n",
       "      <td>649000.0</td>\n",
       "      <td>65</td>\n",
       "      <td>343894.736842</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>67670.0</td>\n",
       "      <td>362</td>\n",
       "      <td>74615.600000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25487</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>73120.0</td>\n",
       "      <td>363</td>\n",
       "      <td>74614.105263</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25488</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>78610.0</td>\n",
       "      <td>364</td>\n",
       "      <td>74256.388889</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25489</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>78323.0</td>\n",
       "      <td>365</td>\n",
       "      <td>73739.294118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25490</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>70435.0</td>\n",
       "      <td>1</td>\n",
       "      <td>73676.250000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25491 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  water_flow_m3_d_cubillas  doy         smooth  outliers\n",
       "0      1955-03-02                  450000.0   61  364133.333333      True\n",
       "1      1955-03-03                       0.0   62  352937.500000     False\n",
       "2      1955-03-04                  500000.0   63  348294.117647      True\n",
       "3      1955-03-05                  324000.0   64  343388.888889      True\n",
       "4      1955-03-06                  649000.0   65  343894.736842      True\n",
       "...           ...                       ...  ...            ...       ...\n",
       "25486  2024-12-27                   67670.0  362   74615.600000     False\n",
       "25487  2024-12-28                   73120.0  363   74614.105263     False\n",
       "25488  2024-12-29                   78610.0  364   74256.388889     False\n",
       "25489  2024-12-30                   78323.0  365   73739.294118     False\n",
       "25490  2025-01-01                   70435.0    1   73676.250000     False\n",
       "\n",
       "[25491 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_water_flow_m3_d_cubillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc3687a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Join_Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TARGET_FID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "est_estaci",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "COD_UE",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "COD_PUNTO_",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F_MUESTREO",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "NOMBRE",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RESULTADO",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "UNIDAD",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "COD_UE_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "COD_PUNTO1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "NOM_PUNTO_",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F_ALTA",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F_BAJA",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Activa",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "UTMX",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "UTMY",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HUSO",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DATUM",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OBSERVACIO",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Motivo_Cam",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Fecha_Camb",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Observac_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "OBJECTID_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRIDCODE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Subbasin",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Slo1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Len1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sll",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Csl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Wid1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Dep1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Long_",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Elev",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ElevMin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ElevMax",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Bname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Shape_Leng",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "HydroID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OutletID",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9dec92eb-56a1-46f2-bc37-2f5c21989596",
       "rows": [
        [
         "32",
         "1",
         "13832",
         "30303",
         "30303-O",
         "GV10090004",
         "09/10/97 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "38",
         "1",
         "13838",
         "30303",
         "30303-O",
         "GV10090004",
         "03/04/98 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "100",
         "1",
         "13900",
         "30303",
         "30303-O",
         "GV10090004",
         "03/11/04 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "105",
         "1",
         "13905",
         "30303",
         "30303-O",
         "GV10090004",
         "08/11/04 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "106",
         "1",
         "13906",
         "30303",
         "30303-O",
         "GV10090004",
         "09/15/04 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "112",
         "1",
         "13912",
         "30303",
         "30303-O",
         "GV10090004",
         "03/09/05 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "115",
         "1",
         "13915",
         "30303",
         "30303-O",
         "GV10090004",
         "06/15/05 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "116",
         "1",
         "13916",
         "30303",
         "30303-O",
         "GV10090004",
         "07/21/05 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "117",
         "1",
         "13917",
         "30303",
         "30303-O",
         "GV10090004",
         "08/18/05 0:00:00",
         "AMONIO",
         "LC",
         "mg NH4/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "464",
         "1",
         "14264",
         "30303",
         "30303-O",
         "GV10090004",
         "11/12/97 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "527",
         "1",
         "14327",
         "30303",
         "30303-O",
         "GV10090004",
         "03/13/03 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "529",
         "1",
         "14329",
         "30303",
         "30303-O",
         "GV10090004",
         "05/15/03 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "530",
         "1",
         "14330",
         "30303",
         "30303-O",
         "GV10090004",
         "06/11/03 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "534",
         "1",
         "14334",
         "30303",
         "30303-O",
         "GV10090004",
         "10/15/03 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "535",
         "1",
         "14335",
         "30303",
         "30303-O",
         "GV10090004",
         "11/11/03 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "536",
         "1",
         "14336",
         "30303",
         "30303-O",
         "GV10090004",
         "01/15/04 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "537",
         "1",
         "14337",
         "30303",
         "30303-O",
         "GV10090004",
         "02/11/04 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "538",
         "1",
         "14338",
         "30303",
         "30303-O",
         "GV10090004",
         "03/11/04 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "541",
         "1",
         "14341",
         "30303",
         "30303-O",
         "GV10090004",
         "06/17/04 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "543",
         "1",
         "14343",
         "30303",
         "30303-O",
         "GV10090004",
         "08/11/04 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "544",
         "1",
         "14344",
         "30303",
         "30303-O",
         "GV10090004",
         "09/15/04 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "546",
         "1",
         "14346",
         "30303",
         "30303-O",
         "GV10090004",
         "11/04/04 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "548",
         "1",
         "14348",
         "30303",
         "30303-O",
         "GV10090004",
         "01/20/05 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "554",
         "1",
         "14354",
         "30303",
         "30303-O",
         "GV10090004",
         "07/21/05 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "556",
         "1",
         "14356",
         "30303",
         "30303-O",
         "GV10090004",
         "09/08/05 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "558",
         "1",
         "14358",
         "30303",
         "30303-O",
         "GV10090004",
         "11/10/05 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "559",
         "1",
         "14359",
         "30303",
         "30303-O",
         "GV10090004",
         "12/01/05 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "561",
         "1",
         "14361",
         "30303",
         "30303-O",
         "GV10090004",
         "02/08/06 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "566",
         "1",
         "14366",
         "30303",
         "30303-O",
         "GV10090004",
         "07/18/06 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "567",
         "1",
         "14367",
         "30303",
         "30303-O",
         "GV10090004",
         "08/01/06 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "569",
         "1",
         "14369",
         "30303",
         "30303-O",
         "GV10090004",
         "10/24/06 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "572",
         "1",
         "14372",
         "30303",
         "30303-O",
         "GV10090004",
         "01/18/07 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "580",
         "1",
         "14380",
         "30303",
         "30303-O",
         "GV10090004",
         "09/17/07 0:00:00",
         "DEMANDA BIOQUIMICA DE OXIGENO 5 DIAS",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "645",
         "1",
         "14445",
         "30303",
         "30303-O",
         "GV10090004",
         "07/12/01 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "646",
         "1",
         "14446",
         "30303",
         "30303-O",
         "GV10090004",
         "11/22/01 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "647",
         "1",
         "14447",
         "30303",
         "30303-O",
         "GV10090004",
         "12/14/01 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "657",
         "1",
         "14457",
         "30303",
         "30303-O",
         "GV10090004",
         "07/10/03 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "658",
         "1",
         "14458",
         "30303",
         "30303-O",
         "GV10090004",
         "09/11/03 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "659",
         "1",
         "14459",
         "30303",
         "30303-O",
         "GV10090004",
         "11/11/03 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "661",
         "1",
         "14461",
         "30303",
         "30303-O",
         "GV10090004",
         "03/11/04 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "662",
         "1",
         "14462",
         "30303",
         "30303-O",
         "GV10090004",
         "05/13/04 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "663",
         "1",
         "14463",
         "30303",
         "30303-O",
         "GV10090004",
         "07/14/04 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "664",
         "1",
         "14464",
         "30303",
         "30303-O",
         "GV10090004",
         "09/15/04 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "665",
         "1",
         "14465",
         "30303",
         "30303-O",
         "GV10090004",
         "11/04/04 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "666",
         "1",
         "14466",
         "30303",
         "30303-O",
         "GV10090004",
         "01/20/05 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "667",
         "1",
         "14467",
         "30303",
         "30303-O",
         "GV10090004",
         "03/09/05 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "668",
         "1",
         "14468",
         "30303",
         "30303-O",
         "GV10090004",
         "05/04/05 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "669",
         "1",
         "14469",
         "30303",
         "30303-O",
         "GV10090004",
         "07/21/05 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "670",
         "1",
         "14470",
         "30303",
         "30303-O",
         "GV10090004",
         "09/08/05 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ],
        [
         "671",
         "1",
         "14471",
         "30303",
         "30303-O",
         "GV10090004",
         "11/10/05 0:00:00",
         "DEMANDA QUIMICA DE OXIGENO",
         "LC",
         "mg O2/l",
         " ",
         "GV10090004",
         "RIO CUBILLAS EMBALSE DE CUBILLAS",
         "10/02/90 0:00:00",
         "01/01/2100",
         "SI",
         "439472",
         "4125473",
         "30",
         "ETRS89",
         "NONE",
         "NONE",
         "01/01/00 0:00:00",
         "NONE",
         "15",
         "15",
         "15",
         "1666.5",
         "7.84445238113",
         "10363.656198",
         "60.9570252972",
         "1.43627895558",
         "6.97706712236",
         "0.400558064153",
         "37.2910961572",
         "-3.66448515689",
         "706.037444374",
         "606.0",
         "869.0",
         " ",
         "40000.0",
         "300015",
         "100001"
        ]
       ],
       "shape": {
        "columns": 42,
        "rows": 212
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>est_estaci</th>\n",
       "      <th>COD_UE</th>\n",
       "      <th>COD_PUNTO_</th>\n",
       "      <th>F_MUESTREO</th>\n",
       "      <th>NOMBRE</th>\n",
       "      <th>RESULTADO</th>\n",
       "      <th>UNIDAD</th>\n",
       "      <th>COD_UE_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Dep1</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Elev</th>\n",
       "      <th>ElevMin</th>\n",
       "      <th>ElevMax</th>\n",
       "      <th>Bname</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>HydroID</th>\n",
       "      <th>OutletID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>13832</td>\n",
       "      <td>30303</td>\n",
       "      <td>30303-O</td>\n",
       "      <td>GV10090004</td>\n",
       "      <td>09/10/97 0:00:00</td>\n",
       "      <td>AMONIO</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg NH4/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>37.291096</td>\n",
       "      <td>-3.664485</td>\n",
       "      <td>706.037444</td>\n",
       "      <td>606.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td></td>\n",
       "      <td>40000.0</td>\n",
       "      <td>300015</td>\n",
       "      <td>100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>13838</td>\n",
       "      <td>30303</td>\n",
       "      <td>30303-O</td>\n",
       "      <td>GV10090004</td>\n",
       "      <td>03/04/98 0:00:00</td>\n",
       "      <td>AMONIO</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg NH4/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>37.291096</td>\n",
       "      <td>-3.664485</td>\n",
       "      <td>706.037444</td>\n",
       "      <td>606.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td></td>\n",
       "      <td>40000.0</td>\n",
       "      <td>300015</td>\n",
       "      <td>100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>13900</td>\n",
       "      <td>30303</td>\n",
       "      <td>30303-O</td>\n",
       "      <td>GV10090004</td>\n",
       "      <td>03/11/04 0:00:00</td>\n",
       "      <td>AMONIO</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg NH4/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>37.291096</td>\n",
       "      <td>-3.664485</td>\n",
       "      <td>706.037444</td>\n",
       "      <td>606.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td></td>\n",
       "      <td>40000.0</td>\n",
       "      <td>300015</td>\n",
       "      <td>100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>13905</td>\n",
       "      <td>30303</td>\n",
       "      <td>30303-O</td>\n",
       "      <td>GV10090004</td>\n",
       "      <td>08/11/04 0:00:00</td>\n",
       "      <td>AMONIO</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg NH4/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>37.291096</td>\n",
       "      <td>-3.664485</td>\n",
       "      <td>706.037444</td>\n",
       "      <td>606.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td></td>\n",
       "      <td>40000.0</td>\n",
       "      <td>300015</td>\n",
       "      <td>100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>13906</td>\n",
       "      <td>30303</td>\n",
       "      <td>30303-O</td>\n",
       "      <td>GV10090004</td>\n",
       "      <td>09/15/04 0:00:00</td>\n",
       "      <td>AMONIO</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg NH4/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.400558</td>\n",
       "      <td>37.291096</td>\n",
       "      <td>-3.664485</td>\n",
       "      <td>706.037444</td>\n",
       "      <td>606.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td></td>\n",
       "      <td>40000.0</td>\n",
       "      <td>300015</td>\n",
       "      <td>100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>1</td>\n",
       "      <td>16887</td>\n",
       "      <td>30304</td>\n",
       "      <td>30304</td>\n",
       "      <td>GV10090007</td>\n",
       "      <td>12/01/99 0:00:00</td>\n",
       "      <td>NITROGENO KJELDAHL</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg N/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.343950</td>\n",
       "      <td>37.311018</td>\n",
       "      <td>-3.639073</td>\n",
       "      <td>749.117173</td>\n",
       "      <td>637.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td></td>\n",
       "      <td>28300.0</td>\n",
       "      <td>300013</td>\n",
       "      <td>100005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>1</td>\n",
       "      <td>16888</td>\n",
       "      <td>30304</td>\n",
       "      <td>30304</td>\n",
       "      <td>GV10090007</td>\n",
       "      <td>03/14/00 0:00:00</td>\n",
       "      <td>NITROGENO KJELDAHL</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg N/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.343950</td>\n",
       "      <td>37.311018</td>\n",
       "      <td>-3.639073</td>\n",
       "      <td>749.117173</td>\n",
       "      <td>637.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td></td>\n",
       "      <td>28300.0</td>\n",
       "      <td>300013</td>\n",
       "      <td>100005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>1</td>\n",
       "      <td>16889</td>\n",
       "      <td>30304</td>\n",
       "      <td>30304</td>\n",
       "      <td>GV10090007</td>\n",
       "      <td>06/06/00 0:00:00</td>\n",
       "      <td>NITROGENO KJELDAHL</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg N/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.343950</td>\n",
       "      <td>37.311018</td>\n",
       "      <td>-3.639073</td>\n",
       "      <td>749.117173</td>\n",
       "      <td>637.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td></td>\n",
       "      <td>28300.0</td>\n",
       "      <td>300013</td>\n",
       "      <td>100005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>1</td>\n",
       "      <td>16890</td>\n",
       "      <td>30304</td>\n",
       "      <td>30304</td>\n",
       "      <td>GV10090007</td>\n",
       "      <td>09/06/00 0:00:00</td>\n",
       "      <td>NITROGENO KJELDAHL</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg N/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.343950</td>\n",
       "      <td>37.311018</td>\n",
       "      <td>-3.639073</td>\n",
       "      <td>749.117173</td>\n",
       "      <td>637.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td></td>\n",
       "      <td>28300.0</td>\n",
       "      <td>300013</td>\n",
       "      <td>100005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>1</td>\n",
       "      <td>16891</td>\n",
       "      <td>30304</td>\n",
       "      <td>30304</td>\n",
       "      <td>GV10090007</td>\n",
       "      <td>12/20/00 0:00:00</td>\n",
       "      <td>NITROGENO KJELDAHL</td>\n",
       "      <td>LC</td>\n",
       "      <td>mg N/l</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.343950</td>\n",
       "      <td>37.311018</td>\n",
       "      <td>-3.639073</td>\n",
       "      <td>749.117173</td>\n",
       "      <td>637.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td></td>\n",
       "      <td>28300.0</td>\n",
       "      <td>300013</td>\n",
       "      <td>100005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Join_Count  TARGET_FID est_estaci   COD_UE  COD_PUNTO_  \\\n",
       "32             1       13832      30303  30303-O  GV10090004   \n",
       "38             1       13838      30303  30303-O  GV10090004   \n",
       "100            1       13900      30303  30303-O  GV10090004   \n",
       "105            1       13905      30303  30303-O  GV10090004   \n",
       "106            1       13906      30303  30303-O  GV10090004   \n",
       "...          ...         ...        ...      ...         ...   \n",
       "3087           1       16887      30304    30304  GV10090007   \n",
       "3088           1       16888      30304    30304  GV10090007   \n",
       "3089           1       16889      30304    30304  GV10090007   \n",
       "3090           1       16890      30304    30304  GV10090007   \n",
       "3091           1       16891      30304    30304  GV10090007   \n",
       "\n",
       "            F_MUESTREO              NOMBRE RESULTADO    UNIDAD COD_UE_1  ...  \\\n",
       "32    09/10/97 0:00:00              AMONIO        LC  mg NH4/l           ...   \n",
       "38    03/04/98 0:00:00              AMONIO        LC  mg NH4/l           ...   \n",
       "100   03/11/04 0:00:00              AMONIO        LC  mg NH4/l           ...   \n",
       "105   08/11/04 0:00:00              AMONIO        LC  mg NH4/l           ...   \n",
       "106   09/15/04 0:00:00              AMONIO        LC  mg NH4/l           ...   \n",
       "...                ...                 ...       ...       ...      ...  ...   \n",
       "3087  12/01/99 0:00:00  NITROGENO KJELDAHL        LC    mg N/l           ...   \n",
       "3088  03/14/00 0:00:00  NITROGENO KJELDAHL        LC    mg N/l           ...   \n",
       "3089  06/06/00 0:00:00  NITROGENO KJELDAHL        LC    mg N/l           ...   \n",
       "3090  09/06/00 0:00:00  NITROGENO KJELDAHL        LC    mg N/l           ...   \n",
       "3091  12/20/00 0:00:00  NITROGENO KJELDAHL        LC    mg N/l           ...   \n",
       "\n",
       "          Dep1        Lat     Long_        Elev ElevMin  ElevMax  Bname  \\\n",
       "32    0.400558  37.291096 -3.664485  706.037444   606.0    869.0          \n",
       "38    0.400558  37.291096 -3.664485  706.037444   606.0    869.0          \n",
       "100   0.400558  37.291096 -3.664485  706.037444   606.0    869.0          \n",
       "105   0.400558  37.291096 -3.664485  706.037444   606.0    869.0          \n",
       "106   0.400558  37.291096 -3.664485  706.037444   606.0    869.0          \n",
       "...        ...        ...       ...         ...     ...      ...    ...   \n",
       "3087  0.343950  37.311018 -3.639073  749.117173   637.0    938.0          \n",
       "3088  0.343950  37.311018 -3.639073  749.117173   637.0    938.0          \n",
       "3089  0.343950  37.311018 -3.639073  749.117173   637.0    938.0          \n",
       "3090  0.343950  37.311018 -3.639073  749.117173   637.0    938.0          \n",
       "3091  0.343950  37.311018 -3.639073  749.117173   637.0    938.0          \n",
       "\n",
       "      Shape_Leng HydroID OutletID  \n",
       "32       40000.0  300015   100001  \n",
       "38       40000.0  300015   100001  \n",
       "100      40000.0  300015   100001  \n",
       "105      40000.0  300015   100001  \n",
       "106      40000.0  300015   100001  \n",
       "...          ...     ...      ...  \n",
       "3087     28300.0  300013   100005  \n",
       "3088     28300.0  300013   100005  \n",
       "3089     28300.0  300013   100005  \n",
       "3090     28300.0  300013   100005  \n",
       "3091     28300.0  300013   100005  \n",
       "\n",
       "[212 rows x 42 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter DMA_cubillas_measurements_131415_mg_L for FOSFORO TOTAL NOMBRES on 2015-2-12 and estaci 30304\n",
    "\n",
    "DMA_cubillas_measurements_131415_mg_L[(DMA_cubillas_measurements_131415_mg_L[\"NOMBRE\"] == \"FOSFORO TOTAL\") & (DMA_cubillas_measurements_131415_mg_L[\"est_estaci\"] == \"30304\")]\n",
    "\n",
    "DMA_cubillas_measurements_131415_mg_L[(DMA_cubillas_measurements_131415_mg_L[\"RESULTADO\"] == \"LC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c59b0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable_for_manual_loaded_rchs_which_needs_lots_of_time_to_load = load_multiple_rch_from_folders(OLD_base_folders) # + [r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_set-219\\BASE recreated from arcswat default\\TxtInOut_1\", ]),#r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_POINT_set-219\\TxtInOut_1\",]),\n",
    "    #extra_dfs = load_or_build_dfs_for_runs([150], force_rebuild=False),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c802e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_BASE_recr_default_rswat = load_multiple_rch_from_folders([r\"C:\\SWAT\\RSWAT\\cubillas\\cubillas_set_219_ruben\\cubillas_BASE_set-219\\BASE recreated from arcswat default\\TxtInOut_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29d111f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_BASE_recr_default_rswat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "988fd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_BASE_recr_default_rswat.keys()\n",
    "#dict_145.keys()\n",
    "\n",
    "comparing_BASEs = {\"BASE\": dict_145['rch_run000145_real000503_1']} #, \"219 recreated RSWAT\": dict_BASE_recr_default_rswat['rch_BASE recreated from arcswat default']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40f7e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable_for_manual_loaded_rchs_which_needs_lots_of_time_to_load.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8116e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dash] Init dashboard {'reach': 13, 'start': '1986-01-01', 'end': '2001-02-25', 'season_months': None}\n",
      "[dash] variables {'n': 14, 'has_KJELDAHL': True}\n",
      "Detected water flow series in water_flow_df - will also map water flow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8fd4a8f6854106af718761d489d4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='Number of initializations: 2 - run 157'), Dropdown(description='Vari…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90caf4d52cf5483ebf1b38c8dbb4876f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='', layout=Layout(margin='0 8px 0 0')), Button(button_style='warning', icon='refresh…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64de1acef1734032802f71ede8aa27bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55528746fcd4b48b593baa85494a5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Lag by:', index=1, layout=Layout(width='140px'), options=('r', 'NSE'), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcff79fc5f3b4238802be418a833c5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='flex-start', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19f3c1951b241b487cc8533bb74c449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='', layout=Layout(border_bottom='1px solid #ddd', border_left='1px solid #ddd', bord…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dash] measured_var_map {}\n",
      "[dash] compute {'var': 'KJELDAHL_OUTkg', 'reach': 13, 'freq': '1D', 'method': 'mean', 'mode': 'load'}\n",
      "[info] median sampling interval = 1.000000 days (24.000 h)\n",
      "[proc] 'main': threshold resolved = 135432.0 (units same as 'Q'), etmin = 2.0 days -> min_samples = 2\n",
      "[result] 'main': runs found = 51, kept (>= 2 samples) = 47\n",
      "[info] median sampling interval = 1.000000 days (24.000 h)\n",
      "[proc] 'main': threshold resolved = 135432.0 (units same as 'Q'), etmin = 2.0 days -> min_samples = 2\n",
      "[result] 'main': runs found = 51, kept (>= 2 samples) = 47\n",
      "[dash] events {'mode': 'all', 'events': 1381, 'buffer': 243, 'keep': 5535}\n",
      "[dash] rch_run000157_real000529_1 raw reach=13: n=14610, date=[1981-01-01 00:00:00..2020-12-31 00:00:00]\n",
      "[dash] rch_run000157_real000529_1 after time slice: n=5535\n",
      "[dash] rch_run000157_real000529_1 after event-mode filter: n=5535\n",
      "[dash] rch_run000157_real000529_1 series after resample: n=5535, idx=[1986-01-01 00:00:00..2001-02-25 00:00:00]\n",
      "[dash] rch_run000157_real000530_2 raw reach=13: n=14610, date=[1981-01-01 00:00:00..2020-12-31 00:00:00]\n",
      "[dash] rch_run000157_real000530_2 after time slice: n=5535\n",
      "[dash] rch_run000157_real000530_2 after event-mode filter: n=5535\n",
      "[dash] rch_run000157_real000530_2 series after resample: n=5535, idx=[1986-01-01 00:00:00..2001-02-25 00:00:00]\n",
      "[dash] aligned {'T': 5535, 'N': 2}\n",
      "[dash] store sed_series_for_ldc {'n': 14610}\n",
      "[dash] events {'mode': 'all', 'events': 1381, 'buffer': 243, 'keep': 5535}\n",
      "[dash] rch_run000157_real000529_1 raw reach=13: n=14610, date=[1981-01-01 00:00:00..2020-12-31 00:00:00]\n",
      "[dash] rch_run000157_real000529_1 after time slice: n=5535\n",
      "[dash] rch_run000157_real000529_1 after event-mode filter: n=5535\n",
      "[dash] rch_run000157_real000529_1 series after resample: n=5535, idx=[1986-01-01 00:00:00..2001-02-25 00:00:00]\n",
      "[dash] rch_run000157_real000530_2 raw reach=13: n=14610, date=[1981-01-01 00:00:00..2020-12-31 00:00:00]\n",
      "[dash] rch_run000157_real000530_2 after time slice: n=5535\n",
      "[dash] rch_run000157_real000530_2 after event-mode filter: n=5535\n",
      "[dash] rch_run000157_real000530_2 series after resample: n=5535, idx=[1986-01-01 00:00:00..2001-02-25 00:00:00]\n",
      "[dash] aligned {'T': 5535, 'N': 2}\n",
      "[dash] store sed_series_for_ldc {'n': 14610}\n",
      "[dash] quantiles {'all_nan_p50': 0}\n",
      "[dash] quantiles {'all_nan_p50': 0}\n",
      "[INFO] Found 0 non-numeric sample values (including NaN and strings like 'LC').\n",
      "[INFO] Set 0 non-numeric sample values to half MDL (0.1).\n",
      "[dash] measured map1 {'chem': 'NITROGENO KJELDAHL', 'mvcol': 'kg_per_day', 'stations': 1}\n",
      "[dash] measured NITROGENO KJELDAHL st=30304 daily: n=20, idx=[1994-12-01 00:00:00..2000-12-20 00:00:00]\n",
      "[dash] measured NITROGENO KJELDAHL st=30304 resampled: n=20, idx=[1994-12-01 00:00:00..2000-12-20 00:00:00]\n",
      "[INFO] Found 0 non-numeric sample values (including NaN and strings like 'LC').\n",
      "[INFO] Set 0 non-numeric sample values to half MDL (0.1).\n",
      "[dash] measured map1 {'chem': 'NITROGENO KJELDAHL', 'mvcol': 'kg_per_day', 'stations': 1}\n",
      "[dash] measured NITROGENO KJELDAHL st=30304 daily: n=20, idx=[1994-12-01 00:00:00..2000-12-20 00:00:00]\n",
      "[dash] measured NITROGENO KJELDAHL st=30304 resampled: n=20, idx=[1994-12-01 00:00:00..2000-12-20 00:00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dash] duration context {'has_q_plot': True, 'q_plot_shape': (5535, 10), 'swat_flow_valid': False, 'ext_flow_valid': True}\n",
      "[dash] duration q_plot cols ['min', 'p05', 'p10', 'p25', 'p50', 'p60', 'p75', 'p90', 'p95', 'max']\n",
      "[dash] duration measured overlay {'n_points': 20}\n",
      "[dash] flow_strat:aligned_df_plot_info {'valid': True, 'shape': (5535, 2)}\n",
      "[dash] flow_strat:event_ctx_indices {'has_events': True, 'n_events': 1624, 'has_non_events': True, 'n_non_events': 3917}\n",
      "Run 157: realizations=2 ids=[529, 530]\n",
      "Time span: 2025-09-20T10:12:08.913842+00:00 → 2025-09-20T10:12:15.190879+00:00\n",
      "Names:\n",
      "  - run000157_real000529_1\n",
      "  - run000157_real000530_2\n",
      "Transforms:\n",
      "  - transform_init_copy\n",
      "  - fn\n",
      "  - ops_choices\n",
      "  - split_choices\n",
      "  - transform_interpolate_years_wide\n",
      "  - point_mgL_choices\n",
      "Inputs (union):\n",
      "  - C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\cubillas_hru\\Watershed\\Shapes\\hru1.shp\n",
      "  - C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\Fosforo_mg_100g_P205_rediam.tif\n",
      "  - C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\Nitrogeno_total_porcent_resample_Rediam.tif\n",
      "Perturbations:\n",
      "  - N_total_mg_kg: bounds=[0..0] strategy=deterministic\n",
      "  - P_element_mg_kg: bounds=[0..0] strategy=n/a\n",
      "  - Soil organic P [mg/kg]: bounds=[0.07..0.2] strategy=all_lower,all_upper\n",
      "  - mgL ORGNYR: bounds=[8..35] strategy=all_lower,all_upper\n",
      "  - mgL ORGPYR: bounds=[1..5] strategy=all_lower,all_upper\n",
      "  - mgL NO3YR: bounds=[0..0] strategy=standard\n",
      "  - mgL NH3YR: bounds=[12..50] strategy=all_lower,all_upper\n",
      "  - mgL NO2YR: bounds=[0..0] strategy=standard\n",
      "  - mgL MINPYR: bounds=[3..10] strategy=all_lower,all_upper\n",
      "  - mgL SEDYR: bounds=[350..1200] strategy=all_lower,all_upper\n",
      "  - mgL CBODYR: bounds=[110..400] strategy=all_lower,all_upper\n",
      "  - mgL DISOXYR: bounds=[0..2] strategy=all_lower,all_upper\n",
      "  - mgL CHLAYR: bounds=[0.0..0.002] strategy=all_lower,all_upper\n",
      "Splits:\n",
      "  - Soil NO3 [mg/kg]: bounds=[0.015..0.03] strategy=all_lower,all_upper\n",
      "  - Soil organic N [mg/kg]: bounds=[0.95..0.99] strategy=all_lower,all_upper\n",
      "  - Soil labile P [mg/kg]: bounds=[1..5] strategy=all_lower,all_upper\n",
      "[dash] flow_strat:aligned_df_plot_info {'valid': True, 'shape': (5535, 2)}\n",
      "[dash] flow_strat:event_ctx_indices {'has_events': True, 'n_events': 1624, 'has_non_events': True, 'n_non_events': 3917}\n",
      "Run 157: realizations=2 ids=[529, 530]\n",
      "Time span: 2025-09-20T10:12:08.913842+00:00 → 2025-09-20T10:12:15.190879+00:00\n",
      "Names:\n",
      "  - run000157_real000529_1\n",
      "  - run000157_real000530_2\n",
      "Transforms:\n",
      "  - transform_init_copy\n",
      "  - fn\n",
      "  - ops_choices\n",
      "  - split_choices\n",
      "  - transform_interpolate_years_wide\n",
      "  - point_mgL_choices\n",
      "Inputs (union):\n",
      "  - C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Archivos de Cesar Ruben Fernandez De Villaran San Juan - swat_cubillas\\cubillas_hru\\Watershed\\Shapes\\hru1.shp\n",
      "  - C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\Fosforo_mg_100g_P205_rediam.tif\n",
      "  - C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil_ArcGIS_Ruben\\ArcGIS _ base de suelo quimico _ ruben _ 30-05-25\\raster\\temp_rasters\\Nitrogeno_total_porcent_resample_Rediam.tif\n",
      "Perturbations:\n",
      "  - N_total_mg_kg: bounds=[0..0] strategy=deterministic\n",
      "  - P_element_mg_kg: bounds=[0..0] strategy=n/a\n",
      "  - Soil organic P [mg/kg]: bounds=[0.07..0.2] strategy=all_lower,all_upper\n",
      "  - mgL ORGNYR: bounds=[8..35] strategy=all_lower,all_upper\n",
      "  - mgL ORGPYR: bounds=[1..5] strategy=all_lower,all_upper\n",
      "  - mgL NO3YR: bounds=[0..0] strategy=standard\n",
      "  - mgL NH3YR: bounds=[12..50] strategy=all_lower,all_upper\n",
      "  - mgL NO2YR: bounds=[0..0] strategy=standard\n",
      "  - mgL MINPYR: bounds=[3..10] strategy=all_lower,all_upper\n",
      "  - mgL SEDYR: bounds=[350..1200] strategy=all_lower,all_upper\n",
      "  - mgL CBODYR: bounds=[110..400] strategy=all_lower,all_upper\n",
      "  - mgL DISOXYR: bounds=[0..2] strategy=all_lower,all_upper\n",
      "  - mgL CHLAYR: bounds=[0.0..0.002] strategy=all_lower,all_upper\n",
      "Splits:\n",
      "  - Soil NO3 [mg/kg]: bounds=[0.015..0.03] strategy=all_lower,all_upper\n",
      "  - Soil organic N [mg/kg]: bounds=[0.95..0.99] strategy=all_lower,all_upper\n",
      "  - Soil labile P [mg/kg]: bounds=[1..5] strategy=all_lower,all_upper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dash] duration context {'has_q_plot': True, 'q_plot_shape': (5535, 10), 'swat_flow_valid': False, 'ext_flow_valid': True}\n",
      "[dash] duration q_plot cols ['min', 'p05', 'p10', 'p25', 'p50', 'p60', 'p75', 'p90', 'p95', 'max']\n",
      "[dash] duration measured overlay {'n_points': 12}\n",
      "[dash] duration measured overlay {'n_points': 12}\n",
      "[dash] flow_strat:aligned_df_plot_info {'valid': True, 'shape': (5535, 2)}\n",
      "[dash] flow_strat:event_ctx_indices {'has_events': True, 'n_events': 1624, 'has_non_events': True, 'n_non_events': 3917}\n",
      "[dash] flow_strat:aligned_df_plot_info {'valid': True, 'shape': (5535, 2)}\n",
      "[dash] flow_strat:event_ctx_indices {'has_events': True, 'n_events': 1624, 'has_non_events': True, 'n_non_events': 3917}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "sys.path.insert(0, r\"c:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\scripts\\Python_Pipeline_SWAT_Pascal\\swat_pipeline\\trabajoFM\")\n",
    "from python_pipeline_scripts.provenance_report import summarize_run\n",
    "\n",
    "# 2) Import module as alias\n",
    "import python_pipeline_scripts.dashboard as dash\n",
    "import python_pipeline_scripts.stats as stats\n",
    "\n",
    "monte_carlo_run_numbmer = 157\n",
    "defaults = {\n",
    "    \"variable\": \"KJELDAHL_OUTkg\", # IMPORTANT: must match an item in your variables list\n",
    "    \"reach\": 13,\n",
    "    \"freq\": \"D\",\n",
    "    \"bin\": 1,\n",
    "    \"compare_mode\": \"load\", # \"conc\" for mg/L, \"load\" for kg/day\n",
    "    \"method\": \"mean\",\n",
    "    \"autoscale_y_live\": True,\n",
    "    \"show_names_in_tooltip\": False,\n",
    "    \"show_diags\": True,\n",
    "    \"lag_metric\": \"NSE\",\n",
    "    \"max_lag\": 2,\n",
    "    \"local_Ks\": [1, 2],\n",
    "    \"log_metrics\": False,\n",
    "    \"measured_on\": True,\n",
    "    \"flow_on\": False,\n",
    "    #\"cats\": {\n",
    "    #    1: {\n",
    "    #        \"enabled\": True,\n",
    "    #        \"chem\": \"FOSFORO TOTAL\", # Edit to your measured chem name as it appears in measured_df[\"NOMBRE\"]\n",
    "    #        \"stations\": [\"30304\"] # Edit to your station codes (strings)\n",
    "    #    },\n",
    "    #    2: {\"enabled\": False},\n",
    "    #    3: {\"enabled\": False}\n",
    "    #},\n",
    "    \"extra_visible\": {\n",
    "    # \"Baseline\": False,\n",
    "    },\n",
    "    \"debug\": True,\n",
    "    \"flow_on\": True, \"exclude_flow_outliers\": False, \"outlier_buffer_days\": 3,\n",
    "    \"swat_flow_on\": False,\n",
    "    \"flag_deviations\": False,\n",
    "    \"erosion_on\": False,\n",
    "    \"cb_ldc_sediment\": False,\n",
    "    \"meas_negative_policy\": \"drop\",\n",
    "    \"meas_nonnum_policy\": \"half_MDL\", # \"zero\" or \"half_detection_limit\" or \"drop\"\n",
    "    \"event_view\": \"all\", # \"all\" or \"events\" or \"non_events\"\n",
    "    \"event_source\": \"swat_avg\", # \"external\" or \"swat_avg\"\n",
    "    \"event_min_days\": 2, # minimum event duration in days\n",
    "    \"event_threshold\": \"p50\", # multiplier of average flow\n",
    "    \"event_buffer_days\": 2, # days to add before/after event\n",
    "    \"event_threshold\": \"p75\", # threshold for event detection\n",
    "\n",
    "    \"ldc_log_scale\": True,\n",
    "    \"flow_strat_curve\": True,\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "reload(stats)\n",
    "stats.SHIFT_AGG = 'both'  # or 'mean', \"median\", \"both\"\n",
    "reload(dash)\n",
    "dash.fan_compare_simulations_dashboard(\n",
    "    load_or_build_dfs_for_runs([monte_carlo_run_numbmer], force_rebuild=False),#dashboard_mc_dfs,\n",
    "    vars_to_compare,\n",
    "    measured_df=DMA_cubillas_measurements_131415_mg_L,\n",
    "    water_flow_df = df_water_flow_m3_d_cubillas,\n",
    "    measured_var_map=swat_to_measured,\n",
    "    reach=13,\n",
    "    start=\"1986-01-01\",\n",
    "    end=\"2001-02-25\",\n",
    "    freq_options=(\"D\",\"W\",\"M\",\"A\"),\n",
    "    max_bin_size=30,\n",
    "    #extra_dfs = variable_for_manual_loaded_rchs_which_needs_lots_of_time_to_load,\n",
    "    #extra_dfs = load_or_build_dfs_for_runs([145], force_rebuild=False), #dict_BASE_recr_default_rswat\n",
    "    extra_dfs = comparing_BASEs,\n",
    "    how_map_defaults=how_map_defaults,\n",
    "    ui_defaults=defaults\n",
    ")\n",
    "\n",
    "print(summarize_run(monte_carlo_run_numbmer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8116e7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' monte_carlo_run_numbmer = 129\\ndashboard_mc_dfs = load_or_build_dfs_for_runs([monte_carlo_run_numbmer], force_rebuild=False)\\n\\n\\ndefaults2 = {\\n    \"variable\": \"TOT_Nkg\", # IMPORTANT: must match an item in your variables list\\n    \"reach\": 13,\\n    \"freq\": \"D\",\\n    \"bin\": 1,\\n    \"compare_mode\": \"conc\", # \"conc\" for mg/L, \"load\" for kg/day\\n    \"method\": \"mean\",\\n    \"autoscale_y_live\": True,\\n    \"show_names_in_tooltip\": False,\\n    \"show_diags\": True,\\n    \"lag_metric\": \"NSE\",\\n    \"max_lag\": 2,\\n    \"local_Ks\": [1, 2],\\n    \"log_metrics\": False,\\n    \"measured_on\": True,\\n    \"flow_on\": False,\\n    #\"cats\": {\\n    #    1: {\\n    #        \"enabled\": True,\\n    #        \"chem\": \"FOSFORO TOTAL\", # Edit to your measured chem name as it appears in measured_df[\"NOMBRE\"]\\n    #        \"stations\": [\"30304\"] # Edit to your station codes (strings)\\n    #    },\\n    #    2: {\"enabled\": False},\\n    #    3: {\"enabled\": False}\\n    #},\\n    \"extra_visible\": {\\n    # \"Baseline\": False,\\n    },\\n    \"debug\": True\\n}\\n\\n\\n\\nreload(dash)\\ndash.fan_compare_simulations_dashboard(\\n    dashboard_mc_dfs,\\n    vars_to_compare,\\n    measured_df=DMA_cubillas_measurements_131415_mg_L,\\n    measured_var_map=swat_to_measured,\\n    reach=13,\\n    freq_options=(\"D\",\"W\",\"M\",\"A\"),\\n    max_bin_size=30,\\n    #extra_dfs = dfs_base_vs_point, \\n    #extra_dfs = load_or_build_dfs_for_runs([118], force_rebuild=False),\\n    water_flow_df = df_water_flow_m3_d_cubillas,\\n    how_map_defaults=how_map_defaults,\\n    ui_defaults=defaults2\\n)\\n\\nprint(summarize_run(monte_carlo_run_numbmer)) '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" monte_carlo_run_numbmer = 129\n",
    "dashboard_mc_dfs = load_or_build_dfs_for_runs([monte_carlo_run_numbmer], force_rebuild=False)\n",
    "\n",
    "\n",
    "defaults2 = {\n",
    "    \"variable\": \"TOT_Nkg\", # IMPORTANT: must match an item in your variables list\n",
    "    \"reach\": 13,\n",
    "    \"freq\": \"D\",\n",
    "    \"bin\": 1,\n",
    "    \"compare_mode\": \"conc\", # \"conc\" for mg/L, \"load\" for kg/day\n",
    "    \"method\": \"mean\",\n",
    "    \"autoscale_y_live\": True,\n",
    "    \"show_names_in_tooltip\": False,\n",
    "    \"show_diags\": True,\n",
    "    \"lag_metric\": \"NSE\",\n",
    "    \"max_lag\": 2,\n",
    "    \"local_Ks\": [1, 2],\n",
    "    \"log_metrics\": False,\n",
    "    \"measured_on\": True,\n",
    "    \"flow_on\": False,\n",
    "    #\"cats\": {\n",
    "    #    1: {\n",
    "    #        \"enabled\": True,\n",
    "    #        \"chem\": \"FOSFORO TOTAL\", # Edit to your measured chem name as it appears in measured_df[\"NOMBRE\"]\n",
    "    #        \"stations\": [\"30304\"] # Edit to your station codes (strings)\n",
    "    #    },\n",
    "    #    2: {\"enabled\": False},\n",
    "    #    3: {\"enabled\": False}\n",
    "    #},\n",
    "    \"extra_visible\": {\n",
    "    # \"Baseline\": False,\n",
    "    },\n",
    "    \"debug\": True\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "reload(dash)\n",
    "dash.fan_compare_simulations_dashboard(\n",
    "    dashboard_mc_dfs,\n",
    "    vars_to_compare,\n",
    "    measured_df=DMA_cubillas_measurements_131415_mg_L,\n",
    "    measured_var_map=swat_to_measured,\n",
    "    reach=13,\n",
    "    freq_options=(\"D\",\"W\",\"M\",\"A\"),\n",
    "    max_bin_size=30,\n",
    "    #extra_dfs = dfs_base_vs_point, \n",
    "    #extra_dfs = load_or_build_dfs_for_runs([118], force_rebuild=False),\n",
    "    water_flow_df = df_water_flow_m3_d_cubillas,\n",
    "    how_map_defaults=how_map_defaults,\n",
    "    ui_defaults=defaults2\n",
    ")\n",
    "\n",
    "print(summarize_run(monte_carlo_run_numbmer)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d165a7",
   "metadata": {},
   "source": [
    "# evaluate sedimentation effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5473bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _to_datetime_if_needed(s):\n",
    "    # If MON is julian, replace this with proper calendar conversion.\n",
    "    return pd.to_datetime(s)\n",
    "\n",
    "def compute_sed_timeseries(\n",
    "    df_rch: pd.DataFrame,\n",
    "    df_sub: pd.DataFrame,\n",
    "    reach: int,\n",
    "    method: str = \"A\",           # \"A\", \"B\", \"C1\", \"C2\"\n",
    "    dr=1.0,                      # delivery ratio: scalar, or mapping {reach: dr}, or Series by reach or by (date, reach)\n",
    "    cols_rch=dict(date=\"date\", reach=\"RCH\", sed_in=\"SED_IN\", sed_out=\"SED_OUTtons\",\n",
    "                  flow_in=\"FLOW_INcms\", flow_out=\"FLOW_OUTcms\", area_km2=\"AREA\"),\n",
    "    cols_sub=dict(date=\"date\", sub=\"SUB\", area_km2=\"AREA\", syld_t_ha=\"SYLD\", wyld_mm=\"WYLD\"),\n",
    "    drop_feb29=True\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a pandas Series indexed by datetime for the chosen reach & method.\n",
    "      Method A: Δ_channel = (OUT - IN) - DR * SYLD_tons\n",
    "      Method B: Retained = (IN + DR * SYLD_tons) - OUT\n",
    "      Method C1: Hydrology-normalized concentration-like (mg/L)\n",
    "      Method C2: Hydrology-normalized per runoff (kg/mm/ha)\n",
    "\n",
    "    Notes:\n",
    "      - SYLD is tons/ha in .sub, convert to tons by multiplying subbasin area (ha).\n",
    "      - If WYLD is zero on a day and method='C2', result is NaN for that day.\n",
    "      - If FLOW_OUT is zero on a day and method='C1', result is NaN for that day.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Extract & clean reach rows\n",
    "    r = df_rch.copy()\n",
    "    s = df_sub.copy()\n",
    "    r = r.rename(columns={\n",
    "        cols_rch[\"date\"]:\"date\", cols_rch[\"RCH\"]:\"RCH\",\n",
    "        cols_rch[\"sed_in\"]:\"SED_IN\", cols_rch[\"sed_out\"]:\"SED_OUTtons\",\n",
    "        cols_rch[\"flow_in\"]:\"FLOW_INcms\", cols_rch[\"flow_out\"]:\"FLOW_OUTcms\",\n",
    "        cols_rch[\"area_km2\"]:\"RCH_AREA_KM2\"\n",
    "    })\n",
    "    s = s.rename(columns={\n",
    "        cols_sub[\"date\"]:\"date\", cols_sub[\"sub\"]:\"SUB\",\n",
    "        cols_sub[\"area_km2\"]:\"SUB_AREA_KM2\", cols_sub[\"syld_t_ha\"]:\"SYLD_T_HA\",\n",
    "        cols_sub[\"wyld_mm\"]:\"WYLD_MM\"\n",
    "    })\n",
    "\n",
    "    # Convert date\n",
    "    r[\"date\"] = _to_datetime_if_needed(r[\"date\"])\n",
    "    s[\"date\"] = _to_datetime_if_needed(s[\"date\"])\n",
    "\n",
    "    # Keep only target reach\n",
    "    r = r[r[\"RCH\"] == reach].copy()\n",
    "    s = s[s[\"SUB\"] == reach].copy()\n",
    "\n",
    "    # Merge reach + sub on date\n",
    "    m = pd.merge(\n",
    "        r[[\"date\",\"RCH\",\"SED_IN\",\"SED_OUTtons\",\"FLOW_INcms\",\"FLOW_OUTcms\",\"RCH_AREA_KM2\"]],\n",
    "        s[[\"date\",\"SUB\",\"SUB_AREA_KM2\",\"SYLD_T_HA\",\"WYLD_MM\"]],\n",
    "        on=\"date\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Delivery ratio\n",
    "    if np.isscalar(dr):\n",
    "        m[\"DR\"] = float(dr)\n",
    "    elif isinstance(dr, dict):\n",
    "        m[\"DR\"] = m[\"RCH\"].map(dr).astype(float)\n",
    "    elif isinstance(dr, pd.Series):\n",
    "        # Series keyed by reach or MultiIndex (date, reach)\n",
    "        if dr.index.nlevels == 1:\n",
    "            m[\"DR\"] = m[\"RCH\"].map(dr).astype(float)\n",
    "        else:\n",
    "            m = m.set_index([\"date\",\"RCH\"])\n",
    "            m[\"DR\"] = dr.reindex(m.index).astype(float)\n",
    "            m = m.reset_index()\n",
    "    else:\n",
    "        m[\"DR\"] = 1.0\n",
    "\n",
    "    # Convert SYLD from tons/ha to tons per time-step (using SUB area)\n",
    "    m[\"SUB_AREA_HA\"] = m[\"SUB_AREA_KM2\"] * 100.0\n",
    "    m[\"SYLD_TONS\"] = m[\"SYLD_T_HA\"] * m[\"SUB_AREA_HA\"]\n",
    "\n",
    "    # Core channel terms\n",
    "    m[\"delta_raw\"] = m[\"SED_OUTtons\"] - m[\"SED_IN\"]\n",
    "    m[\"local_delivered\"] = m[\"DR\"] * m[\"SYLD_TONS\"]\n",
    "    m[\"delta_channel\"] = m[\"delta_raw\"] - m[\"local_delivered\"]\n",
    "    m[\"retained\"] = (m[\"SED_IN\"] + m[\"local_delivered\"]) - m[\"SED_OUTtons\"]  # = -delta_channel\n",
    "\n",
    "    # Optional: remove Feb 29 to keep a consistent year-day\n",
    "    if drop_feb29:\n",
    "        is_feb29 = (m[\"date\"].dt.month == 2) & (m[\"date\"].dt.day == 29)\n",
    "        m = m[~is_feb29]\n",
    "\n",
    "    m = m.sort_values(\"date\").set_index(\"date\")\n",
    "\n",
    "    # Methods\n",
    "    if method.upper() == \"A\":\n",
    "        out = m[\"delta_channel\"]  # tons per time-step\n",
    "        out.name = f\"Δ_channel_tons_R{reach}\"\n",
    "\n",
    "    elif method.upper() == \"B\":\n",
    "        out = m[\"retained\"]  # tons per time-step (positive = deposition)\n",
    "        out.name = f\"Retained_tons_R{reach}\"\n",
    "\n",
    "    elif method.upper() == \"C1\":\n",
    "        # concentration-like normalization using FLOW_OUT (m3/s)\n",
    "        # tons/day -> mg/L approx: tons/day * 1e9 mg/ton / (m3/s * 86400 s/day * 1000 L/m3)\n",
    "        # Simplify factor ~ 11.574074 / Qcms\n",
    "        q = m[\"FLOW_OUTcms\"].replace(0, np.nan)\n",
    "        out = (m[\"delta_channel\"] * 11.574074) / q\n",
    "        out.name = f\"Δ_channel_mgL_R{reach}\"\n",
    "\n",
    "    elif method.upper() == \"C2\":\n",
    "        # kg per mm-runoff per ha (uses SUB WYLD and area)\n",
    "        denom = (m[\"WYLD_MM\"] * m[\"SUB_AREA_HA\"]).replace(0, np.nan)  # mm * ha\n",
    "        out = (m[\"delta_channel\"] * 1000.0) / denom  # tons -> kg\n",
    "        out.name = f\"Δ_channel_kg_per_mm_ha_R{reach}\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of 'A', 'B', 'C1', 'C2'\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "732495fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sediment Dynamics Dashboard (methods A/B/C) — Jupyter + Plotly + ipywidgets\n",
    "# ----------------------------------------------------------------------------\n",
    "# Methods (one time series per reach):\n",
    "#  A: Δ_channel = (SED_OUT − SED_IN) − DR * SYLD_tons\n",
    "#  B: Retained  = (SED_IN + DR * SYLD_tons) − SED_OUT  ( = −Δ_channel )\n",
    "#  C1: Hydrology-normalized Δ_channel per discharge  [mg/L]  (uses FLOW_OUT)\n",
    "#  C2: Hydrology-normalized Δ_channel per runoff     [kg/mm/ha] (uses WYLD + area)\n",
    "#\n",
    "# Notes:\n",
    "# - .rch must have: date, RCH, SED_INtons, SED_OUTtons (optional: FLOW_OUT)\n",
    "# - .sub must have: date, SUB, AREA (km²), SYLD (tons/ha), WYLD (mm)\n",
    "# - Delivery ratio DR is user-controlled (scalar) in the UI.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # stop showing warnings in dashboard\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as W\n",
    "from IPython.display import display\n",
    "\n",
    "# ---------------- Utility helpers ----------------\n",
    "def to_datetime(s):\n",
    "    return pd.to_datetime(s)\n",
    "\n",
    "def agg_key(name: str) -> str:\n",
    "    # Return pandas string aggregator -> fixes FutureWarning\n",
    "    return \"mean\" if name == \"Mean\" else \"median\"\n",
    "\n",
    "def rolling_apply(x, win, func):\n",
    "    if win is None or win <= 1:\n",
    "        return np.asarray(x)\n",
    "    # func is a numpy function (np.nanmean / np.nanmedian)\n",
    "    f = np.nanmean if func == \"mean\" else np.nanmedian\n",
    "    return pd.Series(x).rolling(win, min_periods=max(1, win // 2)).apply(lambda s: f(s.values), raw=False).values\n",
    "\n",
    "def quantiles(a, qs):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    a = a[~np.isnan(a)]\n",
    "    if a.size == 0: return {q: np.nan for q in qs}\n",
    "    qq = np.quantile(a, qs)\n",
    "    return {q: float(v) for q, v in zip(qs, qq)}\n",
    "\n",
    "def band_fill(fig, x, high, low, name, opacity=0.2):\n",
    "    fig.add_trace(go.Scatter(x=x, y=high, mode=\"lines\", line=dict(width=0), showlegend=False, hoverinfo=\"skip\"))\n",
    "    fig.add_trace(go.Scatter(x=x, y=low,  mode=\"lines\", line=dict(width=0), fill=\"tonexty\", name=name, opacity=opacity))\n",
    "\n",
    "# ------------- Method engine (build metric per row) -------------\n",
    "def build_metric_table(\n",
    "    df_rch: pd.DataFrame,\n",
    "    df_sub: pd.DataFrame,\n",
    "    drop_feb29: bool,\n",
    "    method: str,\n",
    "    DR: float,\n",
    "    cols_rch=dict(date=\"date\", reach=\"RCH\", sed_in=\"SED_INtons\", sed_out=\"SED_OUTtons\", flow_out=\"FLOW_OUTcms\"),\n",
    "    cols_sub=dict(date=\"date\", sub=\"SUB\", area_km2=\"AREA\", syld_t_ha=\"SYLD\", wyld_mm=\"WYLD\"),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a table with columns:\n",
    "      date, RCH, year, doy, metric  (metric depends on method & DR)\n",
    "    \"\"\"\n",
    "    r = df_rch.rename(columns={\n",
    "        cols_rch[\"date\"]:\"date\", cols_rch[\"reach\"]:\"RCH\",\n",
    "        cols_rch[\"sed_in\"]:\"SED_IN\", cols_rch[\"sed_out\"]:\"SED_OUT\",\n",
    "        cols_rch.get(\"flow_out\",\"FLOW_OUTcms\"):\"FLOW_OUTcms\"\n",
    "    }).copy()\n",
    "    s = df_sub.rename(columns={\n",
    "        cols_sub[\"date\"]:\"date\", cols_sub[\"sub\"]:\"SUB\",\n",
    "        cols_sub[\"area_km2\"]:\"SUB_AREA_KM2\",\n",
    "        cols_sub[\"syld_t_ha\"]:\"SYLD_T_HA\",\n",
    "        cols_sub[\"wyld_mm\"]:\"WYLD_MM\"\n",
    "    }).copy()\n",
    "\n",
    "    r[\"date\"] = to_datetime(r[\"date\"])\n",
    "    s[\"date\"] = to_datetime(s[\"date\"])\n",
    "\n",
    "    # merge by (date, reach/sub)\n",
    "    m = pd.merge(\n",
    "        r[[\"date\",\"RCH\",\"SED_IN\",\"SED_OUT\",\"FLOW_OUTcms\"]],\n",
    "        s[[\"date\",\"SUB\",\"SUB_AREA_KM2\",\"SYLD_T_HA\",\"WYLD_MM\"]],\n",
    "        left_on=[\"date\",\"RCH\"], right_on=[\"date\",\"SUB\"], how=\"inner\"\n",
    "    )\n",
    "    m.drop(columns=[\"SUB\"], inplace=True)\n",
    "\n",
    "    # Convert SYLD tons/ha -> tons (per step)\n",
    "    m[\"SUB_AREA_HA\"] = m[\"SUB_AREA_KM2\"] * 100.0\n",
    "    m[\"SYLD_TONS\"]   = m[\"SYLD_T_HA\"] * m[\"SUB_AREA_HA\"]\n",
    "\n",
    "    # core deltas\n",
    "    m[\"delta_raw\"]       = m[\"SED_OUT\"] - m[\"SED_IN\"]\n",
    "    m[\"local_delivered\"] = float(DR) * m[\"SYLD_TONS\"]\n",
    "    m[\"delta_channel\"]   = m[\"delta_raw\"] - m[\"local_delivered\"]          # Method A\n",
    "    m[\"retained\"]        = (m[\"SED_IN\"] + m[\"local_delivered\"]) - m[\"SED_OUT\"]  # Method B\n",
    "\n",
    "    # choose metric\n",
    "    method = method.upper()\n",
    "    if method == \"A\":\n",
    "        metric = m[\"delta_channel\"]  # tons/step\n",
    "        ylab = \"Δ_channel (tons)\"\n",
    "    elif method == \"B\":\n",
    "        metric = m[\"retained\"]       # tons/step (positive = deposition)\n",
    "        ylab = \"Retained (tons)\"\n",
    "    elif method == \"C1\":\n",
    "        # per discharge mg/L (use FLOW_OUT m3/s)\n",
    "        q = m[\"FLOW_OUTcms\"].replace(0, np.nan)\n",
    "        metric = (m[\"delta_channel\"] * 11.574074) / q   # tons/day → mg/L approx\n",
    "        ylab = \"Δ_channel per discharge (mg/L)\"\n",
    "    elif method == \"C2\":\n",
    "        # per runoff kg/mm/ha\n",
    "        denom = (m[\"WYLD_MM\"] * m[\"SUB_AREA_HA\"]).replace(0, np.nan)  # mm * ha\n",
    "        metric = (m[\"delta_channel\"] * 1000.0) / denom                # tons → kg\n",
    "        ylab = \"Δ_channel per runoff (kg/mm/ha)\"\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of 'A', 'B', 'C1', 'C2'\")\n",
    "\n",
    "    out = m[[\"date\",\"RCH\"]].copy()\n",
    "    out[\"metric\"] = metric.values\n",
    "    out[\"year\"] = out[\"date\"].dt.year\n",
    "    out[\"month\"] = out[\"date\"].dt.month\n",
    "    out[\"day\"] = out[\"date\"].dt.day\n",
    "    if drop_feb29:\n",
    "        out = out[~((out[\"month\"] == 2) & (out[\"day\"] == 29))]\n",
    "    out[\"doy\"] = out[\"date\"].dt.dayofyear\n",
    "    out.drop(columns=[\"month\",\"day\"], inplace=True)\n",
    "    out.attrs[\"ylab\"] = ylab\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# ------------- Aggregators (operate on 'metric') -------------\n",
    "def compose_time_aggregate(subm: pd.DataFrame, reaches, years, agg_name: str, stats, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "\n",
    "    # center line by date\n",
    "    if len(reaches) > 1:\n",
    "        grouped = s.groupby(\"date\", as_index=False)[\"metric\"].agg(agg_key(agg_name)).rename(columns={\"metric\":\"center\"})\n",
    "    else:\n",
    "        grouped = s.groupby(\"date\", as_index=False)[\"metric\"].agg(\"mean\").rename(columns={\"metric\":\"center\"})\n",
    "\n",
    "    # bands across reaches (distribution at each date)\n",
    "    if len(reaches) > 1:\n",
    "        tmp = s.groupby([\"date\",\"RCH\"])[\"metric\"].agg(\"mean\").reset_index()\n",
    "        rows = []\n",
    "        for d, g in tmp.groupby(\"date\"):\n",
    "            vals = g[\"metric\"].values\n",
    "            row = {\"date\": d}\n",
    "            if \"p10p90\" in stats: row.update(quantiles(vals,[0.10,0.90]))\n",
    "            if \"p25p75\" in stats: \n",
    "                q = quantiles(vals,[0.25,0.75]); row.update({\"p25\":q[0.25],\"p75\":q[0.75]})\n",
    "            if \"minmax\" in stats and len(vals):\n",
    "                row.update({\"vmin\": float(np.nanmin(vals)), \"vmax\": float(np.nanmax(vals))})\n",
    "            rows.append(row)\n",
    "        band_df = pd.DataFrame(rows)\n",
    "        grouped = grouped.merge(band_df, on=\"date\", how=\"left\")\n",
    "\n",
    "    # rolling\n",
    "    grouped = grouped.sort_values(\"date\")\n",
    "    grouped[\"center\"] = rolling_apply(grouped[\"center\"].values, roll_win, agg_key(agg_name))\n",
    "    for col in [\"p10\",\"p90\",\"p25\",\"p75\",\"vmin\",\"vmax\"]:\n",
    "        if col in grouped.columns:\n",
    "            grouped[col] = rolling_apply(grouped[col].values, roll_win, \"mean\")\n",
    "    return grouped\n",
    "\n",
    "def compose_climatology(subm: pd.DataFrame, reaches, years, agg_name: str, stats, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "\n",
    "    center = s.groupby(\"doy\")[\"metric\"].agg(agg_key(agg_name)).rename(\"center\").reset_index()\n",
    "\n",
    "    # bands across (year×reach) samples per DOY\n",
    "    tmp = s.groupby([\"doy\",\"year\",\"RCH\"])[\"metric\"].agg(\"mean\").reset_index()\n",
    "    rows=[]\n",
    "    for d, g in tmp.groupby(\"doy\"):\n",
    "        vals = g[\"metric\"].values\n",
    "        row = {\"doy\": d}\n",
    "        if \"p10p90\" in stats: row.update(quantiles(vals,[0.10,0.90]))\n",
    "        if \"p25p75\" in stats:\n",
    "            q = quantiles(vals,[0.25,0.75]); row.update({\"p25\":q[0.25],\"p75\":q[0.75]})\n",
    "        if \"minmax\" in stats and len(vals):\n",
    "            row.update({\"vmin\": float(np.nanmin(vals)), \"vmax\": float(np.nanmax(vals))})\n",
    "        rows.append(row)\n",
    "    band_df = pd.DataFrame(rows)\n",
    "    out = center.merge(band_df, on=\"doy\", how=\"left\").sort_values(\"doy\")\n",
    "\n",
    "    # rolling over DOY (simple)\n",
    "    out[\"center\"] = rolling_apply(out[\"center\"].values, roll_win, agg_key(agg_name))\n",
    "    for col in [\"p10\",\"p90\",\"p25\",\"p75\",\"vmin\",\"vmax\"]:\n",
    "        if col in out.columns:\n",
    "            out[col] = rolling_apply(out[col].values, roll_win, \"mean\")\n",
    "    return out\n",
    "\n",
    "def compose_all_years_overlay(subm: pd.DataFrame, reaches, agg_name: str, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    years = sorted(s[\"year\"].unique())\n",
    "    lines = {}\n",
    "    for y in years:\n",
    "        ydf = s[s[\"year\"]==y]\n",
    "        if len(reaches)>1:\n",
    "            daily = ydf.groupby(\"date\")[\"metric\"].agg(agg_key(agg_name)).reset_index()\n",
    "        else:\n",
    "            daily = ydf.groupby(\"date\")[\"metric\"].agg(\"mean\").reset_index()\n",
    "        daily = daily.sort_values(\"date\")\n",
    "        daily[\"metric\"] = rolling_apply(daily[\"metric\"].values, roll_win, agg_key(agg_name))\n",
    "        lines[y] = daily\n",
    "    return lines\n",
    "\n",
    "def compose_year_reach(subm: pd.DataFrame, reaches, years):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "    return s.groupby([\"year\",\"RCH\"])[\"metric\"].agg(\"mean\").reset_index().rename(columns={\"metric\":\"delta\"})\n",
    "\n",
    "def compose_across_years_all_reaches(subm: pd.DataFrame, reaches, agg_name: str, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)] if reaches else subm.copy()\n",
    "    line = s.groupby(\"doy\")[\"metric\"].agg(agg_key(agg_name)).reset_index().sort_values(\"doy\")\n",
    "    line[\"center\"] = rolling_apply(line[\"metric\"].values, roll_win, agg_key(agg_name))\n",
    "    return line[[\"doy\",\"center\"]]\n",
    "\n",
    "def plot_time_series(df_stats, title, ylab, bands=(\"p10p90\",\"p25p75\",\"minmax\"),\n",
    "                     flow_stats=None, y2lab=\"Flow (m³/d)\"):\n",
    "    has_flow = flow_stats is not None and len(flow_stats)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": has_flow}]]) if has_flow else go.Figure()\n",
    "    x = df_stats[\"date\"]\n",
    "\n",
    "    if \"minmax\" in bands and {\"vmin\",\"vmax\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmax\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmin\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"min–max\", opacity=0.15), secondary_y=False if has_flow else None)\n",
    "\n",
    "    if \"p10p90\" in bands and {\"p10\",\"p90\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p90\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p10\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p10–p90\", opacity=0.20), secondary_y=False if has_flow else None)\n",
    "\n",
    "    if \"p25p75\" in bands and {\"p25\",\"p75\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p75\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p25\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p25–p75\", opacity=0.30), secondary_y=False if has_flow else None)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=df_stats[\"center\"], mode=\"lines\", name=\"Center\"),\n",
    "                  secondary_y=False if has_flow else None)\n",
    "\n",
    "    if has_flow:\n",
    "        fig.add_trace(go.Scatter(x=flow_stats[\"date\"], y=flow_stats[\"center\"], mode=\"lines\",\n",
    "                                 name=\"Flow\", line=dict(dash=\"dot\")), secondary_y=True)\n",
    "        fig.update_yaxes(title_text=y2lab, secondary_y=True)\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5, secondary_y=False if has_flow else None)\n",
    "    fig.update_layout(title=title, xaxis_title=\"Date\", yaxis_title=ylab, legend_title=None,\n",
    "                      margin=dict(l=40,r=20,t=50,b=40))\n",
    "    return fig\n",
    "\n",
    "def plot_climatology(df_stats, title, ylab, bands=(\"p10p90\",\"p25p75\",\"minmax\"),\n",
    "                     flow_stats=None, y2lab=\"Flow (m³/d)\"):\n",
    "    has_flow = flow_stats is not None and len(flow_stats)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": has_flow}]]) if has_flow else go.Figure()\n",
    "    x = df_stats[\"doy\"]\n",
    "\n",
    "    if \"minmax\" in bands and {\"vmin\",\"vmax\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmax\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmin\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"min–max\", opacity=0.15), secondary_y=False if has_flow else None)\n",
    "    if \"p10p90\" in bands and {\"p10\",\"p90\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p90\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p10\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p10–p90\", opacity=0.20), secondary_y=False if has_flow else None)\n",
    "    if \"p25p75\" in bands and {\"p25\",\"p75\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p75\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p25\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p25–p75\", opacity=0.30), secondary_y=False if has_flow else None)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=df_stats[\"center\"], mode=\"lines\", name=\"Center\"),\n",
    "                  secondary_y=False if has_flow else None)\n",
    "\n",
    "    if has_flow:\n",
    "        fig.add_trace(go.Scatter(x=flow_stats[\"doy\"], y=flow_stats[\"center\"], mode=\"lines\",\n",
    "                                 name=\"Flow\", line=dict(dash=\"dot\")), secondary_y=True)\n",
    "        fig.update_yaxes(title_text=y2lab, secondary_y=True)\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5, secondary_y=False if has_flow else None)\n",
    "    fig.update_layout(title=title, xaxis_title=\"Day of Year (1–365)\", yaxis_title=ylab, legend_title=None,\n",
    "                      margin=dict(l=40,r=20,t=50,b=40))\n",
    "    return fig\n",
    "\n",
    "def plot_all_years_overlay(lines_dict, title, ylab, flow_lines=None, y2lab=\"Flow (m³/d)\"):\n",
    "    has_flow = isinstance(flow_lines, dict) and len(flow_lines)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": has_flow}]]) if has_flow else go.Figure()\n",
    "\n",
    "    for y, d in lines_dict.items():\n",
    "        fig.add_trace(go.Scatter(x=d[\"date\"], y=d[\"metric\"], mode=\"lines\", name=str(y)),\n",
    "                      secondary_y=False if has_flow else None)\n",
    "\n",
    "    if has_flow:\n",
    "        for y, d in flow_lines.items():\n",
    "            fig.add_trace(go.Scatter(x=d[\"date\"], y=d[\"metric\"], mode=\"lines\",\n",
    "                                     name=f\"Flow {y}\", line=dict(dash=\"dot\")), secondary_y=True)\n",
    "        fig.update_yaxes(title_text=y2lab, secondary_y=True)\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5, secondary_y=False if has_flow else None)\n",
    "    fig.update_layout(title=title, xaxis_title=\"Date\", yaxis_title=ylab, legend_title=\"Year\",\n",
    "                      margin=dict(l=40,r=20,t=50,b=40))\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# ------------- UI: per-panel with method toggle -------------\n",
    "class ChartPanel:\n",
    "    PLOT_TYPES = [\n",
    "        \"Time series\",\n",
    "        \"DOY climatology\",\n",
    "        \"All years overlay\",\n",
    "        \"Year × Reach bars\",\n",
    "        \"Across-years avg per reach (DOY)\",\n",
    "        \"Across-years avg (all reaches, DOY)\",\n",
    "    ]\n",
    "    BAND_OPTIONS = [(\"p10–p90\",\"p10p90\"), (\"p25–p75\",\"p25p75\"), (\"min–max\",\"minmax\")]\n",
    "    METHOD_OPTIONS = [\n",
    "                        (\"Channel net balance — (OUT−IN) − DR×SYLD (tons)\", \"A\"),\n",
    "                        (\"Retained in reach — deposition = IN + DR×SYLD − OUT (tons)\", \"B\"),\n",
    "                        (\"Hydrology-normalized — Δ_channel per discharge (mg/L)\", \"C1\"),\n",
    "                        (\"Runoff-normalized — Δ_channel per runoff (kg/mm/ha)\", \"C2\"),\n",
    "     ]\n",
    "\n",
    "    def __init__(self, df_rch, df_sub,df_flow=None):\n",
    "        self.df_rch = df_rch\n",
    "        self.df_sub = df_sub\n",
    "        self.df_flow_raw = df_flow\n",
    "\n",
    "        # defaults\n",
    "        self.method = W.Dropdown(options=self.METHOD_OPTIONS, value=\"A\", description=\"Method\")\n",
    "        self.DR = W.FloatSlider(value=1.0, min=0.0, max=1.0, step=0.05, description=\"DR\", readout_format=\".2f\", continuous_update=False)\n",
    "\n",
    "        # we build an initial metric table to populate reach/year lists\n",
    "        base = build_metric_table(self.df_rch, self.df_sub, True, self.method.value, self.DR.value)\n",
    "        self.all_reaches = sorted(base[\"RCH\"].unique().tolist())\n",
    "        self.all_years   = sorted(base[\"year\"].unique().tolist())\n",
    "\n",
    "        self.plot_type = W.Dropdown(options=self.PLOT_TYPES, value=\"Time series\", description=\"Plot\")\n",
    "        self.reach_sel = W.SelectMultiple(options=self.all_reaches, value=tuple(self.all_reaches[:3]), description=\"Reaches\", rows=7)\n",
    "        self.year_sel  = W.SelectMultiple(options=self.all_years, value=tuple(self.all_years), description=\"Years\", rows=7)\n",
    "        self.agg = W.ToggleButtons(options=[\"Mean\",\"Median\"], value=\"Mean\", description=\"Aggregate\")\n",
    "        self.roll = W.IntSlider(value=7, min=1, max=60, step=1, description=\"Rolling (d)\", continuous_update=False)\n",
    "        self.drop_feb = W.Checkbox(value=True, description=\"Drop Feb 29\")\n",
    "        self.band_sel = W.SelectMultiple(options=[lbl for lbl,_ in self.BAND_OPTIONS],\n",
    "                                         value=(\"p10–p90\",\"p25–p75\"), rows=4, description=\"Bands\")\n",
    "        self.out = W.Output()\n",
    "\n",
    "        # Wire\n",
    "        for w in [self.method, self.DR, self.plot_type, self.reach_sel, self.year_sel, self.agg, self.roll, self.drop_feb, self.band_sel]:\n",
    "            w.observe(self.render, names=\"value\")\n",
    "\n",
    "        # Initial render\n",
    "        self.render(None)\n",
    "\n",
    "    def _band_keys(self):\n",
    "        labels = set(self.band_sel.value)\n",
    "        return tuple(dict(self.BAND_OPTIONS)[lbl] for lbl in labels if lbl in dict(self.BAND_OPTIONS))\n",
    "\n",
    "    def widget(self):\n",
    "        return W.VBox([\n",
    "            W.HBox([self.plot_type, self.method, self.DR, self.agg, self.roll]),\n",
    "            W.HBox([self.reach_sel, self.year_sel, W.VBox([self.drop_feb, self.band_sel])]),\n",
    "            self.out\n",
    "        ])\n",
    "\n",
    "    def render(self, _):\n",
    "        with self.out:\n",
    "            self.out.clear_output(wait=True)\n",
    "\n",
    "            # Build table of the chosen method (contains y-label in attrs)\n",
    "            subm = build_metric_table(self.df_rch, self.df_sub, self.drop_feb.value, self.method.value, self.DR.value)\n",
    "            ylab = subm.attrs.get(\"ylab\", \"Metric\")\n",
    "            reaches = list(self.reach_sel.value) or sorted(subm[\"RCH\"].unique())\n",
    "            years   = list(self.year_sel.value)  or sorted(subm[\"year\"].unique())\n",
    "            agg_name = self.agg.value\n",
    "            roll = int(self.roll.value)\n",
    "            bands = self._band_keys()\n",
    "\n",
    "            if self.plot_type.value == \"Time series\":\n",
    "                stats = set(bands)\n",
    "                data = compose_time_aggregate(subm, reaches, years, agg_name, stats, roll)\n",
    "                fig = plot_time_series(data, \"Time series — aggregated over selected reaches\", ylab, bands)\n",
    "\n",
    "            elif self.plot_type.value == \"DOY climatology\":\n",
    "                data = compose_climatology(subm, reaches, years, agg_name, set(bands), roll)\n",
    "                fig = plot_climatology(data, \"DOY climatology — selected reaches & years\", ylab, bands)\n",
    "\n",
    "            elif self.plot_type.value == \"All years overlay\":\n",
    "                lines = compose_all_years_overlay(subm, reaches, agg_name, roll)\n",
    "                fig = plot_all_years_overlay(lines, \"All years overlay (one line per year)\", ylab)\n",
    "\n",
    "            elif self.plot_type.value == \"Year × Reach bars\":\n",
    "                df_yr = compose_year_reach(subm, reaches, years)\n",
    "                fig = plot_year_reach_bars(df_yr, \"Year × Reach mean (center metric)\", ylab)\n",
    "\n",
    "            elif self.plot_type.value == \"Across-years avg per reach (DOY)\":\n",
    "                fig = go.Figure()\n",
    "                s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "                if years: s = s[s[\"year\"].isin(years)]\n",
    "                for r in sorted(set(reaches)):\n",
    "                    rsub = s[s[\"RCH\"]==r]\n",
    "                    line = rsub.groupby(\"doy\")[\"metric\"].agg(agg_key(agg_name)).reset_index().sort_values(\"doy\")\n",
    "                    line[\"metric\"] = rolling_apply(line[\"metric\"].values, roll, agg_key(agg_name))\n",
    "                    fig.add_trace(go.Scatter(x=line[\"doy\"], y=line[\"metric\"], mode=\"lines\", name=f\"R{r}\"))\n",
    "                fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5)\n",
    "                fig.update_layout(title=f\"Across-years DOY average per reach ({agg_name})\",\n",
    "                                  xaxis_title=\"Day of Year (1–365)\", yaxis_title=ylab,\n",
    "                                  legend_title=None, margin=dict(l=40,r=20,t=50,b=40))\n",
    "\n",
    "            elif self.plot_type.value == \"Across-years avg (all reaches, DOY)\":\n",
    "                line = compose_across_years_all_reaches(subm[subm[\"year\"].isin(years)], reaches, agg_name, roll)\n",
    "                fig = go.Figure([go.Scatter(x=line[\"doy\"], y=line[\"center\"], mode=\"lines\", name=f\"{agg_name}\")])\n",
    "                fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5)\n",
    "                fig.update_layout(title=f\"Across-years DOY average (all selected reaches) — {agg_name}\",\n",
    "                                  xaxis_title=\"Day of Year (1–365)\", yaxis_title=ylab,\n",
    "                                  margin=dict(l=40,r=20,t=50,b=40))\n",
    "            else:\n",
    "                fig = go.Figure()\n",
    "\n",
    "            fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots  # <-- add at top with other imports\n",
    "\n",
    "# ---- Flow helpers (Cubillas) ----\n",
    "def prep_flow(df_flow: pd.DataFrame, drop_feb29: bool) -> pd.DataFrame:\n",
    "    df = df_flow.rename(columns={\"date\":\"date\", \"water_flow_m3_d_cubillas\":\"flow\"}).copy()\n",
    "    df[\"date\"] = to_datetime(df[\"date\"])\n",
    "    if drop_feb29:\n",
    "        m = df[\"date\"].dt.month; d = df[\"date\"].dt.day\n",
    "        df = df[~((m==2) & (d==29))]\n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "    df[\"doy\"]  = df[\"date\"].dt.dayofyear\n",
    "    return df[[\"date\",\"year\",\"doy\",\"flow\"]].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def compose_time_aggregate_flow(df_flow_prep: pd.DataFrame, years, agg_name: str, roll_win: int):\n",
    "    s = df_flow_prep.copy()\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "    g = s.groupby(\"date\", as_index=False)[\"flow\"].agg(agg_key(agg_name)).rename(columns={\"flow\":\"center\"})\n",
    "    g = g.sort_values(\"date\")\n",
    "    g[\"center\"] = rolling_apply(g[\"center\"].values, roll_win, agg_key(agg_name))\n",
    "    return g\n",
    "\n",
    "def compose_climatology_flow(df_flow_prep: pd.DataFrame, years, agg_name: str, roll_win: int):\n",
    "    s = df_flow_prep.copy()\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "    g = s.groupby(\"doy\", as_index=False)[\"flow\"].agg(agg_key(agg_name)).rename(columns={\"flow\":\"center\"})\n",
    "    g = g.sort_values(\"doy\")\n",
    "    g[\"center\"] = rolling_apply(g[\"center\"].values, roll_win, agg_key(agg_name))\n",
    "    return g\n",
    "\n",
    "def compose_all_years_overlay_flow(df_flow_prep: pd.DataFrame, agg_name: str, roll_win: int):\n",
    "    lines = {}\n",
    "    for y in sorted(df_flow_prep[\"year\"].unique()):\n",
    "        d = df_flow_prep[df_flow_prep[\"year\"]==y][[\"date\",\"flow\"]].rename(columns={\"flow\":\"metric\"}).copy()\n",
    "        d = d.groupby(\"date\", as_index=False)[\"metric\"].agg(agg_key(agg_name))\n",
    "        d = d.sort_values(\"date\")\n",
    "        d[\"metric\"] = rolling_apply(d[\"metric\"].values, roll_win, agg_key(agg_name))\n",
    "        lines[y] = d\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sediment / TP / TN Dynamics Dashboard — methods A/B/C + Constituent toggle\n",
    "# ----------------------------------------------------------------------------\n",
    "# Methods (one time series per reach):\n",
    "#  A: Δ_channel = (OUT − IN) − DR * local_yield\n",
    "#  B: Retained  = (IN + DR * local_yield) − OUT  (= −Δ_channel)\n",
    "#  C1: Hydrology-normalized Δ_channel per discharge [mg/L]  (uses FLOW_OUTcms)\n",
    "#  C2: Hydrology-normalized Δ_channel per runoff    [kg/mm/ha] (uses WYLD + area)\n",
    "#\n",
    "# Constituents:\n",
    "#  - Sediment (tons): uses SED_INtons / SED_OUTtons; local_yield = SYLD (tons/ha) × area_ha × DR_sed\n",
    "#  - Total Phosphorus (kg): OUT/IN = ORGP ± MINP; local_yield = (ORGP+SEDP)*DR_partic + SOLP*DR_diss (all kg/ha × area_ha)\n",
    "#  - Total Nitrogen (kg):   OUT/IN = ORGN ± NO3 ± NH4 ± NO2; local_yield = ORGN*DR_partic + NSURQ*DR_diss (kg/ha × area_ha)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as W\n",
    "from IPython.display import display\n",
    "\n",
    "# --------------- Helpers ---------------\n",
    "def to_datetime(s): return pd.to_datetime(s)\n",
    "\n",
    "def agg_key(name: str) -> str:\n",
    "    return \"mean\" if name == \"Mean\" else \"median\"\n",
    "\n",
    "def rolling_apply(x, win, reducer_key):\n",
    "    if win is None or win <= 1:\n",
    "        return np.asarray(x)\n",
    "    f = np.nanmean if reducer_key == \"mean\" else np.nanmedian\n",
    "    return pd.Series(x).rolling(win, min_periods=max(1, win // 2)).apply(lambda s: f(s.values), raw=False).values\n",
    "\n",
    "def quantiles(a, qs):\n",
    "    a = np.asarray(a, dtype=float); a = a[~np.isnan(a)]\n",
    "    if a.size == 0: return {q: np.nan for q in qs}\n",
    "    qq = np.quantile(a, qs)\n",
    "    return {q: float(v) for q, v in zip(qs, qq)}\n",
    "\n",
    "def band_fill(fig, x, high, low, name, opacity=0.2):\n",
    "    fig.add_trace(go.Scatter(x=x, y=high, mode=\"lines\", line=dict(width=0), showlegend=False, hoverinfo=\"skip\"))\n",
    "    fig.add_trace(go.Scatter(x=x, y=low,  mode=\"lines\", line=dict(width=0), fill=\"tonexty\", name=name, opacity=opacity))\n",
    "\n",
    "def _sum_cols(df, cols):\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    if not cols: return pd.Series(0.0, index=df.index)\n",
    "    return df[cols].fillna(0).sum(axis=1)\n",
    "\n",
    "# ------------- Method engine (by constituent) -------------\n",
    "def build_metric_table(\n",
    "    df_rch: pd.DataFrame,\n",
    "    df_sub: pd.DataFrame,\n",
    "    drop_feb29: bool,\n",
    "    method: str,\n",
    "    constituent: str,         # \"SED\" | \"TP\" | \"TN\"\n",
    "    DR_sed: float = 1.0,      # for sediment\n",
    "    DR_partic: float = 0.7,   # for particulate (ORGN, ORGP, SEDP)\n",
    "    DR_diss: float = 0.95,    # for dissolved (NO3, NH4, NO2, SOLP, NSURQ)\n",
    "    # column mappings (keep your names)\n",
    "    cols_rch=dict(\n",
    "        date=\"date\", reach=\"RCH\",\n",
    "        sed_in=\"SED_INtons\", sed_out=\"SED_OUTtons\", flow_out=\"FLOW_OUTcms\",\n",
    "        # P (kg)\n",
    "        ORGP_IN=\"ORGP_INkg\", ORGP_OUT=\"ORGP_OUTkg\",\n",
    "        MINP_IN=\"MINP_INkg\", MINP_OUT=\"MINP_OUTkg\",\n",
    "        # N (kg)\n",
    "        ORGN_IN=\"ORGN_INkg\", ORGN_OUT=\"ORGN_OUTkg\",\n",
    "        NO3_IN=\"NO3_INkg\",  NO3_OUT=\"NO3_OUTkg\",\n",
    "        NH4_IN=\"NH4_INkg\",  NH4_OUT=\"NH4_OUTkg\",\n",
    "        NO2_IN=\"NO2_INkg\",  NO2_OUT=\"NO2_OUTkg\",\n",
    "    ),\n",
    "    cols_sub=dict(\n",
    "        date=\"date\", sub=\"SUB\", area_km2=\"AREA\", wyld_mm=\"WYLD\",\n",
    "        syld_t_ha=\"SYLD\",       # sediment (tons/ha)\n",
    "        ORGP=\"ORGP\", SOLP=\"SOLP\", SEDP=\"SEDP\",  # P (kg/ha)\n",
    "        ORGN=\"ORGN\", NSURQ=\"NSURQ\",             # N (kg/ha)\n",
    "    ),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns columns: date, RCH, year, doy, metric; y-label in out.attrs['ylab'].\n",
    "    \"\"\"\n",
    "    # ---- rename minimally\n",
    "    r = df_rch.rename(columns={\n",
    "        cols_rch[\"date\"]:\"date\", cols_rch[\"reach\"]:\"RCH\",\n",
    "        cols_rch[\"sed_in\"]:\"SED_IN\", cols_rch[\"sed_out\"]:\"SED_OUT\", cols_rch[\"flow_out\"]:\"FLOW_OUTcms\",\n",
    "        # P\n",
    "        cols_rch.get(\"ORGP_IN\",\"ORGP_INkg\"):\"ORGP_INkg\", cols_rch.get(\"ORGP_OUT\",\"ORGP_OUTkg\"):\"ORGP_OUTkg\",\n",
    "        cols_rch.get(\"MINP_IN\",\"MINP_INkg\"):\"MINP_INkg\", cols_rch.get(\"MINP_OUT\",\"MINP_OUTkg\"):\"MINP_OUTkg\",\n",
    "        # N\n",
    "        cols_rch.get(\"ORGN_IN\",\"ORGN_INkg\"):\"ORGN_INkg\", cols_rch.get(\"ORGN_OUT\",\"ORGN_OUTkg\"):\"ORGN_OUTkg\",\n",
    "        cols_rch.get(\"NO3_IN\",\"NO3_INkg\"):\"NO3_INkg\",   cols_rch.get(\"NO3_OUT\",\"NO3_OUTkg\"):\"NO3_OUTkg\",\n",
    "        cols_rch.get(\"NH4_IN\",\"NH4_INkg\"):\"NH4_INkg\",   cols_rch.get(\"NH4_OUT\",\"NH4_OUTkg\"):\"NH4_OUTkg\",\n",
    "        cols_rch.get(\"NO2_IN\",\"NO2_INkg\"):\"NO2_INkg\",   cols_rch.get(\"NO2_OUT\",\"NO2_OUTkg\"):\"NO2_OUTkg\",\n",
    "    }).copy()\n",
    "    s = df_sub.rename(columns={\n",
    "        cols_sub[\"date\"]:\"date\", cols_sub[\"sub\"]:\"SUB\", cols_sub[\"area_km2\"]:\"SUB_AREA_KM2\",\n",
    "        cols_sub[\"wyld_mm\"]:\"WYLD_MM\", cols_sub[\"syld_t_ha\"]:\"SYLD_T_HA\",\n",
    "        cols_sub.get(\"ORGP\",\"ORGP\"):\"ORGP\", cols_sub.get(\"SOLP\",\"SOLP\"):\"SOLP\", cols_sub.get(\"SEDP\",\"SEDP\"):\"SEDP\",\n",
    "        cols_sub.get(\"ORGN\",\"ORGN\"):\"ORGN\", cols_sub.get(\"NSURQ\",\"NSURQ\"):\"NSURQ\",\n",
    "    }).copy()\n",
    "\n",
    "    r[\"date\"] = to_datetime(r[\"date\"]); s[\"date\"] = to_datetime(s[\"date\"])\n",
    "\n",
    "    # select needed rch columns by constituent\n",
    "    base_cols = [\"date\",\"RCH\",\"FLOW_OUTcms\"]\n",
    "    if constituent == \"SED\":\n",
    "        need_r = base_cols + [\"SED_IN\",\"SED_OUT\"]\n",
    "    elif constituent == \"TP\":\n",
    "        need_r = base_cols + [\"ORGP_INkg\",\"MINP_INkg\",\"ORGP_OUTkg\",\"MINP_OUTkg\"]\n",
    "    else:  # \"TN\"\n",
    "        need_r = base_cols + [\"ORGN_INkg\",\"NO3_INkg\",\"NH4_INkg\",\"NO2_INkg\",\n",
    "                               \"ORGN_OUTkg\",\"NO3_OUTkg\",\"NH4_OUTkg\",\"NO2_OUTkg\"]\n",
    "\n",
    "    need_r = [c for c in need_r if c in r.columns]\n",
    "    r_use = r[need_r].copy()\n",
    "\n",
    "    s_use = s[[\"date\",\"SUB\",\"SUB_AREA_KM2\",\"WYLD_MM\",\"SYLD_T_HA\",\"ORGP\",\"SOLP\",\"SEDP\",\"ORGN\",\"NSURQ\"]].copy()\n",
    "\n",
    "    # merge reach & sub\n",
    "    m = pd.merge(r_use, s_use, left_on=[\"date\",\"RCH\"], right_on=[\"date\",\"SUB\"], how=\"inner\").drop(columns=[\"SUB\"])\n",
    "\n",
    "    # area conversion (km² -> ha)\n",
    "    m[\"SUB_AREA_HA\"] = m[\"SUB_AREA_KM2\"] * 100.0\n",
    "\n",
    "    # build IN/OUT & local delivered per constituent\n",
    "    if constituent == \"SED\":\n",
    "        X_IN  = m[\"SED_IN\"].astype(float)\n",
    "        X_OUT = m[\"SED_OUT\"].astype(float)\n",
    "        local = DR_sed * (m[\"SYLD_T_HA\"].astype(float) * m[\"SUB_AREA_HA\"])  # tons\n",
    "        unit = \"tons\"\n",
    "        # Δ channel (tons)\n",
    "        delta_channel = (X_OUT - X_IN) - local\n",
    "\n",
    "        # method transforms\n",
    "        if method.upper() == \"A\":\n",
    "            metric = delta_channel; ylab = \"Δ_channel (tons)\"\n",
    "        elif method.upper() == \"B\":\n",
    "            metric = -delta_channel; ylab = \"Retained (tons)\"\n",
    "        elif method.upper() == \"C1\":\n",
    "            q = m[\"FLOW_OUTcms\"].replace(0, np.nan).astype(float)\n",
    "            metric = delta_channel * 11.574074 / q  # tons/day → mg/L approx\n",
    "            ylab = \"Δ_channel per discharge (mg/L)\"\n",
    "        elif method.upper() == \"C2\":\n",
    "            denom = (m[\"WYLD_MM\"] * m[\"SUB_AREA_HA\"]).replace(0, np.nan)  # mm * ha\n",
    "            metric = (delta_channel * 1000.0) / denom  # tons → kg; kg/(mm·ha)\n",
    "            ylab = \"Δ_channel per runoff (kg/mm/ha)\"\n",
    "        else:\n",
    "            raise ValueError(\"method must be one of 'A','B','C1','C2'\")\n",
    "\n",
    "    elif constituent == \"TP\":\n",
    "        # IN/OUT in kg\n",
    "        IN_cols  = [\"ORGP_INkg\",\"MINP_INkg\"]\n",
    "        OUT_cols = [\"ORGP_OUTkg\",\"MINP_OUTkg\"]\n",
    "        X_IN  = _sum_cols(m, IN_cols).astype(float)\n",
    "        X_OUT = _sum_cols(m, OUT_cols).astype(float)\n",
    "        # local delivered in kg: particulate (ORGP+SEDP) × DR_partic + dissolved (SOLP) × DR_diss\n",
    "        local = ((m[\"ORGP\"].fillna(0) + m[\"SEDP\"].fillna(0)) * DR_partic +\n",
    "                  m[\"SOLP\"].fillna(0) * DR_diss) * m[\"SUB_AREA_HA\"]\n",
    "        delta_channel = (X_OUT - X_IN) - local\n",
    "        unit = \"kg\"\n",
    "\n",
    "        if method.upper() == \"A\":\n",
    "            metric = delta_channel; ylab = \"Δ_channel TP (kg)\"\n",
    "        elif method.upper() == \"B\":\n",
    "            metric = -delta_channel; ylab = \"Retained TP (kg)\"\n",
    "        elif method.upper() == \"C1\":\n",
    "            q = m[\"FLOW_OUTcms\"].replace(0, np.nan).astype(float)\n",
    "            metric = delta_channel * 0.011574074 / q   # kg/day → mg/L\n",
    "            ylab = \"Δ_channel TP per discharge (mg/L)\"\n",
    "        elif method.upper() == \"C2\":\n",
    "            denom = (m[\"WYLD_MM\"] * m[\"SUB_AREA_HA\"]).replace(0, np.nan)\n",
    "            metric = delta_channel / denom  # kg/(mm·ha)\n",
    "            ylab = \"Δ_channel TP per runoff (kg/mm/ha)\"\n",
    "        else:\n",
    "            raise ValueError(\"method must be one of 'A','B','C1','C2'\")\n",
    "\n",
    "    else:  # \"TN\"\n",
    "        IN_cols  = [\"ORGN_INkg\",\"NO3_INkg\",\"NH4_INkg\",\"NO2_INkg\"]\n",
    "        OUT_cols = [\"ORGN_OUTkg\",\"NO3_OUTkg\",\"NH4_OUTkg\",\"NO2_OUTkg\"]\n",
    "        X_IN  = _sum_cols(m, IN_cols).astype(float)\n",
    "        X_OUT = _sum_cols(m, OUT_cols).astype(float)\n",
    "        # local delivered in kg: ORGN × DR_partic + NSURQ × DR_diss\n",
    "        local = (m[\"ORGN\"].fillna(0) * DR_partic + m[\"NSURQ\"].fillna(0) * DR_diss) * m[\"SUB_AREA_HA\"]\n",
    "        delta_channel = (X_OUT - X_IN) - local\n",
    "        unit = \"kg\"\n",
    "\n",
    "        if method.upper() == \"A\":\n",
    "            metric = delta_channel; ylab = \"Δ_channel TN (kg)\"\n",
    "        elif method.upper() == \"B\":\n",
    "            metric = -delta_channel; ylab = \"Retained TN (kg)\"\n",
    "        elif method.upper() == \"C1\":\n",
    "            q = m[\"FLOW_OUTcms\"].replace(0, np.nan).astype(float)\n",
    "            metric = delta_channel * 0.011574074 / q   # kg/day → mg/L\n",
    "            ylab = \"Δ_channel TN per discharge (mg/L)\"\n",
    "        elif method.upper() == \"C2\":\n",
    "            denom = (m[\"WYLD_MM\"] * m[\"SUB_AREA_HA\"]).replace(0, np.nan)\n",
    "            metric = delta_channel / denom  # kg/(mm·ha)\n",
    "            ylab = \"Δ_channel TN per runoff (kg/mm/ha)\"\n",
    "        else:\n",
    "            raise ValueError(\"method must be one of 'A','B','C1','C2'\")\n",
    "\n",
    "    out = m[[\"date\",\"RCH\"]].copy()\n",
    "    out[\"metric\"] = metric.values\n",
    "    out[\"year\"] = pd.to_datetime(out[\"date\"]).dt.year\n",
    "    out[\"month\"] = pd.to_datetime(out[\"date\"]).dt.month\n",
    "    out[\"day\"] = pd.to_datetime(out[\"date\"]).dt.day\n",
    "    if drop_feb29:\n",
    "        out = out[~((out[\"month\"]==2) & (out[\"day\"]==29))]\n",
    "    out[\"doy\"] = pd.to_datetime(out[\"date\"]).dt.dayofyear\n",
    "    out.drop(columns=[\"month\",\"day\"], inplace=True)\n",
    "    out.attrs[\"ylab\"] = ylab\n",
    "    out.attrs[\"unit\"] = unit\n",
    "    return out.reset_index(drop=True)\n",
    "\n",
    "# ------------- Aggregators (re-used) -------------\n",
    "def compose_time_aggregate(subm: pd.DataFrame, reaches, years, agg_name: str, stats, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "    if len(reaches) > 1:\n",
    "        grouped = s.groupby(\"date\", as_index=False)[\"metric\"].agg(agg_key(agg_name)).rename(columns={\"metric\":\"center\"})\n",
    "    else:\n",
    "        grouped = s.groupby(\"date\", as_index=False)[\"metric\"].agg(\"mean\").rename(columns={\"metric\":\"center\"})\n",
    "    if len(reaches) > 1:\n",
    "        tmp = s.groupby([\"date\",\"RCH\"])[\"metric\"].agg(\"mean\").reset_index()\n",
    "        rows=[]\n",
    "        for d,g in tmp.groupby(\"date\"):\n",
    "            vals=g[\"metric\"].values; row={\"date\":d}\n",
    "            if \"p10p90\" in stats: row.update(quantiles(vals,[0.10,0.90]))\n",
    "            if \"p25p75\" in stats:\n",
    "                q=quantiles(vals,[0.25,0.75]); row.update({\"p25\":q[0.25],\"p75\":q[0.75]})\n",
    "            if \"minmax\" in stats and len(vals):\n",
    "                row.update({\"vmin\":float(np.nanmin(vals)),\"vmax\":float(np.nanmax(vals))})\n",
    "            rows.append(row)\n",
    "        grouped = grouped.merge(pd.DataFrame(rows), on=\"date\", how=\"left\")\n",
    "    grouped = grouped.sort_values(\"date\")\n",
    "    reducer = agg_key(agg_name)\n",
    "    grouped[\"center\"] = rolling_apply(grouped[\"center\"].values, roll_win, reducer)\n",
    "    for col in [\"p10\",\"p90\",\"p25\",\"p75\",\"vmin\",\"vmax\"]:\n",
    "        if col in grouped.columns:\n",
    "            grouped[col] = rolling_apply(grouped[col].values, roll_win, \"mean\")\n",
    "    return grouped\n",
    "\n",
    "def compose_climatology(subm: pd.DataFrame, reaches, years, agg_name: str, stats, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "    center = s.groupby(\"doy\")[\"metric\"].agg(agg_key(agg_name)).rename(\"center\").reset_index()\n",
    "    tmp = s.groupby([\"doy\",\"year\",\"RCH\"])[\"metric\"].agg(\"mean\").reset_index()\n",
    "    rows=[]\n",
    "    for d,g in tmp.groupby(\"doy\"):\n",
    "        vals=g[\"metric\"].values; row={\"doy\":d}\n",
    "        if \"p10p90\" in stats: row.update(quantiles(vals,[0.10,0.90]))\n",
    "        if \"p25p75\" in stats:\n",
    "            q=quantiles(vals,[0.25,0.75]); row.update({\"p25\":q[0.25],\"p75\":q[0.75]})\n",
    "        if \"minmax\" in stats and len(vals):\n",
    "            row.update({\"vmin\":float(np.nanmin(vals)),\"vmax\":float(np.nanmax(vals))})\n",
    "        rows.append(row)\n",
    "    out = center.merge(pd.DataFrame(rows), on=\"doy\", how=\"left\").sort_values(\"doy\")\n",
    "    reducer = agg_key(agg_name)\n",
    "    out[\"center\"] = rolling_apply(out[\"center\"].values, roll_win, reducer)\n",
    "    for col in [\"p10\",\"p90\",\"p25\",\"p75\",\"vmin\",\"vmax\"]:\n",
    "        if col in out.columns:\n",
    "            out[col] = rolling_apply(out[col].values, roll_win, \"mean\")\n",
    "    return out\n",
    "\n",
    "def compose_all_years_overlay(subm: pd.DataFrame, reaches, agg_name: str, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    years = sorted(s[\"year\"].unique()); lines={}\n",
    "    for y in years:\n",
    "        ydf = s[s[\"year\"]==y]\n",
    "        if len(reaches)>1:\n",
    "            daily = ydf.groupby(\"date\")[\"metric\"].agg(agg_key(agg_name)).reset_index()\n",
    "        else:\n",
    "            daily = ydf.groupby(\"date\")[\"metric\"].agg(\"mean\").reset_index()\n",
    "        daily = daily.sort_values(\"date\")\n",
    "        daily[\"metric\"] = rolling_apply(daily[\"metric\"].values, roll_win, agg_key(agg_name))\n",
    "        lines[y] = daily\n",
    "    return lines\n",
    "\n",
    "def compose_year_reach(subm: pd.DataFrame, reaches, years):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "    if years: s = s[s[\"year\"].isin(years)]\n",
    "    return s.groupby([\"year\",\"RCH\"])[\"metric\"].agg(\"mean\").reset_index().rename(columns={\"metric\":\"delta\"})\n",
    "\n",
    "def compose_across_years_all_reaches(subm: pd.DataFrame, reaches, agg_name: str, roll_win: int):\n",
    "    s = subm[subm[\"RCH\"].isin(reaches)] if reaches else subm.copy()\n",
    "    line = s.groupby(\"doy\")[\"metric\"].agg(agg_key(agg_name)).reset_index().sort_values(\"doy\")\n",
    "    line[\"center\"] = rolling_apply(line[\"metric\"].values, roll, agg_key(agg_name))\n",
    "    return line[[\"doy\",\"center\"]]\n",
    "\n",
    "# ------------- Plotters -------------\n",
    "def plot_time_series(df_stats, title, ylab, bands=(\"p10p90\",\"p25p75\",\"minmax\"),\n",
    "                     flow_stats=None, y2lab=\"Flow (m³/d)\"):\n",
    "    has_flow = flow_stats is not None and len(flow_stats)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": has_flow}]]) if has_flow else go.Figure()\n",
    "    x = df_stats[\"date\"]\n",
    "\n",
    "    if \"minmax\" in bands and {\"vmin\",\"vmax\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmax\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmin\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"min–max\", opacity=0.15), secondary_y=False if has_flow else None)\n",
    "\n",
    "    if \"p10p90\" in bands and {\"p10\",\"p90\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p90\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p10\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p10–p90\", opacity=0.20), secondary_y=False if has_flow else None)\n",
    "\n",
    "    if \"p25p75\" in bands and {\"p25\",\"p75\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p75\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p25\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p25–p75\", opacity=0.30), secondary_y=False if has_flow else None)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=df_stats[\"center\"], mode=\"lines\", name=\"Center\"),\n",
    "                  secondary_y=False if has_flow else None)\n",
    "\n",
    "    if has_flow:\n",
    "        fig.add_trace(go.Scatter(x=flow_stats[\"date\"], y=flow_stats[\"center\"], mode=\"lines\",\n",
    "                                 name=\"Flow\", line=dict(dash=\"dot\")), secondary_y=True)\n",
    "        fig.update_yaxes(title_text=y2lab, secondary_y=True)\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5, secondary_y=False if has_flow else None)\n",
    "    fig.update_layout(title=title, xaxis_title=\"Date\", yaxis_title=ylab, legend_title=None,\n",
    "                      margin=dict(l=40,r=20,t=50,b=40))\n",
    "    return fig\n",
    "\n",
    "def plot_climatology(df_stats, title, ylab, bands=(\"p10p90\",\"p25p75\",\"minmax\"),\n",
    "                     flow_stats=None, y2lab=\"Flow (m³/d)\"):\n",
    "    has_flow = flow_stats is not None and len(flow_stats)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": has_flow}]]) if has_flow else go.Figure()\n",
    "    x = df_stats[\"doy\"]\n",
    "\n",
    "    if \"minmax\" in bands and {\"vmin\",\"vmax\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmax\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"vmin\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"min–max\", opacity=0.15), secondary_y=False if has_flow else None)\n",
    "    if \"p10p90\" in bands and {\"p10\",\"p90\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p90\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p10\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p10–p90\", opacity=0.20), secondary_y=False if has_flow else None)\n",
    "    if \"p25p75\" in bands and {\"p25\",\"p75\"}.issubset(df_stats.columns):\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p75\"], mode=\"lines\", line=dict(width=0),\n",
    "                                 showlegend=False, hoverinfo=\"skip\"), secondary_y=False if has_flow else None)\n",
    "        fig.add_trace(go.Scatter(x=x, y=df_stats[\"p25\"], mode=\"lines\", line=dict(width=0), fill=\"tonexty\",\n",
    "                                 name=\"p25–p75\", opacity=0.30), secondary_y=False if has_flow else None)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=df_stats[\"center\"], mode=\"lines\", name=\"Center\"),\n",
    "                  secondary_y=False if has_flow else None)\n",
    "\n",
    "    if has_flow:\n",
    "        fig.add_trace(go.Scatter(x=flow_stats[\"doy\"], y=flow_stats[\"center\"], mode=\"lines\",\n",
    "                                 name=\"Flow\", line=dict(dash=\"dot\")), secondary_y=True)\n",
    "        fig.update_yaxes(title_text=y2lab, secondary_y=True)\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5, secondary_y=False if has_flow else None)\n",
    "    fig.update_layout(title=title, xaxis_title=\"Day of Year (1–365)\", yaxis_title=ylab, legend_title=None,\n",
    "                      margin=dict(l=40,r=20,t=50,b=40))\n",
    "    return fig\n",
    "\n",
    "def plot_all_years_overlay(lines_dict, title, ylab, flow_lines=None, y2lab=\"Flow (m³/d)\"):\n",
    "    has_flow = isinstance(flow_lines, dict) and len(flow_lines)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": has_flow}]]) if has_flow else go.Figure()\n",
    "\n",
    "    for y, d in lines_dict.items():\n",
    "        fig.add_trace(go.Scatter(x=d[\"date\"], y=d[\"metric\"], mode=\"lines\", name=str(y)),\n",
    "                      secondary_y=False if has_flow else None)\n",
    "\n",
    "    if has_flow:\n",
    "        for y, d in flow_lines.items():\n",
    "            fig.add_trace(go.Scatter(x=d[\"date\"], y=d[\"metric\"], mode=\"lines\",\n",
    "                                     name=f\"Flow {y}\", line=dict(dash=\"dot\")), secondary_y=True)\n",
    "        fig.update_yaxes(title_text=y2lab, secondary_y=True)\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5, secondary_y=False if has_flow else None)\n",
    "    fig.update_layout(title=title, xaxis_title=\"Date\", yaxis_title=ylab, legend_title=\"Year\",\n",
    "                      margin=dict(l=40,r=20,t=50,b=40))\n",
    "    return fig\n",
    "\n",
    "\n",
    "# ------------- UI Panel -------------\n",
    "class ChartPanel:\n",
    "    PLOT_TYPES = [\n",
    "        \"Time series\",\n",
    "        \"DOY climatology\",\n",
    "        \"All years overlay\",\n",
    "        \"Year × Reach bars\",\n",
    "        \"Across-years avg per reach (DOY)\",\n",
    "        \"Across-years avg (all reaches, DOY)\",\n",
    "    ]\n",
    "    BAND_OPTIONS = [(\"p10–p90\",\"p10p90\"), (\"p25–p75\",\"p25p75\"), (\"min–max\",\"minmax\")]\n",
    "    METHOD_OPTIONS = [\n",
    "        (\"Channel net balance — (OUT−IN) − DR×local\", \"A\"),\n",
    "        (\"Retained in reach — (IN + DR×local − OUT)\", \"B\"),\n",
    "        (\"Hydrology-normalized — per discharge (mg/L)\", \"C1\"),\n",
    "        (\"Runoff-normalized — per runoff (kg/mm/ha)\", \"C2\"),\n",
    "    ]\n",
    "    CONSTITUENTS = [(\"Sediment\", \"SED\"), (\"Total Phosphorus (TP)\", \"TP\"), (\"Total Nitrogen (TN)\", \"TN\")]\n",
    "\n",
    "    def __init__(self, df_rch, df_sub, df_flow=None):\n",
    "        self.df_rch = df_rch\n",
    "        self.df_sub = df_sub\n",
    "        self.df_flow_raw = df_flow\n",
    "\n",
    "        #df_water_flow_m3_d_cubillas = pd.read_csv(r\"C:\\Users\\Usuario\\OneDrive - UNIVERSIDAD DE HUELVA\\Granada\\TrabajoFM\\Genil GEO_INFO_POOL\\Data Zip inicial Francisco\\CHGxSAIH\\Embalses\\E45SAIHInflowQR_most_current_Francisco\\E45SAIHInflowQR.csv\", index_col=False)\n",
    "\n",
    "        # controls\n",
    "        self.constit = W.Dropdown(options=self.CONSTITUENTS, value=\"SED\", description=\"Constituent\")\n",
    "        self.method  = W.Dropdown(options=self.METHOD_OPTIONS, value=\"A\", description=\"Method\")\n",
    "        self.DR_sed = W.FloatSlider(value=1.0, min=0.0, max=1.0, step=0.05, description=\"DR_sed\", readout_format=\".2f\", continuous_update=False)\n",
    "        self.DR_partic = W.FloatSlider(value=0.7, min=0.0, max=1.0, step=0.05, description=\"DR_partic\", readout_format=\".2f\", continuous_update=False)\n",
    "        self.DR_diss   = W.FloatSlider(value=0.95, min=0.0, max=1.0, step=0.05, description=\"DR_diss\", readout_format=\".2f\", continuous_update=False)\n",
    "\n",
    "        # initial metric table (for reach/year options)\n",
    "        base = build_metric_table(self.df_rch, self.df_sub, True, self.method.value, self.constit.value,\n",
    "                                  DR_sed=self.DR_sed.value, DR_partic=self.DR_partic.value, DR_diss=self.DR_diss.value)\n",
    "        self.all_reaches = sorted(base[\"RCH\"].unique().tolist())\n",
    "        self.all_years   = sorted(base[\"year\"].unique().tolist())\n",
    "\n",
    "        self.plot_type = W.Dropdown(options=self.PLOT_TYPES, value=\"Time series\", description=\"Plot\")\n",
    "        self.reach_sel = W.SelectMultiple(options=self.all_reaches, value=tuple(self.all_reaches[:3]), description=\"Reaches\", rows=7)\n",
    "        self.year_sel  = W.SelectMultiple(options=self.all_years, value=tuple(self.all_years), description=\"Years\", rows=7)\n",
    "        self.agg = W.ToggleButtons(options=[\"Mean\",\"Median\"], value=\"Mean\", description=\"Aggregate\")\n",
    "        self.roll = W.IntSlider(value=7, min=1, max=60, step=1, description=\"Rolling (d)\", continuous_update=False)\n",
    "        self.drop_feb = W.Checkbox(value=True, description=\"Drop Feb 29\")\n",
    "        self.band_sel = W.SelectMultiple(options=[lbl for lbl,_ in self.BAND_OPTIONS],\n",
    "                                         value=(\"p10–p90\",\"p25–p75\"), rows=4, description=\"Bands\")\n",
    "        self.show_flow = W.Checkbox(value=False, description=\"Overlay flow (right y-axis)\")\n",
    "        self.out = W.Output()\n",
    "\n",
    "        # wire up\n",
    "        for w in [self.constit, self.method, self.DR_sed, self.DR_partic, self.DR_diss,\n",
    "                  self.plot_type, self.reach_sel, self.year_sel, self.agg, self.roll, self.drop_feb, self.band_sel, self.show_flow]:\n",
    "            w.observe(self.render, names=\"value\")\n",
    "\n",
    "        self.render(None)\n",
    "\n",
    "    def _band_keys(self):\n",
    "        labels = set(self.band_sel.value)\n",
    "        return tuple(dict(self.BAND_OPTIONS)[lbl] for lbl in labels if lbl in dict(self.BAND_OPTIONS))\n",
    "\n",
    "    def widget(self):\n",
    "        return W.VBox([\n",
    "            W.HBox([self.plot_type, self.constit, self.method]),\n",
    "            W.HBox([self.DR_sed, self.DR_partic, self.DR_diss, self.agg, self.roll]),\n",
    "            W.HBox([self.reach_sel, self.year_sel, W.VBox([self.drop_feb, self.band_sel, self.show_flow])]),\n",
    "            self.out\n",
    "        ])\n",
    "\n",
    "    def render(self, _):\n",
    "        with self.out:\n",
    "            self.out.clear_output(wait=True)\n",
    "            subm = build_metric_table(\n",
    "                self.df_rch, self.df_sub,\n",
    "                self.drop_feb.value, self.method.value, self.constit.value,\n",
    "                DR_sed=self.DR_sed.value, DR_partic=self.DR_partic.value, DR_diss=self.DR_diss.value\n",
    "            )\n",
    "            ylab = subm.attrs.get(\"ylab\", \"Metric\")\n",
    "            reaches = list(self.reach_sel.value) or sorted(subm[\"RCH\"].unique())\n",
    "            years   = list(self.year_sel.value)  or sorted(subm[\"year\"].unique())\n",
    "            agg_name = self.agg.value\n",
    "            roll = int(self.roll.value)\n",
    "            bands = self._band_keys()\n",
    "\n",
    "            # --- flow overlay prep (optional)\n",
    "            flow_stats = None\n",
    "            flow_lines = None\n",
    "            if self.show_flow.value and self.df_flow_raw is not None:\n",
    "                flow_prep = prep_flow(self.df_flow_raw, self.drop_feb.value)\n",
    "                if self.plot_type.value == \"Time series\":\n",
    "                    flow_stats = compose_time_aggregate_flow(flow_prep, years, agg_name, roll)\n",
    "                elif self.plot_type.value == \"DOY climatology\":\n",
    "                    flow_stats = compose_climatology_flow(flow_prep, years, agg_name, roll)\n",
    "                elif self.plot_type.value == \"All years overlay\":\n",
    "                    flow_lines = compose_all_years_overlay_flow(flow_prep, agg_name, roll)\n",
    "\n",
    "            # --- plots\n",
    "            if self.plot_type.value == \"Time series\":\n",
    "                data = compose_time_aggregate(subm, reaches, years, agg_name, set(bands), roll)\n",
    "                fig = plot_time_series(data, \"Time series — aggregated over selected reaches\",\n",
    "                                       ylab, bands, flow_stats=flow_stats)\n",
    "\n",
    "            elif self.plot_type.value == \"DOY climatology\":\n",
    "                data = compose_climatology(subm, reaches, years, agg_name, set(bands), roll)\n",
    "                fig = plot_climatology(data, \"DOY climatology — selected reaches & years\",\n",
    "                                       ylab, bands, flow_stats=flow_stats)\n",
    "\n",
    "            elif self.plot_type.value == \"All years overlay\":\n",
    "                lines = compose_all_years_overlay(subm, reaches, agg_name, roll)\n",
    "                fig = plot_all_years_overlay(lines, \"All years overlay (one line per year)\",\n",
    "                                             ylab, flow_lines=flow_lines)\n",
    "\n",
    "            elif self.plot_type.value == \"Year × Reach bars\":\n",
    "                df_yr = compose_year_reach(subm, reaches, years)\n",
    "                fig = plot_year_reach_bars(df_yr, \"Year × Reach mean (center metric)\", ylab)\n",
    "\n",
    "            elif self.plot_type.value == \"Across-years avg per reach (DOY)\":\n",
    "                fig = go.Figure()\n",
    "                s = subm[subm[\"RCH\"].isin(reaches)]\n",
    "                if years: s = s[s[\"year\"].isin(years)]\n",
    "                for rch in sorted(set(reaches)):\n",
    "                    rsub = s[s[\"RCH\"]==rch]\n",
    "                    line = rsub.groupby(\"doy\")[\"metric\"].agg(agg_key(agg_name)).reset_index().sort_values(\"doy\")\n",
    "                    line[\"metric\"] = rolling_apply(line[\"metric\"].values, roll, agg_key(agg_name))\n",
    "                    fig.add_trace(go.Scatter(x=line[\"doy\"], y=line[\"metric\"], mode=\"lines\", name=f\"R{rch}\"))\n",
    "                fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5)\n",
    "                fig.update_layout(title=f\"Across-years DOY average per reach ({agg_name})\",\n",
    "                                  xaxis_title=\"Day of Year (1–365)\", yaxis_title=ylab,\n",
    "                                  legend_title=None, margin=dict(l=40,r=20,t=50,b=40))\n",
    "\n",
    "            elif self.plot_type.value == \"Across-years avg (all reaches, DOY)\":\n",
    "                line = compose_across_years_all_reaches(subm[subm[\"year\"].isin(years)], reaches, agg_name, roll)\n",
    "                fig = go.Figure([go.Scatter(x=line[\"doy\"], y=line[\"center\"], mode=\"lines\", name=f\"{agg_name}\")])\n",
    "                fig.add_hline(y=0, line_dash=\"dash\", opacity=0.5)\n",
    "                fig.update_layout(title=f\"Across-years DOY average (all selected reaches) — {agg_name}\",\n",
    "                                  xaxis_title=\"Day of Year (1–365)\", yaxis_title=ylab,\n",
    "                                  margin=dict(l=40,r=20,t=50,b=40))\n",
    "            else:\n",
    "                fig = go.Figure()\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601abe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_155.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_pipeline_scripts.sub_parser import parse_swat_sub_to_df\n",
    "df_sed_rch = dict_155['rch_run000155_real000526_1']\n",
    "#df_sed_rch = dict_145['rch_run000145_real000503_1']\n",
    "df_sub_yld = parse_swat_sub_to_df(r\"C:\\SWAT\\RSWAT\\cubillas\\mc_results\\run000117_real000404_1\\output.sub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net sediment difference calculations (added cell)\n",
    "# This cell derives two helper series from df_sed_rch if the needed columns exist:\n",
    "#   SED_IN_MINUS_OUT = SED_IN - SED_OUT\n",
    "#   SED_OUT_MINUS_IN = SED_OUT - SED_IN\n",
    "# It supports either column naming convention: SED_INtons/SED_OUTtons or SED_IN/SED_OUT.\n",
    "import pandas as _pd\n",
    "\n",
    "# Identify candidate column names\n",
    "_sed_in_cols = [c for c in df_sed_rch.columns if c.upper() in {\"SED_INTONS\", \"SED_IN\"}]\n",
    "_sed_out_cols = [c for c in df_sed_rch.columns if c.upper() in {\"SED_OUTTONS\", \"SED_OUT\"}]\n",
    "\n",
    "if _sed_in_cols and _sed_out_cols:\n",
    "    sed_in_col = _sed_in_cols[0]\n",
    "    sed_out_col = _sed_out_cols[0]\n",
    "    # Ensure datetime index\n",
    "    if not isinstance(df_sed_rch.index, _pd.DatetimeIndex):\n",
    "        # Try common date column names\n",
    "        for cand in [\"date\", \"DATE\", \"Date\", \"time\", \"TIME\"]:\n",
    "            if cand in df_sed_rch.columns:\n",
    "                df_sed_rch = df_sed_rch.set_index(_pd.to_datetime(df_sed_rch[cand]))\n",
    "                break\n",
    "    df_sed_rch[\"SED_IN_MINUS_OUT\"] = df_sed_rch[sed_in_col] - df_sed_rch[sed_out_col]\n",
    "    df_sed_rch[\"SED_OUT_MINUS_IN\"] = df_sed_rch[sed_out_col] - df_sed_rch[sed_in_col]\n",
    "    print(f\"Added net sediment columns using {sed_in_col} and {sed_out_col} -> SED_IN_MINUS_OUT / SED_OUT_MINUS_IN\")\n",
    "else:\n",
    "    print(\"Net sediment columns NOT added (required SED_IN*/SED_OUT* columns missing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly / Annual aggregations for sediment variables (including net differences)\n",
    "import pandas as _pd\n",
    "\n",
    "# Select the working dataframe\n",
    "sed_df = df_sed_rch.copy()\n",
    "# Ensure datetime index\n",
    "if not isinstance(sed_df.index, _pd.DatetimeIndex):\n",
    "    for cand in [\"date\", \"DATE\", \"Date\", \"time\", \"TIME\"]:\n",
    "        if cand in sed_df.columns:\n",
    "            sed_df = sed_df.set_index(_pd.to_datetime(sed_df[cand]))\n",
    "            break\n",
    "\n",
    "# Identify sediment related columns (original + derived)\n",
    "_sed_cols = [c for c in sed_df.columns if c.upper().startswith(\"SED_\")]\n",
    "print(f\"Sediment columns considered: {_sed_cols}\")\n",
    "\n",
    "# Build aggregations\n",
    "monthly_sum = sed_df[_sed_cols].resample('M').sum(min_count=1)\n",
    "monthly_mean = sed_df[_sed_cols].resample('M').mean()\n",
    "annual_sum = sed_df[_sed_cols].resample('Y').sum(min_count=1)\n",
    "annual_mean = sed_df[_sed_cols].resample('Y').mean()\n",
    "\n",
    "print(\"Monthly sum head:\\n\", monthly_sum.head())\n",
    "print(\"Annual sum head:\\n\", annual_sum.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e7de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple interactive selection for sediment aggregation view\n",
    "import ipywidgets as _w\n",
    "import plotly.graph_objects as _go\n",
    "\n",
    "sed_cols_all = [c for c in df_sed_rch.columns if c.upper().startswith('SED_')]\n",
    "_default_var = 'SED_IN_MINUS_OUT' if 'SED_IN_MINUS_OUT' in sed_cols_all else sed_cols_all[0]\n",
    "\n",
    "_dd_var = _w.Dropdown(options=sed_cols_all, value=_default_var, description='Var:')\n",
    "_dd_freq = _w.Dropdown(options=['D','M','Y'], value='Y', description='Freq:')\n",
    "_dd_method = _w.Dropdown(options=['sum','mean'], value='sum', description='Agg:')\n",
    "_btn = _w.Button(description='Update', button_style='primary')\n",
    "_out = _w.Output()\n",
    "\n",
    "# Precompute daily frame with chosen columns only (copy to avoid SettingWithCopy)\n",
    "_sed_base = df_sed_rch[sed_cols_all].copy()\n",
    "if not isinstance(_sed_base.index, pd.DatetimeIndex):\n",
    "    for cand in ['date','DATE','Date']:  # attempt to set date index\n",
    "        if cand in df_sed_rch.columns:\n",
    "            _sed_base = _sed_base.set_index(pd.to_datetime(df_sed_rch[cand]))\n",
    "            break\n",
    "\n",
    "\n",
    "def _agg(series: pd.Series, freq: str, how: str) -> pd.Series:\n",
    "    if freq == 'D':\n",
    "        return series\n",
    "    rule = {'M':'M','Y':'Y'}[freq]\n",
    "    if how == 'sum':\n",
    "        return series.resample(rule).sum(min_count=1)\n",
    "    elif how == 'mean':\n",
    "        return series.resample(rule).mean()\n",
    "    else:\n",
    "        return series\n",
    "\n",
    "\n",
    "def _update_view(*_):\n",
    "    with _out:\n",
    "        _out.clear_output()\n",
    "        v = _dd_var.value\n",
    "        f = _dd_freq.value\n",
    "        h = _dd_method.value\n",
    "        s = _sed_base[v].dropna()\n",
    "        a = _agg(s, f, h)\n",
    "\n",
    "        fig = _go.Figure()\n",
    "        fig.add_trace(_go.Scatter(\n",
    "            x=a.index, y=a.values, mode='lines+markers',\n",
    "            marker=dict(size=5),\n",
    "            line=dict(width=1.5),\n",
    "            name=f'{v} ({h} {f})'\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            height=330,\n",
    "            width=640,              # narrower figure\n",
    "            title='Cubillas sedimentation: Sed_in - Sed_out; yearly sum',\n",
    "            margin=dict(l=60, r=10, t=50, b=40),\n",
    "            yaxis_title='Sedimentation in tons',\n",
    "            xaxis_title='Date'\n",
    "        )\n",
    "        fig.update_yaxes(automargin=True)\n",
    "        display(fig)\n",
    "\n",
    "# Narrow widget widths\n",
    "for wdg, w in [(_dd_var, '170px'), (_dd_freq, '90px'), (_dd_method, '110px'), (_btn, '80px')]:\n",
    "    wdg.layout.width = w\n",
    "\n",
    "_btn.on_click(_update_view)\n",
    "\n",
    "# Initial render\n",
    "_update_view()\n",
    "\n",
    "# Compact container (about half typical notebook width)\n",
    "_w.VBox(\n",
    "    [\n",
    "        _w.HBox([_dd_var, _dd_freq, _dd_method, _btn],\n",
    "                layout=_w.Layout(justify_content='flex-start', width='640px')),\n",
    "        _out\n",
    "    ],\n",
    "    layout=_w.Layout(width='660px')  # overall box width\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade7554",
   "metadata": {},
   "source": [
    "### Net sediment differences & aggregation\n",
    "The previous cells added:\n",
    "- `SED_IN_MINUS_OUT` = sediment entering minus sediment leaving the reach.\n",
    "- `SED_OUT_MINUS_IN` = sediment leaving minus entering (mirror of the first).\n",
    "\n",
    "We also produced monthly and annual aggregations (sum & mean). Use the interactive widget above to:\n",
    "1. Pick a sediment (or derived) variable.\n",
    "2. Choose frequency: Daily (`D`), Monthly (`M`), Yearly (`Y`).\n",
    "3. Select aggregation: `sum` (load over period) or `mean` (average daily value in period).\n",
    "\n",
    "Implementation notes:\n",
    "- Supports both column name variants: `SED_INtons`/`SED_OUTtons` or `SED_IN`/`SED_OUT`.\n",
    "- If required columns are missing, a message is printed and derived columns aren't added.\n",
    "- Aggregations use pandas resample; sums require at least one non-NA (`min_count=1`).\n",
    "\n",
    "You can now integrate this logic into other analysis cells or export the aggregated frames as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca00335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "panel1 = ChartPanel(df_sed_rch, df_sub_yld, df_flow=df_water_flow_m3_d_cubillas)\n",
    "#panel2 = ChartPanel(df_sed_rch, df_sub_yld)\n",
    "#panel3 = ChartPanel(df_sed_rch, df_sub_yld)\n",
    "display(W.VBox([W.HTML(\"<h3>Δ Dynamics — Sediment / TP / TN</h3>\"), panel1.widget(), W.HTML(\"<hr>\")]))#, panel2.widget(), W.HTML(\"<hr>\"), panel3.widget()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d908226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your two dataframes here:\n",
    "# - df_sed_rch: SWAT .rch-like data (must include: date, RCH, SED_INtons, SED_OUTtons; optional: FLOW_OUT)\n",
    "# - df_sub_yld: SWAT .sub-like data (must include: date, SUB, AREA (km2), SYLD (t/ha), WYLD (mm))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example wiring (adjust variable names to yours):\n",
    "df_rch = df_sed_rch         # <-- replace with your reach dataframe variable\n",
    "df_sub = df_sub_yld         # <-- replace with your subbasin dataframe variable\n",
    "\n",
    "# If you don't have them yet, this creates a tiny synthetic example:\n",
    "if \"df_rch\" not in locals() or \"df_sub\" not in locals():\n",
    "    rng = pd.date_range(\"2018-01-01\",\"2020-12-31\",freq=\"D\")\n",
    "    reaches = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "    rec_r, rec_s = [], []\n",
    "    for rch in reaches:\n",
    "        IN = np.random.gamma(8, 15, len(rng))\n",
    "        OUT = IN + np.sin(np.linspace(0, 18, len(rng))) * 30 + np.random.normal(0,15,len(rng))\n",
    "        FLOW_OUT = np.random.uniform(3, 30, len(rng))\n",
    "        rec_r.append(pd.DataFrame({\"date\": rng, \"RCH\": rch, \"SED_INtons\": IN.clip(0), \"SED_OUTtons\": OUT.clip(0), FLOW_OUTcms: FLOW_OUT}))\n",
    "        area_km2 = 50 + 20*rch\n",
    "        WYLD = np.random.uniform(0, 8, len(rng))\n",
    "        SYLD_t_ha = np.random.gamma(3, 0.05, len(rng))\n",
    "        rec_s.append(pd.DataFrame({\"date\": rng, \"SUB\": rch, \"AREA\": area_km2, \"SYLD\": SYLD_t_ha, \"WYLD\": WYLD}))\n",
    "    df_rch = pd.concat(rec_r, ignore_index=True)\n",
    "    df_sub = pd.concat(rec_s, ignore_index=True)\n",
    "\n",
    "# Launch three independent panels\n",
    "panel1 = ChartPanel(df_rch, df_sub)\n",
    "panel2 = ChartPanel(df_rch, df_sub)\n",
    "panel3 = ChartPanel(df_rch, df_sub)\n",
    "\n",
    "display(W.VBox([\n",
    "    W.HTML(\"<h3>Sediment Dynamics Dashboard — methods A/B/C with toggles</h3>\"\n",
    "           \"<p>Δ_channel = (OUT − IN) − DR·SYLD_tons;  Retained = (IN + DR·SYLD_tons − OUT). \"\n",
    "           \"C1: mg/L (uses FLOW_OUT). C2: kg/mm/ha (uses WYLD & area).</p>\"),\n",
    "    panel1.widget(),\n",
    "    W.HTML(\"<hr>\"),\n",
    "    panel2.widget(),\n",
    "    W.HTML(\"<hr>\"),\n",
    "    panel3.widget(),\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01f975",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 3 possible methods (one time series each)\n",
    "\n",
    "## Method A — **Channel net balance corrected for local yield** (Δ\\_channel)\n",
    "\n",
    "**What it is:**\n",
    "Net channel exchange (erosion/resuspension minus deposition) after removing the subbasin’s lateral supply.\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Delta_\\text{channel}(t) \\;=\\; \\underbrace{\\text{SED\\_OUT}(t) - \\text{SED\\_IN}(t)}_{\\text{net at reach}} \\;-\\; \\underbrace{DR \\cdot \\text{SYLD\\_tons}(t)}_{\\text{local hillslope delivery}}\n",
    "}\n",
    "$$\n",
    "\n",
    "* **Positive** ⇒ channel is a **source** (net erosion/resuspension that adds sediment).\n",
    "* **Negative** ⇒ channel is a **sink** (net deposition/trapping).\n",
    "* Units: **tons / time-step** (daily if daily outputs).\n",
    "* $DR$ = delivery ratio (0–1) for how much of the subbasin yield actually makes it into the channel segment during the step. If you don’t estimate it, start with **DR=1** (upper bound).\n",
    "\n",
    "---\n",
    "\n",
    "## Method B — **Retained mass in reach** (deposition-focused)\n",
    "\n",
    "**What it is:**\n",
    "How much mass is kept in the reach after accounting for what came in (upstream + local) vs what left.\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\text{Retained}(t) \\;=\\; \\underbrace{\\big(\\text{SED\\_IN}(t) + DR \\cdot \\text{SYLD\\_tons}(t)\\big) - \\text{SED\\_OUT}(t)}_{\\text{positive = deposition, negative = net export}}\n",
    "}\n",
    "$$\n",
    "\n",
    "* **Positive** ⇒ **deposition/retention** that day;\n",
    "* **Negative** ⇒ **net export** that day.\n",
    "* Units: **tons / time-step**.\n",
    "* This is simply the sign-flipped form of Method A: $\\text{Retained} = -\\Delta_\\text{channel}$. It’s often easier to interpret when you care about **sedimentation**.\n",
    "\n",
    "---\n",
    "\n",
    "## Method C — **Hydrologically normalized channel signal**\n",
    "\n",
    "**What it is:**\n",
    "Normalize the channel net signal for hydrologic forcing so you can compare wet vs. dry periods and different-size basins. Two common normalizations; pick one depending on your question:\n",
    "\n",
    "### (C1) Concentration-like normalization (per discharge)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Delta_\\text{chan\\_conc}(t)\\;[\\mathrm{mg/L}] \\;\\approx\\; \n",
    "\\frac{10^9\\cdot\\big(\\text{SED\\_OUT}-\\text{SED\\_IN}-DR\\cdot \\text{SYLD\\_tons}\\big)}\n",
    "{ \\text{FLOW\\_OUT}(t)\\,[\\mathrm{m^3/s}] \\cdot 86{,}400 \\cdot 10^3 }\n",
    "}\n",
    "$$\n",
    "\n",
    "(Practically: $\\text{tons/day} \\times 11.574074 / Q_\\text{out,cms}$.)\n",
    "\n",
    "* Tells you how much **excess channel signal per unit water** you have (mg/L).\n",
    "* Use when comparing periods/places with different flows.\n",
    "\n",
    "### (C2) Runoff normalization (per mm-runoff per ha)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\Delta_\\text{chan,\\,kg/mm/ha}(t) \\;=\\;\n",
    "\\frac{\\Delta_\\text{channel}(t)\\,[\\text{tons}] \\times 1000}{\\text{WYLD}(t)\\,[\\text{mm}] \\times \\text{Area}_\\text{sub}(t)\\,[\\text{ha}]}\n",
    "}\n",
    "$$\n",
    "\n",
    "* Interpretable as **channel net mass per unit hydrologic production** from that subbasin.\n",
    "* Great to remove the “it was a wet year” effect.\n",
    "\n",
    "> You can compute **either C1 or C2** (or both). They each produce a single time series.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Transparent explanations (what you’re actually measuring)\n",
    "\n",
    "### Method A — Δ\\_channel (tons/time)\n",
    "\n",
    "* **Goal:** isolate the **channel** as a control volume.\n",
    "* **Why subtract subbasin SYLD?** The raw `OUT−IN` includes hillslope + channel. Removing delivered local load aims to leave **net channel processes** (bed/bank erosion vs. deposition).\n",
    "* **Delivery ratio $DR$:** If you don’t know it, **DR=1** is conservative (maximizes local delivery). If you later build a simple upstream accounting, estimate $DR$ empirically (see below).\n",
    "* **Use when:** you want a direct, mass-based answer to “is this reach eroding or depositing over time?”\n",
    "\n",
    "### Method B — Retained mass (tons/time)\n",
    "\n",
    "* **Goal:** focus directly on **sedimentation/retention**.\n",
    "* Positive values simply read as “this much sediment stayed in the reach this step.”\n",
    "* **Pros:** very interpretable if you’re concerned with **sediment build-up** or **trap performance**;\n",
    "  **Cons:** bounded only by inflow magnitude; can be volatile in events (use weekly/monthly smoothing if needed).\n",
    "\n",
    "### Method C — Hydrologically normalized signal\n",
    "\n",
    "* **Goal:** take out the effect of **varying water** so you can compare seasons/years or subbasins fairly.\n",
    "* **C1 (mg/L):** treats the channel net term as a concentration-like metric per unit discharge (uses `FLOW_OUT`).\n",
    "\n",
    "  * Good for diagnosing event-driven resuspension vs. baseline.\n",
    "* **C2 (kg/mm/ha):** divides by subbasin **runoff production** (WYLD × area) — a *process-based* normalization.\n",
    "\n",
    "  * Good for inter-year or inter-basin comparisons where hydrology differs.\n",
    "* **Caveat:** normalizations move you away from strict mass balance; interpret as **indices** of channel behavior per unit water, not as total stored mass.\n",
    "\n",
    "---\n",
    "\n",
    "## Optional: estimating a better $DR$ later (if you get topology)\n",
    "\n",
    "If you can map **upstream reaches** for each reach, estimate a **time-varying delivery ratio**:\n",
    "\n",
    "1. Sum upstream `SED_OUT` into the target reach (per day).\n",
    "2. The **observed lateral load** is $\\max( \\text{SED\\_IN} - \\sum \\text{upstream SED\\_OUT}, 0)$.\n",
    "3. Then $ DR \\approx \\frac{\\text{observed lateral load}}{\\text{SYLD\\_tons}}$ (clip to \\[0,1], smooth by event/season).\n",
    "\n",
    "You can pass that as `dr` (Series keyed by `(date, reach)`) to the same function above.\n",
    "\n",
    "---\n",
    "\n",
    "## What else to account for (quick checklist)\n",
    "\n",
    "* **Storage features:** reservoirs/ponds/wetlands -> big effect on retention (consider separate treatment if present).\n",
    "* **Timing/lag:** daily routing can shift peaks; exact day-by-day mass balance can be noisy (aggregate to weekly/monthly for interpretation).\n",
    "* **Area scaling:** for cross-reach comparisons, use C2 or divide A/B by area (tons/km²/day).\n",
    "* **Uncertainty:** show IQR/90% bands or confidence intervals over seasons/years.\n",
    "\n",
    "If you share small slices of your `.rch`/`.sub` (columns + a few days), I can plug them into the functions and show you all three series overlayed for a sample reach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### old dashboard calls:\n",
    "\n",
    "\n",
    "figs = build_sediment_dashboard(df_sed_rch, reach_numbers=[10,12,13,14, 15, 16, 17])    \n",
    "figs[\"fig_avg_over_time\"].show()\n",
    "figs[\"fig_clim_aggregate\"].show()\n",
    "figs[\"fig_year_reach\"].show()\n",
    "#\n",
    "# # per-reach quick views:\n",
    "figs[\"per_reach_climatology\"](reach=2).show()\n",
    "figs[\"per_reach_full_series\"](reach=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c71f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5292e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14484456",
   "metadata": {},
   "source": [
    "# Fan charts with optional spaghetti lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea915b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fan_compare_simulations_dashboard(\n",
    "    sim_dfs: Dict[str, pd.DataFrame],\n",
    "    variables: List[str],\n",
    "    *,\n",
    "    reach: Optional[int] = None,\n",
    "    freq_options: Iterable[str] = (\"D\",\"W\",\"M\",\"A\"),\n",
    "    max_bin_size: int = 12,\n",
    "    start: Optional[Union[str, datetime, date]] = None,\n",
    "    end: Optional[Union[str, datetime, date]] = None,\n",
    "    season_months: Optional[List[int]] = None,\n",
    "    how_map_defaults: Optional[Dict[str, str]] = None,\n",
    "    reach_col: str = \"RCH\",\n",
    "    date_col: str = \"date\",\n",
    "    flow_col: str = \"FLOW_OUTcms\",\n",
    "    template: str = \"plotly_white\",\n",
    "    figure_width: Optional[int] = 1200,\n",
    "    figure_height: int = 650\n",
    "):\n",
    "    if how_map_defaults is None:\n",
    "        how_map_defaults = {}\n",
    "\n",
    "    # discover reaches\n",
    "    all_reaches = set()\n",
    "    number_of_simulations = 0\n",
    "    for df in sim_dfs.values():\n",
    "        if reach_col in df.columns:\n",
    "            all_reaches.update(df[reach_col].dropna().unique().tolist())\n",
    "        number_of_simulations += 1\n",
    "    reach_choices = sorted(int(r) for r in all_reaches if pd.notna(r))\n",
    "    if not reach_choices:\n",
    "        raise ValueError(\"No reaches found.\")\n",
    "    if reach is None:\n",
    "        reach = reach_choices[0]\n",
    "\n",
    "    # widgets (no per-run checkboxes; too many runs)\n",
    "    num_sim = widgets.HTML(value=f\"Number of initializations: {number_of_simulations}\")\n",
    "    dd_var   = widgets.Dropdown(options=variables, value=variables[0], description=\"Variable:\", layout=widgets.Layout(width=\"360px\"))\n",
    "    dd_reach = widgets.Dropdown(options=reach_choices, value=reach, description=\"Reach:\", layout=widgets.Layout(width=\"180px\"))\n",
    "    dd_freq  = widgets.Dropdown(options=list(freq_options), value=\"D\", description=\"Freq:\", layout=widgets.Layout(width=\"140px\"))\n",
    "    sl_bin   = widgets.IntSlider(value=1, min=1, max=max_bin_size, step=1, description=\"Bin:\", continuous_update=False, layout=widgets.Layout(width=\"300px\"))\n",
    "    dd_method = widgets.Dropdown(options=[\"sum\",\"mean\",\"flow_weighted_mean\"], value=\"mean\", description=\"Method:\", layout=widgets.Layout(width=\"280px\"))\n",
    "    cb_autoscale_y_live = widgets.Checkbox(value=True, description=\"Auto-scale Y on zoom\")\n",
    "    cb_show_names_in_tooltip = widgets.Checkbox(value=False, description=\"Names in tooltip\")\n",
    "    \n",
    "\n",
    "    def _default_method_for_var(v: str) -> str:\n",
    "        if v in how_map_defaults:\n",
    "            return how_map_defaults[v]\n",
    "        if \"Conc\" in v or \"mg/L\" in v:\n",
    "            return \"flow_weighted_mean\"\n",
    "        if any(u in v.lower() for u in [\"kg\",\"tons\",\"mg\"]):\n",
    "            return \"sum\"\n",
    "        return \"mean\"\n",
    "    dd_method.value = _default_method_for_var(dd_var.value)\n",
    "\n",
    "    out = widgets.Output()\n",
    "    _last = {\"aligned_df\": None, \"y_fixed\": None, \"fig\": None}\n",
    "\n",
    "    TICK_STOPS = [\n",
    "        dict(dtickrange=[None, 1000*60*60*24], value=\"%Y-%m-%d\\n%H:%M\"),\n",
    "        dict(dtickrange=[1000*60*60*24, 1000*60*60*24*28], value=\"%Y-%m-%d\"),\n",
    "        dict(dtickrange=[1000*60*60*24*28, 1000*60*60*24*365], value=\"%Y-%m\"),\n",
    "        dict(dtickrange=[1000*60*60*24*365, None], value=\"%Y\"),\n",
    "    ]\n",
    "\n",
    "    def _hovertemplate(show_name: bool) -> str:\n",
    "        return (\"%{fullData.name}: %{y:.4g}<extra></extra>\" if show_name\n",
    "                else \"%{y:.4g}<extra></extra>\")\n",
    "\n",
    "    def _compute_and_plot():\n",
    "        freq_str = _make_freq_string(dd_freq.value, sl_bin.value)\n",
    "        var = dd_var.value\n",
    "        method = dd_method.value\n",
    "\n",
    "        # Extract a single resampled series per run for the selected reach/variable\n",
    "        per_sim = {}\n",
    "        for sim_name, df in sim_dfs.items():\n",
    "            if var not in df.columns:\n",
    "                continue\n",
    "            sub = df[df[reach_col] == dd_reach.value][[date_col, var] + ([flow_col] if method == \"flow_weighted_mean\" else [])].copy()\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            sub = _ensure_dt_index(sub, date_col)\n",
    "            if start or end:\n",
    "                sub = _slice_time(sub, start, end)\n",
    "            if season_months:\n",
    "                sub = _filter_season(sub, season_months)\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            s = _resample_series(sub, var, freq=freq_str, how=method, flow_col=flow_col)\n",
    "            if s.empty:\n",
    "                continue\n",
    "            s.name = sim_name\n",
    "            per_sim[sim_name] = s\n",
    "\n",
    "        if not per_sim:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"No data for reach {dd_reach.value} and variable '{var}'.\")\n",
    "            return\n",
    "\n",
    "        # Align series to a common time index (union) and build 2D matrix (T x N)\n",
    "        aligned_df = pd.concat(per_sim.values(), axis=1).sort_index()\n",
    "        aligned_df.index = pd.to_datetime(aligned_df.index, utc=False)\n",
    "        arr = aligned_df.to_numpy(dtype=float)  # shape: (T, N)\n",
    "        x_dt = aligned_df.index.to_pydatetime()\n",
    "        _last[\"aligned_df\"] = aligned_df\n",
    "\n",
    "        # Compute quantiles across runs (ignore NaNs)\n",
    "        percs = [5, 10, 25, 50, 75, 90, 95]\n",
    "        if arr.shape[1] == 0:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(\"No aligned data after resampling.\")\n",
    "            return\n",
    "        qs = np.nanpercentile(arr, percs, axis=1)  # shape: (7, T)\n",
    "        q = {p: qs[i, :] for i, p in enumerate(percs)}  # p -> array(T,)\n",
    "\n",
    "        # Precompute y-range for fixed scaling\n",
    "        finite_vals = arr[np.isfinite(arr)]\n",
    "        if finite_vals.size:\n",
    "            y_min = float(np.nanmin(finite_vals))\n",
    "            y_max = float(np.nanmax(finite_vals))\n",
    "            if y_min == y_max:\n",
    "                y_max = y_min + 1.0\n",
    "        else:\n",
    "            y_min, y_max = 0.0, 1.0\n",
    "        pad = (y_max - y_min) * 0.05\n",
    "        _last[\"y_fixed\"] = [y_min - pad, y_max + pad]\n",
    "\n",
    "        # Build figure\n",
    "        fig = go.FigureWidget(layout=dict(template=template))\n",
    "        if figure_width is not None:\n",
    "            fig.layout.width = int(figure_width)\n",
    "        fig.layout.height = int(figure_height)\n",
    "\n",
    "        # Fan chart: draw wider band first, then narrower, then median\n",
    "        color = \"#1f77b4\"\n",
    "        rgba = lambda a: f\"rgba(31,119,180,{a})\"\n",
    "\n",
    "        # 90% band (p05..p95)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_dt, y=q[95], mode=\"lines\", line=dict(color=rgba(0.12), width=0.5),\n",
    "            name=\"p95\", showlegend=False, hoverinfo=\"skip\"\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_dt, y=q[5], mode=\"lines\", line=dict(color=rgba(0.12), width=0.5),\n",
    "            fill=\"tonexty\", fillcolor=rgba(0.12),\n",
    "            name=\"p05–p95\", showlegend=True, hoverinfo=\"skip\"\n",
    "        ))\n",
    "\n",
    "        # 50% band (p25..p75)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_dt, y=q[75], mode=\"lines\", line=dict(color=rgba(0.28), width=0.5),\n",
    "            name=\"p75\", showlegend=False, hoverinfo=\"skip\"\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_dt, y=q[25], mode=\"lines\", line=dict(color=rgba(0.28), width=0.5),\n",
    "            fill=\"tonexty\", fillcolor=rgba(0.28),\n",
    "            name=\"p25–p75\", showlegend=True, hoverinfo=\"skip\"\n",
    "        ))\n",
    "\n",
    "        # Median\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_dt, y=q[50], mode=\"lines\", line=dict(color=\"black\", width=2),\n",
    "            name=\"median\", hovertemplate=\"%{y:.4g}<extra></extra>\"\n",
    "        ))\n",
    "\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"{var} — Reach {dd_reach.value} ({freq_str}, {method})\",\n",
    "            xaxis_title=\"Date\", yaxis_title=var,\n",
    "            hovermode=\"x unified\",\n",
    "            hoverlabel=dict(namelength=-1, align=\"left\", font_size=12, bgcolor=\"white\"),\n",
    "            legend=dict(orientation=\"h\", y=1.05, x=0),\n",
    "            xaxis=dict(\n",
    "                type=\"date\",\n",
    "                rangeslider=dict(visible=True),\n",
    "                tickformatstops=TICK_STOPS\n",
    "            ),\n",
    "            margin=dict(l=60, r=20, t=110, b=50)\n",
    "        )\n",
    "\n",
    "        # fixed Y; optional live update on zoom\n",
    "        fig.update_yaxes(autorange=False, range=_last[\"y_fixed\"])\n",
    "        _last[\"fig\"] = fig\n",
    "\n",
    "        def _on_xrange_change(layout, xrange):\n",
    "            if _last[\"aligned_df\"] is None:\n",
    "                return\n",
    "            if not cb_autoscale_y_live.value:\n",
    "                fig.layout.yaxis.update(autorange=False, range=_last[\"y_fixed\"])\n",
    "                return\n",
    "            try:\n",
    "                x0 = pd.to_datetime(xrange[0]); x1 = pd.to_datetime(xrange[1])\n",
    "            except Exception:\n",
    "                return\n",
    "            win = _last[\"aligned_df\"].loc[( _last[\"aligned_df\"].index >= x0) & (_last[\"aligned_df\"].index <= x1)]\n",
    "            if win.empty:\n",
    "                return\n",
    "            vals = win.to_numpy(dtype=float)\n",
    "            vals = vals[np.isfinite(vals)]\n",
    "            if vals.size == 0:\n",
    "                return\n",
    "            ymin = float(np.nanmin(vals)); ymax = float(np.nanmax(vals))\n",
    "            if ymin == ymax: ymax = ymin + 1.0\n",
    "            pad_local = (ymax - ymin) * 0.05\n",
    "            fig.layout.yaxis.update(autorange=False, range=[ymin - pad_local, ymax + pad_local])\n",
    "\n",
    "        fig.layout.xaxis.on_change(_on_xrange_change, 'range')\n",
    "\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "    # observers\n",
    "    def _on_var_change(change):\n",
    "        dd_method.value = _default_method_for_var(change[\"new\"])\n",
    "    dd_var.observe(_on_var_change, names=\"value\")\n",
    "\n",
    "    def _on_tooltip_toggle(change):\n",
    "        if _last[\"fig\"] is None:\n",
    "            return\n",
    "        ht = (\"%{fullData.name}: %{y:.4g}<extra></extra>\" if change[\"new\"]\n",
    "              else \"%{y:.4g}<extra></extra>\")\n",
    "\n",
    "\n",
    "    cb_show_names_in_tooltip.observe(_on_tooltip_toggle, names=\"value\")\n",
    "\n",
    "    for w in [num_sim, dd_var, dd_reach, dd_freq, sl_bin, dd_method, cb_autoscale_y_live]:\n",
    "        w.observe(lambda _: _compute_and_plot(), names=\"value\")\n",
    "\n",
    "    controls_left  = widgets.VBox([num_sim, dd_var, dd_method])\n",
    "    controls_right = widgets.VBox([dd_reach, dd_freq, sl_bin, cb_autoscale_y_live, cb_show_names_in_tooltip])\n",
    "    controls = widgets.HBox([controls_left, widgets.HBox([widgets.Label(\"\"), controls_right])])\n",
    "    display(controls, out)\n",
    "\n",
    "    _compute_and_plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537aa1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dda88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058904c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_fan1 = fan_compare_simulations_dashboard(\n",
    "    dfs_mc_run_x,\n",
    "    vars_to_compare,\n",
    "    reach=15,\n",
    "    start=\"1981-01-01\",\n",
    "    end=\"2020-12-30\",\n",
    "    freq_options=(\"D\",\"W\",\"M\",\"A\"),\n",
    "    max_bin_size=30,\n",
    "    how_map_defaults=how_map_defaults,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce19e0d",
   "metadata": {},
   "source": [
    "# compare measuremenst to swat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d729a",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079afbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c97b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c514320",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90816417",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf13ff",
   "metadata": {},
   "source": [
    "## Compare different simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b288e8",
   "metadata": {},
   "source": [
    "### variance in certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from typing import Dict, List, Optional, Literal, Union, Iterable\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def _ensure_dt_index(df: pd.DataFrame, date_col: str) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[date_col] = pd.to_datetime(out[date_col])\n",
    "    return out.set_index(date_col).sort_index()\n",
    "\n",
    "def _slice_time(df: pd.DataFrame, start: Optional[Union[str, datetime, date]], end: Optional[Union[str, datetime, date]]) -> pd.DataFrame:\n",
    "    if start is not None:\n",
    "        df = df.loc[pd.to_datetime(start):]\n",
    "    if end is not None:\n",
    "        df = df.loc[:pd.to_datetime(end)]\n",
    "    return df\n",
    "\n",
    "def _filter_season(df: pd.DataFrame, months: List[int]) -> pd.DataFrame:\n",
    "    return df[df.index.month.isin(months)]\n",
    "\n",
    "def _make_freq_string(freq: str, bin_size: int) -> str:\n",
    "    base_map = {\"D\": \"D\", \"DAILY\": \"D\", \"W\": \"W\", \"WEEKLY\": \"W\",\n",
    "                \"M\": \"M\", \"MONTHLY\": \"M\", \"A\": \"A\", \"Y\": \"A\", \"YEARLY\": \"A\"}\n",
    "    base = base_map.get(freq.upper(), freq)\n",
    "    return f\"{bin_size}{base}\" if bin_size and bin_size > 1 else base\n",
    "\n",
    "def _resample_series(df: pd.DataFrame, var: str, freq: str,\n",
    "                     how: Literal[\"sum\",\"mean\",\"flow_weighted_mean\"],\n",
    "                     flow_col: str = \"FLOW_OUTcms\") -> pd.Series:\n",
    "    if how == \"sum\":\n",
    "        s = df[var].resample(freq).sum(min_count=1)\n",
    "    elif how == \"mean\":\n",
    "        s = df[var].resample(freq).mean()\n",
    "    elif how == \"flow_weighted_mean\":\n",
    "        w = df[flow_col].clip(lower=0)\n",
    "        num = (df[var] * w).resample(freq).sum(min_count=1)\n",
    "        den = w.resample(freq).sum(min_count=1)\n",
    "        s = num / den.replace(0, np.nan)\n",
    "    else:\n",
    "        raise ValueError(\"how must be 'sum','mean','flow_weighted_mean'\")\n",
    "\n",
    "    # Make 100% sure the index is a tz-naive DatetimeIndex (not PeriodIndex/object)\n",
    "    if isinstance(s.index, pd.PeriodIndex):\n",
    "        s.index = s.index.to_timestamp(how=\"end\")\n",
    "    s.index = pd.to_datetime(s.index, utc=False)  # tz-naive\n",
    "    return s\n",
    "\n",
    "def compare_simulations_dashboard(\n",
    "    sim_dfs: Dict[str, pd.DataFrame],\n",
    "    variables: List[str],\n",
    "    *,\n",
    "    reach: Optional[int] = None,\n",
    "    freq_options: Iterable[str] = (\"D\",\"W\",\"M\",\"A\"),\n",
    "    max_bin_size: int = 12,\n",
    "    start: Optional[Union[str, datetime, date]] = None,\n",
    "    end: Optional[Union[str, datetime, date]] = None,\n",
    "    season_months: Optional[List[int]] = None,\n",
    "    how_map_defaults: Optional[Dict[str, str]] = None,\n",
    "    reach_col: str = \"RCH\",\n",
    "    date_col: str = \"date\",\n",
    "    flow_col: str = \"FLOW_OUTcms\",\n",
    "    template: str = \"plotly_white\",\n",
    "    figure_width: Optional[int] = 1200,\n",
    "    figure_height: int = 600\n",
    "):\n",
    "    if how_map_defaults is None:\n",
    "        how_map_defaults = {}\n",
    "\n",
    "    # discover reaches\n",
    "    all_reaches = set()\n",
    "    for df in sim_dfs.values():\n",
    "        all_reaches.update(df[reach_col].dropna().unique().tolist())\n",
    "    reach_choices = sorted(int(r) for r in all_reaches if pd.notna(r))\n",
    "    if not reach_choices:\n",
    "        raise ValueError(\"No reaches found.\")\n",
    "    if reach is None:\n",
    "        reach = reach_choices[0]\n",
    "\n",
    "    # widgets\n",
    "    sim_checkboxes = [widgets.Checkbox(value=True, description=name, layout=widgets.Layout(width=\"360px\"))\n",
    "                      for name in sim_dfs.keys()]\n",
    "    sim_box = widgets.VBox(sim_checkboxes, layout=widgets.Layout(width=\"400px\"))\n",
    "\n",
    "    dd_var   = widgets.Dropdown(options=variables, value=variables[0], description=\"Variable:\", layout=widgets.Layout(width=\"360px\"))\n",
    "    dd_reach = widgets.Dropdown(options=reach_choices, value=reach, description=\"Reach:\", layout=widgets.Layout(width=\"180px\"))\n",
    "    dd_freq  = widgets.Dropdown(options=list(freq_options), value=\"D\", description=\"Freq:\", layout=widgets.Layout(width=\"140px\"))\n",
    "    sl_bin   = widgets.IntSlider(value=1, min=1, max=max_bin_size, step=1, description=\"Bin:\", continuous_update=False, layout=widgets.Layout(width=\"300px\"))\n",
    "    dd_method = widgets.Dropdown(options=[\"sum\",\"mean\",\"flow_weighted_mean\"], value=\"mean\", description=\"Method:\", layout=widgets.Layout(width=\"280px\"))\n",
    "    cb_autoscale_y_live = widgets.Checkbox(value=True, description=\"Auto-scale Y when zooming\")\n",
    "    cb_show_names_in_tooltip = widgets.Checkbox(value=True, description=\"Show names in tooltip\")\n",
    "\n",
    "    def _default_method_for_var(v: str) -> str:\n",
    "        if v in how_map_defaults:\n",
    "            return how_map_defaults[v]\n",
    "        if \"Conc\" in v or \"mg/L\" in v:\n",
    "            return \"flow_weighted_mean\"\n",
    "        if any(u in v.lower() for u in [\"kg\",\"tons\",\"mg\"]):\n",
    "            return \"sum\"\n",
    "        return \"mean\"\n",
    "    dd_method.value = _default_method_for_var(dd_var.value)\n",
    "\n",
    "    out = widgets.Output()\n",
    "    _last = {\"aligned_df\": None, \"y_fixed\": None, \"fig\": None}\n",
    "\n",
    "    # “Nice” dynamic date labels without breaking rendering\n",
    "    TICK_STOPS = [\n",
    "        dict(dtickrange=[None, 1000*60*60*24], value=\"%Y-%m-%d\\n%H:%M\"),\n",
    "        dict(dtickrange=[1000*60*60*24, 1000*60*60*24*28], value=\"%Y-%m-%d\"),\n",
    "        dict(dtickrange=[1000*60*60*24*28, 1000*60*60*24*365], value=\"%Y-%m\"),\n",
    "        dict(dtickrange=[1000*60*60*24*365, None], value=\"%Y\"),\n",
    "    ]\n",
    "\n",
    "    def _hovertemplate(show_name: bool) -> str:\n",
    "        return (\"%{fullData.name}: %{y:.4g}<extra></extra>\" if show_name\n",
    "                else \"%{y:.4g}<extra></extra>\")\n",
    "\n",
    "    def _compute_and_plot():\n",
    "        selected_sims = {cb.description: sim_dfs[cb.description] for cb in sim_checkboxes if cb.value}\n",
    "        if not selected_sims:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(\"No simulations selected.\")\n",
    "            return\n",
    "\n",
    "        freq_str = _make_freq_string(dd_freq.value, sl_bin.value)\n",
    "        var = dd_var.value\n",
    "        method = dd_method.value\n",
    "\n",
    "        # prepare per sim\n",
    "        per_sim = {}\n",
    "        for sim_name, df in selected_sims.items():\n",
    "            sub = df[df[reach_col] == dd_reach.value].copy()\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            sub = _ensure_dt_index(sub, date_col)\n",
    "            if start or end:\n",
    "                sub = _slice_time(sub, start, end)\n",
    "            if season_months:\n",
    "                sub = _filter_season(sub, season_months)\n",
    "            if not sub.empty:\n",
    "                per_sim[sim_name] = sub\n",
    "\n",
    "        if not per_sim:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"No data for reach {dd_reach.value} in selection.\")\n",
    "            return\n",
    "\n",
    "        # align series\n",
    "        aligned = []\n",
    "        for sim_name, sub in per_sim.items():\n",
    "            s = _resample_series(sub, var, freq=freq_str, how=method, flow_col=flow_col)\n",
    "            s.name = sim_name\n",
    "            aligned.append(s)\n",
    "\n",
    "        aligned_df = pd.concat(aligned, axis=1).sort_index()\n",
    "        # Ensure real datetimes and build py-datetime array for Plotly (avoids “huge number” axes)\n",
    "        aligned_df.index = pd.to_datetime(aligned_df.index, utc=False)\n",
    "        x_dt = aligned_df.index.to_pydatetime()\n",
    "        _last[\"aligned_df\"] = aligned_df\n",
    "\n",
    "        # y range with padding\n",
    "        if aligned_df.size:\n",
    "            y_min = float(np.nanmin(aligned_df.values))\n",
    "            y_max = float(np.nanmax(aligned_df.values))\n",
    "            if not np.isfinite(y_min) or not np.isfinite(y_max):\n",
    "                y_min, y_max = 0.0, 1.0\n",
    "            if y_min == y_max:\n",
    "                y_max = y_min + 1.0\n",
    "        else:\n",
    "            y_min, y_max = 0.0, 1.0\n",
    "        pad = (y_max - y_min) * 0.05\n",
    "        _last[\"y_fixed\"] = [y_min - pad, y_max + pad]\n",
    "\n",
    "        # figure\n",
    "        fig = go.FigureWidget(layout=dict(template=template))\n",
    "        if figure_width is not None:\n",
    "            fig.layout.width = int(figure_width)\n",
    "        fig.layout.height = int(figure_height)\n",
    "\n",
    "        # lines only (simplified)\n",
    "        ht = _hovertemplate(cb_show_names_in_tooltip.value)\n",
    "        for sim_name in aligned_df.columns:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_dt, y=aligned_df[sim_name].values,\n",
    "                mode=\"lines\", name=sim_name, hovertemplate=ht,\n",
    "                connectgaps=True\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"{var} — Reach {dd_reach.value} ({freq_str}, {method})\",\n",
    "            xaxis_title=\"Date\", yaxis_title=var,\n",
    "            hovermode=\"x unified\",\n",
    "            hoverlabel=dict(namelength=-1, align=\"left\", font_size=12, bgcolor=\"white\"),\n",
    "            legend=dict(orientation=\"h\", y=1.05, x=0),\n",
    "            xaxis=dict(\n",
    "                type=\"date\",\n",
    "                rangeslider=dict(visible=True),\n",
    "                tickformatstops=TICK_STOPS\n",
    "            ),\n",
    "            margin=dict(l=60, r=20, t=110, b=50)\n",
    "        )\n",
    "\n",
    "        # fixed Y; live update on zoom\n",
    "        fig.update_yaxes(autorange=False, range=_last[\"y_fixed\"])\n",
    "        _last[\"fig\"] = fig\n",
    "\n",
    "        def _on_xrange_change(layout, xrange):\n",
    "            if _last[\"aligned_df\"] is None:\n",
    "                return\n",
    "            if not cb_autoscale_y_live.value:\n",
    "                fig.layout.yaxis.update(autorange=False, range=_last[\"y_fixed\"])\n",
    "                return\n",
    "            try:\n",
    "                x0 = pd.to_datetime(xrange[0]); x1 = pd.to_datetime(xrange[1])\n",
    "            except Exception:\n",
    "                return\n",
    "            win = _last[\"aligned_df\"].loc[( _last[\"aligned_df\"].index >= x0) & (_last[\"aligned_df\"].index <= x1)]\n",
    "            if win.empty:\n",
    "                return\n",
    "            ymin = float(np.nanmin(win.values)); ymax = float(np.nanmax(win.values))\n",
    "            if not np.isfinite(ymin) or not np.isfinite(ymax):\n",
    "                return\n",
    "            if ymin == ymax:\n",
    "                ymax = ymin + 1.0\n",
    "            pad_local = (ymax - ymin) * 0.05\n",
    "            fig.layout.yaxis.update(autorange=False, range=[ymin - pad_local, ymax + pad_local])\n",
    "\n",
    "        fig.layout.xaxis.on_change(_on_xrange_change, 'range')\n",
    "\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "    # observers\n",
    "    def _on_var_change(change):\n",
    "        dd_method.value = _default_method_for_var(change[\"new\"])\n",
    "    dd_var.observe(_on_var_change, names=\"value\")\n",
    "\n",
    "    def _on_tooltip_toggle(change):\n",
    "        if _last[\"fig\"] is None:\n",
    "            return\n",
    "        ht = (\"%{fullData.name}: %{y:.4g}<extra></extra>\" if change[\"new\"]\n",
    "              else \"%{y:.4g}<extra></extra>\")\n",
    "        for tr in _last[\"fig\"].data:\n",
    "            tr.update(hovertemplate=ht)\n",
    "\n",
    "    cb_show_names_in_tooltip.observe(_on_tooltip_toggle, names=\"value\")\n",
    "\n",
    "    for w in [dd_var, dd_reach, dd_freq, sl_bin, dd_method, cb_autoscale_y_live] + sim_checkboxes:\n",
    "        w.observe(lambda _: _compute_and_plot(), names=\"value\")\n",
    "\n",
    "    controls_top = widgets.HBox([sim_box, widgets.VBox([dd_var, dd_method])])\n",
    "    controls_bottom = widgets.HBox([dd_reach, dd_freq, sl_bin, cb_autoscale_y_live, cb_show_names_in_tooltip])\n",
    "    display(controls_top, controls_bottom, out)\n",
    "\n",
    "    _compute_and_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b463e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad5711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Yearly, aggregated view (sum for loads, FWM for concentrations) for the same reach:\n",
    "figs_annually = compare_simulations_dashboard(\n",
    "    load_or_build_dfs_for_runs([81], force_rebuild=False),\n",
    "    vars_to_compare,\n",
    "    reach=15,\n",
    "    start=\"1981-01-01\",\n",
    "    end=\"2020-12-30\",\n",
    "    freq_options=(\"D\",\"W\",\"M\",\"A\"),\n",
    "    max_bin_size=30,\n",
    "    how_map_defaults=how_map_defaults,\n",
    ")\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "figs_annually_2 = compare_simulations_dashboard(\n",
    "    runs,\n",
    "    vars_to_compare,\n",
    "    reach=15,\n",
    "    start=\"1981-01-01\",\n",
    "    end=\"2020-12-30\",\n",
    "    freq_options=(\"D\",\"W\",\"M\",\"A\"),\n",
    "    max_bin_size=30,\n",
    "    how_map_defaults={\n",
    "        \"ORGN_OUTkg\": \"sum\",\n",
    "        \"ORGP_OUTkg\": \"sum\",\n",
    "        \"NO3_OUTkg\": \"sum\",\n",
    "        \"SEDCONCmg/L\": \"flow_weighted_mean\",\n",
    "        \"NO3ConcMg/l\": \"flow_weighted_mean\"\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Save a specific plot:\n",
    "# figs_daily[\"NO3_OUTkg\"].savefig(\"reach12_no3_daily_compare.png\", dpi=180, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315a1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as W\n",
    "from IPython.display import display\n",
    "\n",
    "def overlay_tp_tn_toggle(\n",
    "    df_rch: pd.DataFrame,\n",
    "    df_sub: pd.DataFrame,\n",
    "    reaches,\n",
    "    agg: str = \"sum\",                 # \"sum\" or \"mean\" across selected reaches\n",
    "    resample_rule: str | None = None, # e.g. \"W\", \"M\" (None = native timestep)\n",
    "    resample_agg: str = \"sum\",        # for masses, \"sum\" is typical\n",
    "    roll: int | None = None,          # rolling window (days); None/0/1 disables\n",
    "    # column mappings (keep your updated names; change only if yours differ)\n",
    "    rch_cols = dict(\n",
    "        date=\"date\", reach=\"RCH\",\n",
    "        ORGN_OUT=\"ORGN_OUTkg\", ORGP_OUT=\"ORGP_OUTkg\",\n",
    "        NO3_OUT=\"NO3_OUTkg\",  NH4_OUT=\"NH4_OUTkg\", NO2_OUT=\"NO2_OUTkg\",\n",
    "        MINP_OUT=\"MINP_OUTkg\",\n",
    "        TOT_N=\"TOT_Nkg\", TOT_P=\"TOT_Pkg\",\n",
    "    ),\n",
    "    sub_cols = dict(\n",
    "        date=\"date\", sub=\"SUB\", area_km2=\"AREA\",\n",
    "        ORGN=\"ORGN\", NSURQ=\"NSURQ\",        # N (kg/ha)\n",
    "        ORGP=\"ORGP\", SOLP=\"SOLP\", SEDP=\"SEDP\",  # P (kg/ha)\n",
    "    ),\n",
    "):\n",
    "    # --- standardize columns locally\n",
    "    r = df_rch.rename(columns={\n",
    "        rch_cols[\"date\"]:\"date\", rch_cols[\"reach\"]:\"RCH\",\n",
    "        rch_cols[\"ORGN_OUT\"]:\"ORGN_OUTkg\", rch_cols[\"ORGP_OUT\"]:\"ORGP_OUTkg\",\n",
    "        rch_cols[\"NO3_OUT\"]:\"NO3_OUTkg\",   rch_cols[\"NH4_OUT\"]:\"NH4_OUTkg\", rch_cols[\"NO2_OUT\"]:\"NO2_OUTkg\",\n",
    "        rch_cols[\"MINP_OUT\"]:\"MINP_OUTkg\",\n",
    "        rch_cols[\"TOT_N\"]:\"TOT_Nkg\", rch_cols[\"TOT_P\"]:\"TOT_Pkg\",\n",
    "    }).copy()\n",
    "    s = df_sub.rename(columns={\n",
    "        sub_cols[\"date\"]:\"date\", sub_cols[\"sub\"]:\"SUB\", sub_cols[\"area_km2\"]:\"AREA_KM2\",\n",
    "        sub_cols[\"ORGN\"]:\"ORGN\", sub_cols[\"NSURQ\"]:\"NSURQ\",\n",
    "        sub_cols[\"ORGP\"]:\"ORGP\", sub_cols[\"SOLP\"]:\"SOLP\", sub_cols[\"SEDP\"]:\"SEDP\",\n",
    "    }).copy()\n",
    "\n",
    "    r[\"date\"] = pd.to_datetime(r[\"date\"])\n",
    "    s[\"date\"] = pd.to_datetime(s[\"date\"])\n",
    "\n",
    "    # filter reaches\n",
    "    reaches = list(reaches) if hasattr(reaches, \"__iter__\") and not isinstance(reaches, (str, bytes)) else [reaches]\n",
    "    r = r[r[\"RCH\"].isin(reaches)].copy()\n",
    "    s = s[s[\"SUB\"].isin(reaches)].copy()\n",
    "\n",
    "    # RCH component sums\n",
    "    r[\"TN_components\"] = r[[\"ORGN_OUTkg\",\"NO3_OUTkg\",\"NH4_OUTkg\",\"NO2_OUTkg\"]].sum(axis=1)\n",
    "    r[\"TP_components\"] = r[[\"ORGP_OUTkg\",\"MINP_OUTkg\"]].sum(axis=1)\n",
    "\n",
    "    # aggregate across reaches by date\n",
    "    agg_key = \"sum\" if agg == \"sum\" else \"mean\"\n",
    "    r_agg = (r.groupby(\"date\")[[\"TN_components\",\"TP_components\",\"TOT_Nkg\",\"TOT_Pkg\"]]\n",
    "               .agg(agg_key).sort_index())\n",
    "\n",
    "    # SUB: kg/ha → kg (robust area handling: AREA in km² or ha)\n",
    "    area_series = pd.to_numeric(s[\"AREA_KM2\"], errors=\"coerce\")\n",
    "    AREA_IS_KM2 = np.nanmedian(area_series) < 1_000\n",
    "    s[\"AREA_HA\"] = area_series * (100.0 if AREA_IS_KM2 else 1.0)\n",
    "\n",
    "    s[\"TN_yield_sub_kg\"] = (s[\"ORGN\"].fillna(0) + s[\"NSURQ\"].fillna(0)) * s[\"AREA_HA\"]\n",
    "    s[\"TP_yield_sub_kg\"] = (s[\"ORGP\"].fillna(0) + s[\"SOLP\"].fillna(0) + s[\"SEDP\"].fillna(0)) * s[\"AREA_HA\"]\n",
    "    s_agg = (s.groupby(\"date\")[[\"TN_yield_sub_kg\",\"TP_yield_sub_kg\"]]\n",
    "               .agg(agg_key).sort_index())\n",
    "\n",
    "    # merge series\n",
    "    dfm = r_agg.merge(s_agg, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "    # optional resample (e.g., weekly/monthly totals)\n",
    "    if resample_rule:\n",
    "        dfm = getattr(dfm.resample(resample_rule), resample_agg)()\n",
    "\n",
    "    # optional rolling smooth\n",
    "    if roll and roll > 1:\n",
    "        dfm = dfm.rolling(roll, min_periods=max(1, roll//2)).mean()\n",
    "\n",
    "    # --- UI toggles\n",
    "    show_total   = W.Checkbox(value=True,  description=\"Show RCH Total (TOT_N/TOT_P)\")\n",
    "    show_comp    = W.Checkbox(value=True,  description=\"Show RCH Components sum (TN: ORGN+NO3+NH4+NO2; TP: ORGP+MINP)\")\n",
    "    show_subyld  = W.Checkbox(value=True,  description=\"Show SUB Yield sums (TN: ORGN+NSURQ; TP: ORGP+SOLP+SEDP)\")\n",
    "    out_tn = W.Output()\n",
    "    out_tp = W.Output()\n",
    "\n",
    "    def draw():\n",
    "        with out_tn:\n",
    "            out_tn.clear_output(wait=True)\n",
    "            fig = go.Figure()\n",
    "            if show_total.value:\n",
    "                fig.add_trace(go.Scatter(x=dfm.index, y=dfm[\"TOT_Nkg\"], mode=\"lines\",\n",
    "                                         name=\"RCH Total N (TOT_Nkg)\", line=dict(width=3)))\n",
    "            if show_comp.value:\n",
    "                fig.add_trace(go.Scatter(x=dfm.index, y=dfm[\"TN_components\"], mode=\"lines\",\n",
    "                                         name=\"RCH N components sum (ORGN+NO3+NH4+NO2)\"))\n",
    "            if show_subyld.value:\n",
    "                fig.add_trace(go.Scatter(x=dfm.index, y=dfm[\"TN_yield_sub_kg\"], mode=\"lines\",\n",
    "                                         name=\"SUB N yield sum (ORGN+NSURQ) — kg (area-scaled)\",\n",
    "                                         line=dict(dash=\"dash\")))\n",
    "            fig.update_layout(title=f\"TN — comparison (reaches {reaches}, agg={agg})\",\n",
    "                              xaxis_title=\"Date\", yaxis_title=\"Nitrogen (kg per step)\",\n",
    "                              legend_title=None, margin=dict(l=40,r=20,t=50,b=40))\n",
    "            fig.show()\n",
    "\n",
    "        with out_tp:\n",
    "            out_tp.clear_output(wait=True)\n",
    "            fig = go.Figure()\n",
    "            if show_total.value:\n",
    "                fig.add_trace(go.Scatter(x=dfm.index, y=dfm[\"TOT_Pkg\"], mode=\"lines\",\n",
    "                                         name=\"RCH Total P (TOT_Pkg)\", line=dict(width=3)))\n",
    "            if show_comp.value:\n",
    "                fig.add_trace(go.Scatter(x=dfm.index, y=dfm[\"TP_components\"], mode=\"lines\",\n",
    "                                         name=\"RCH P components sum (ORGP+MINP)\"))\n",
    "            if show_subyld.value:\n",
    "                fig.add_trace(go.Scatter(x=dfm.index, y=dfm[\"TP_yield_sub_kg\"], mode=\"lines\",\n",
    "                                         name=\"SUB P yield sum (ORGP+SOLP+SEDP) — kg (area-scaled)\",\n",
    "                                         line=dict(dash=\"dash\")))\n",
    "            fig.update_layout(title=f\"TP — comparison (reaches {reaches}, agg={agg})\",\n",
    "                              xaxis_title=\"Date\", yaxis_title=\"Phosphorus (kg per step)\",\n",
    "                              legend_title=None, margin=dict(l=40,r=20,t=50,b=40))\n",
    "            fig.show()\n",
    "\n",
    "    def on_change(_):\n",
    "        draw()\n",
    "\n",
    "    for w in (show_total, show_comp, show_subyld):\n",
    "        w.observe(on_change, names=\"value\")\n",
    "\n",
    "    # initial draw & display\n",
    "    draw()\n",
    "    display(W.VBox([\n",
    "        W.HTML(\"<b>Toggle which curves to show</b>\"),\n",
    "        W.HBox([show_total, show_comp, show_subyld]),\n",
    "        out_tn,\n",
    "        out_tp\n",
    "    ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sed_rch_cmp = dict_109[\"rch_run000109_real000396_1\"]\n",
    "df_sub_yld_cmp = parse_swat_sub_to_df(r\"C:\\SWAT\\RSWAT\\cubillas\\mc_results\\run000109_real000396_1\\output.sub\")\n",
    "df_sed_rch_cmp\n",
    "df_sub_yld_cmp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Minimal call — pick a single reach (or a list) and go:\n",
    "overlay_tp_tn_toggle(df_sed_rch_cmp, df_sub_yld_cmp, reaches=[1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,17], agg=\"mean\", resample_rule=\"W\", resample_agg=\"mean\", roll=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
